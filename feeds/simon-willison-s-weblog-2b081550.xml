<?xml version="1.0" encoding="utf-8"?><rss version="2.0"><channel><title>Simon Willison&apos;s Weblog</title><link>https://raw.githubusercontent.com/xavwe/rss-aggregator/refs/heads/main/feeds/simon-willison-s-weblog-2b081550.xml</link><description>Archived feed from https://simonwillison.net/atom/everything</description><item><title>Video + notes on upgrading a Datasette plugin for the latest 1.0 alpha</title><link>https://simonwillison.net/2025/Nov/6/upgrading-datasette-plugins/#atom-everything</link><description><![CDATA[<p>I'm upgrading various plugins for compatibility with the new <a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/">Datasette 1.0a20 alpha release</a> and I decided to record <a href="https://www.youtube.com/watch?v=qy4ci7AoF9Y">a video</a> of the process. This post accompanies that video with detailed additional notes.</p>

<p><lite-youtube videoid="qy4ci7AoF9Y" js-api="js-api" title="My process for upgrading Datasette plugins with uv and OpenAI Codex CLI" playlabel="Play: My process for upgrading Datasette plugins with uv and OpenAI Codex CLI"> </lite-youtube></p>

<h4 id="the-datasette-checkbox-plugin">The datasette-checkbox plugin</h4>
<p>I picked a very simple plugin to illustrate the upgrade process (possibly too simple). <a href="https://github.com/datasette/datasette-checkbox">datasette-checkbox</a> adds just one feature to Datasette: if you are viewing a table with boolean columns (detected as integer columns with names like <code>is_active</code> or <code>has_attachments</code> or <code>should_notify</code>) <em>and</em> your current user has permission to update rows in that table it adds an inline checkbox UI that looks like this:</p>
<p><img src="https://static.simonwillison.net/static/2025/datasette-checkbox.gif" alt="Animated demo of a table with name, is_done, should_be_deleted and is_happy columns. Each column has checkboxes, and clicking a checkboxflashes a little &quot;updated&quot; message." style="max-width: 100%;" /></p>
<p>I built the first version with the help of Claude back in August 2024 - details <a href="https://github.com/datasette/datasette-checkbox/issues/1#issuecomment-2294168693">in this issue comment</a>.</p>
<p>Most of the implementation is JavaScript that makes calls to Datasette 1.0's <a href="https://simonwillison.net/2022/Dec/2/datasette-write-api/">JSON write API</a>. The Python code just checks that the user has the necessary permissions before including the extra JavaScript.</p>
<h4 id="running-the-plugin-s-tests">Running the plugin's tests</h4>
<p>The first step in upgrading any plugin is to run its tests against the latest Datasette version.</p>
<p>Thankfully <code>uv</code> makes it easy to run code in scratch virtual environments that include the different code versions you want to test against.</p>
<p>I have a test utility called <code>tadd</code> (for "test against development Datasette") which I use for that purpose. I can run it in any plugin directory like this:</p>
<div class="highlight highlight-source-shell"><pre>tadd</pre></div>
<p>And it will run the existing plugin tests against whatever version of Datasette I have checked out in my <code>~/dev/datasette</code> directory.</p>
<p>You can see the full implementation of <code>tadd</code> (and its friend <code>radd</code> described below) <a href="https://til.simonwillison.net/python/uv-tests#variants-tadd-and-radd">in this TIL</a> - the basic version looks like this:</p>
<div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#!</span>/bin/sh</span>
uv run --no-project --isolated \
  --with-editable <span class="pl-s"><span class="pl-pds">'</span>.[test]<span class="pl-pds">'</span></span> --with-editable <span class="pl-k">~</span>/dev/datasette \
  python -m pytest <span class="pl-s"><span class="pl-pds">"</span><span class="pl-smi">$@</span><span class="pl-pds">"</span></span></pre></div>
<p>I started by running <code>tadd</code> in the <code>datasette-checkbox</code> directory, and got my first failure... but it wasn't due to permissions, it was because the <code>pyproject.toml</code> for the plugin was <a href="https://github.com/datasette/datasette-checkbox/blob/0.1a3/pyproject.toml#L13C1-L15C2">pinned</a> to a specific mismatched version of Datasette:</p>
<div class="highlight highlight-source-toml"><pre><span class="pl-smi">dependencies</span> = [
    <span class="pl-s"><span class="pl-pds">"</span>datasette==1.0a19<span class="pl-pds">"</span></span>
]</pre></div>
<p>I fixed this problem by swapping <code>==</code> to <code>&gt;=</code> and ran the tests again... and they passed! Which was a problem because I was expecting permission-related failures.</p>
<p>It turns out when I first wrote the plugin I was <a href="https://github.com/datasette/datasette-checkbox/blob/0.1a3/tests/test_checkbox.py">lazy with the tests</a> - they weren't actually confirming that the table page loaded without errors.</p>
<p>I needed to actually run the code myself to see the expected bug.</p>
<p>First I created myself a demo database using <a href="https://sqlite-utils.datasette.io/en/stable/cli.html#creating-tables">sqlite-utils create-table</a>:</p>
<div class="highlight highlight-source-shell"><pre>sqlite-utils create-table demo.db \
  demo id integer is_checked integer --pk id</pre></div>
<p>Then I ran it with Datasette against the plugin's code like so:</p>
<div class="highlight highlight-source-shell"><pre>radd demo.db</pre></div>
<p>Sure enough, visiting <code>/demo/demo</code> produced a 500 error about the missing <code>Datasette.permission_allowed()</code> method.</p>
<p>The next step was to update the test to also trigger this error:</p>
<pre><span class="pl-en">@<span class="pl-s1">pytest</span>.<span class="pl-c1">mark</span>.<span class="pl-c1">asyncio</span></span>
<span class="pl-k">async</span> <span class="pl-k">def</span> <span class="pl-en">test_plugin_adds_javascript</span>():
    <span class="pl-s1">datasette</span> <span class="pl-c1">=</span> <span class="pl-en">Datasette</span>()
    <span class="pl-s1">db</span> <span class="pl-c1">=</span> <span class="pl-s1">datasette</span>.<span class="pl-c1">add_memory_database</span>(<span class="pl-s">"demo"</span>)
    <span class="pl-k">await</span> <span class="pl-s1">db</span>.<span class="pl-c1">execute_write</span>(
        <span class="pl-s">"CREATE TABLE IF NOT EXISTS test (id INTEGER PRIMARY KEY, is_active INTEGER)"</span>
    )
    <span class="pl-k">await</span> <span class="pl-s1">datasette</span>.<span class="pl-c1">invoke_startup</span>()
    <span class="pl-s1">response</span> <span class="pl-c1">=</span> <span class="pl-k">await</span> <span class="pl-s1">datasette</span>.<span class="pl-c1">client</span>.<span class="pl-c1">get</span>(<span class="pl-s">"/demo/test"</span>)
    <span class="pl-k">assert</span> <span class="pl-s1">response</span>.<span class="pl-c1">status_code</span> <span class="pl-c1">==</span> <span class="pl-c1">200</span></pre>
<p>And now <code>tadd</code> fails as expected.</p>
<h4 id="upgrading-the-plugin-with-codex">Upgrading the plugin with Codex</h4>
<p>It this point I could have manually fixed the plugin itself - which would likely have been faster given the small size of the fix - but instead I demonstrated a bash one-liner I've been using to apply these kinds of changes automatically:</p>
<div class="highlight highlight-source-shell"><pre>codex <span class="pl-c1">exec</span> --dangerously-bypass-approvals-and-sandbox \
<span class="pl-s"><span class="pl-pds">"</span>Run the command tadd and look at the errors and then</span>
<span class="pl-s">read ~/dev/datasette/docs/upgrade-1.0a20.md and apply</span>
<span class="pl-s">fixes and run the tests again and get them to pass<span class="pl-pds">"</span></span></pre></div>
<p><code>codex exec</code> runs OpenAI Codex in non-interactive mode - it will loop until it has finished the prompt you give it.</p>
<p>I tell it to consult the subset of the <a href="https://docs.datasette.io/en/latest/upgrade_guide.html#datasette-1-0a20-plugin-upgrade-guide">Datasette upgrade documentation</a> that talks about Datasette permissions and then get the <code>tadd</code> command to pass its tests.</p>
<p>This is an example of what I call <a href="https://simonwillison.net/2025/Sep/30/designing-agentic-loops/">designing agentic loops</a> - I gave Codex the tools it needed (<code>tadd</code>) and a clear goal and let it get to work on my behalf.</p>
<p>The remainder of the video covers finishing up the work - testing the fix manually, commiting my work using:</p>
<div class="highlight highlight-source-shell"><pre>git commit -a -m <span class="pl-s"><span class="pl-pds">"</span><span class="pl-s"><span class="pl-pds">$(</span>basename <span class="pl-s"><span class="pl-pds">"</span><span class="pl-smi">$PWD</span><span class="pl-pds">"</span></span><span class="pl-pds">)</span></span> for datasette&gt;=1.0a20<span class="pl-pds">"</span></span> \
  -m <span class="pl-s"><span class="pl-pds">"</span>Refs https://github.com/simonw/datasette/issues/2577<span class="pl-pds">"</span></span></pre></div>
<p>Then shipping a <a href="https://pypi.org/project/datasette-checkbox/0.1a4/">0.1a4 release</a> to PyPI using the pattern <a href="https://til.simonwillison.net/pypi/pypi-releases-from-github">described in this TIL</a>.
Finally, I demonstrated that the shipped plugin worked in a fresh environment using <code>uvx</code> like this:</p>
<div class="highlight highlight-source-shell"><pre>uvx --prerelease=allow --with datasette-checkbox \
  datasette --root <span class="pl-k">~</span>/dev/ecosystem/datasette-checkbox/demo.db</pre></div>
<p>Executing this command installs and runs a fresh Datasette instance with a fresh copy of the new alpha plugin (<code>--prerelease=allow</code>). It's a neat way of confirming that freshly released software works as expected.</p>
<h4 id="a-colophon-for-the-video">A colophon for the video</h4>
<p>This video was shot in a single take using <a href="https://www.descript.com/">Descript</a>, with no rehearsal and perilously little preparation in advance. I recorded through my AirPods and applied the "Studio Sound" filter to clean up the audio. I pasted in a <code>simonwillison.net</code> closing slide from <a href="https://www.youtube.com/watch?v=GQvMLLrFPVI&amp;t=7s">my previous video</a> and exported it locally at 1080p, then uploaded it to YouTube.</p>
<p>Something I learned from the Software Carpentry <a href="https://simonwillison.net/2020/Sep/26/weeknotes-software-carpentry-sqlite/">instructor training course</a> is that making mistakes in front of an audience is actively helpful - it helps them see a realistic version of how software development works and they can learn from watching you recover. I see this as a great excuse for not editing out all of my mistakes!</p>
<p>I'm trying to build new habits around video content that let me produce useful videos while minimizing the amount of time I spend on production.</p>
<p>I plan to iterate more on the format as I get more comfortable with the process. I'm hoping I can find the right balance between production time and value to viewers.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/plugins">plugins</a>, <a href="https://simonwillison.net/tags/youtube">youtube</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/datasette">datasette</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/codex-cli">codex-cli</a></p>]]></description><pubDate>Thu, 6 Nov 2025 18:26:05 +0000</pubDate></item><item><title>Code research projects with async coding agents like Claude Code and Codex</title><link>https://simonwillison.net/2025/Nov/6/async-code-research/#atom-everything</link><description><![CDATA[<p>I've been experimenting with a pattern for LLM usage recently that's working out really well: <strong>asynchronous code research tasks</strong>. Pick a research question, spin up an asynchronous coding agent and let it go and run some experiments and report back when it's done.</p>
<ul>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#code-research">Code research</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#coding-agents">Coding agents</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#asynchronous-coding-agents">Asynchronous coding agents</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#give-them-a-dedicated-github-repository">Give them a dedicated GitHub repository</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#let-them-rip-with-unlimited-network-access">Let them rip with unlimited network access</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#my-simonw-research-collection">My simonw/research collection</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#this-is-total-slop-of-course">This is total slop, of course</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#try-it-yourself">Try it yourself</a></li>
</ul>
<h4 id="code-research">Code research</h4>
<p>Software development benefits enormously from something I call <strong>code research</strong>. The great thing about questions about code is that they can often be definitively answered by writing and executing code.</p>
<p>I often see questions on forums which hint at a lack of understanding of this skill.</p>
<p>"Could Redis work for powering the notifications feed for my app?" is a great example. The answer is <em>always</em> "it depends", but a better answer is that a good programmer already has everything they need to answer that question for themselves. Build a proof-of-concept, simulate the patterns you expect to see in production, then run experiments to see if it's going to work.</p>
<p>I've been a keen practitioner of code research for a long time. Many of my most interesting projects started out as a few dozen lines of experimental code to prove to myself that something was possible.</p>
<h4 id="coding-agents">Coding agents</h4>
<p>It turns out <strong>coding agents</strong> like Claude Code and Codex are a fantastic fit for this kind of work as well. Give them the right goal and a useful environment and they'll churn through a basic research project without any further supervision.</p>
<p>LLMs hallucinate and make mistakes. This is far less important for code research tasks because the code itself doesn't lie: if they write code and execute it and it does the right things then they've demonstrated to both themselves and to you that something really does work.</p>
<p>They can't prove something is impossible - just because the coding agent couldn't find a way to do something doesn't mean it can't be done - but they can often demonstrate that something <em>is</em> possible in just a few minutes of crunching.</p>
<h4 id="asynchronous-coding-agents">Asynchronous coding agents</h4>
<p>I've used interactive coding agents like Claude Code and Codex CLI for a bunch of these, but today I'm increasingly turning to their <strong>asynchronous coding agent</strong> family members instead.</p>
<p>An asynchronous coding agent is a coding agent that operates on a fire-and-forget basis. You pose it a task, it churns away on a server somewhere and when it's done it files a pull request against your chosen GitHub repository.</p>
<p>OpenAI's <a href="https://chatgpt.com/codex">Codex Cloud</a>, Anthropic's <a href="https://claude.ai/code">Claude Code for web</a>, Google Gemini's <a href="https://jules.google/">Jules</a>, and GitHub's <a href="https://docs.github.com/en/copilot/concepts/agents/coding-agent/about-coding-agent?utm_source=chatgpt.com">Copilot coding agent</a> are four prominent examples of this pattern.</p>
<p>These are <em>fantastic</em> tools for code research projects. Come up with a clear goal, turn it into a few paragraphs of prompt, set them loose and check back ten minutes later to see what they've come up with.</p>
<p>I'm firing off 2-3 code research projects a day right now. My own time commitment is minimal and they frequently come back with useful or interesting results.</p>
<h4 id="give-them-a-dedicated-github-repository">Give them a dedicated GitHub repository</h4>
<p>You can run a code research task against an existing GitHub repository, but I find it's much more liberating to have a separate, dedicated repository for your coding agents to run their projects in.</p>
<p>This frees you from being limited to research against just code you've already written, and also means you can be much less cautious about what you let the agents do.</p>
<p>I have two repositories that I use for this - one public, one private. I use the public one for research tasks that have no need to be private, and the private one for anything that I'm not yet ready to share with the world.</p>
<h4 id="let-them-rip-with-unlimited-network-access">Let them rip with unlimited network access</h4>
<p>The biggest benefit of a dedicated repository is that you don't need to be cautious about what the agents operating in that repository can do.</p>
<p>Both Codex Cloud and Claude Code for web default to running agents in a locked-down environment, with strict restrictions on how they can access the network. This makes total sense if they are running against sensitive repositories - a prompt injection attack of the <a href="https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/">lethal trifecta</a> variety could easily be used to steal sensitive code or environment variables.</p>
<p>If you're running in a fresh, non-sensitive repository you don't need to worry about this at all! I've configured my research repositories for full network access, which means my coding agents can install any dependencies they need, fetch data from the web and generally do anything I'd be able to do on my own computer.</p>
<h4 id="my-simonw-research-collection">My simonw/research collection</h4>
<p>Let's dive into some examples. My public research repository is at <a href="https://github.com/simonw/research">simonw/research</a> on GitHub. It currently contains 13 folders, each of which is a separate research project. I only created it two weeks ago so I'm already averaging nearly one a day!</p>
<p>It also includes <a href="https://github.com/simonw/research/blob/main/.github/workflows/update-readme.yml">a GitHub Workflow</a> which uses <a href="https://docs.github.com/en/github-models">GitHub Models</a> to automatically update <a href="https://github.com/simonw/research/blob/main/README.md">the README</a> file with a summary of every new project, using <a href="https://cog.readthedocs.io/">Cog</a>, <a href="https://llm.datasette.io/">LLM</a>, <a href="https://github.com/tonybaloney/llm-github-models">llm-github-models</a> and <a href="https://github.com/simonw/research/blob/b059108dfefeb05a48e1c27f7a127dc9fd648129/README.md#L9-L116">this snippet of Python</a>.</p>
<p>Here are a some example research projects from the repo.</p>
<p><strong><a href="https://github.com/simonw/research/tree/main/node-pyodide">node-pyodide</a></strong> shows an example of a <a href="https://github.com/simonw/research/blob/main/node-pyodide/server-simple.js">Node.js script</a> that runs the <a href="https://pyodide.org/">Pyodide</a> WebAssembly distribution of Python inside it - yet another of my <a href="https://simonwillison.net/tags/sandboxing+python/">ongoing attempts</a> to find a great way of running Python in a WebAssembly sandbox on a server.</p>
<p><strong><a href="https://github.com/simonw/research/tree/main/python-markdown-comparison">python-markdown-comparison</a></strong> (<a href="https://gistpreview.github.io/?fb07c2a3fd2d4cfb814a46696a58a00e">transcript</a>) provides a detailed performance benchmark of seven different Python Markdown libraries. I fired this one off because I stumbled across <a href="https://pypi.org/project/cmarkgfm/">cmarkgfm</a>, a Python binding around GitHub's Markdown implementation in C, and wanted to see how it compared to the other options. This one produced some charts! <code>cmarkgfm</code> came out on top by a significant margin:</p>
<p><img src="https://static.simonwillison.net/static/2025/markdown-performance.png" alt="Bar chart titled &quot;Relative Performance vs cmarkgfm (Large Document)&quot; comparing relative speed of markdown libraries, with marko at 52.1x, markdown2 at 16.9x, mistletoe at 14.1x, markdown at 12.9x, commonmark at 12.1x, mistune at 10.0x, and cmarkgfm at 1.0x baseline marked by a red dashed line; x-axis labeled &quot;Relative Speed (lower is better)&quot; ranging from 0 to 50+" style="max-width: 100%;" /></p>
<p>Here's the entire prompt I used for that project:</p>
<blockquote>
<p>Create a performance benchmark and feature comparison report on PyPI cmarkgfm compared to other popular Python markdown libraries - check all of them out from github and read the source to get an idea for features, then design and run a benchmark including generating some charts, then create a report in a new python-markdown-comparison folder (do not create a _summary.md file or edit anywhere outside of that folder). Make sure the performance chart images are directly displayed in the README.md in the folder.</p>
</blockquote>
<p>Note that I didn't specify any Markdown libraries other than <code>cmarkgfm</code> - Claude Code ran a search and found the other six by itself.</p>
<p><strong><a href="https://github.com/simonw/research/tree/main/cmarkgfm-in-pyodide">cmarkgfm-in-pyodide</a></strong> is a lot more fun. A neat thing about having all of my research projects in the same repository is that new projects can build on previous ones. Here I decided to see how hard it would be to get <code>cmarkgfm</code> - which has a C extension - working inside Pyodide inside Node.js. Claude successfully compiled a 88.4KB <code>cmarkgfm_pyodide-2025.10.22-cp312-cp312-emscripten_3_1_46_wasm32.whl</code> file with the necessary C extension and proved it could be loaded into Pyodide in WebAssembly inside of Node.js.</p>
<p>I ran this one using Claude Code on my laptop after an initial attempt failed. The starting prompt was:</p>
<blockquote>
<p>Figure out how to get the cmarkgfm markdown lover <em>[typo in prompt, this should have been "library" but it figured it out anyway]</em> for Python working in pyodide. This will be hard because it uses C so you will need to compile it to pyodide compatible webassembly somehow. Write a report on your results plus code to a new cmarkgfm-in-pyodide directory. Test it using pytest to exercise a node.js test script that calls pyodide as seen in the existing node.js and pyodide directory</p>
<p>There is an existing branch that was an initial attempt at this research, but which failed because it did not have Internet access. You do have Internet access. Use that existing branch to accelerate your work, but do not commit any code unless you are certain that you have successfully executed tests that prove that the pyodide module you created works correctly.</p>
</blockquote>
<p>This one gave up half way through, complaining that emscripten would take too long. I told it:</p>
<blockquote>
<p>Complete this project, actually run emscripten, I do not care how long it takes, update the report if it works</p>
</blockquote>
<p>It churned away for a bit longer and complained that the existing Python library used CFFI which isn't available in Pyodide. I asked it:</p>
<blockquote>
<p>Can you figure out how to rewrite cmarkgfm to not use FFI and to use a pyodide-friendly way of integrating that C code instead?</p>
</blockquote>
<p>... and it did. You can <a href="https://gistpreview.github.io/?6d778a8f9c4c2c005a189ff308c3bc47">see the full transcript here</a>.</p>
<p><strong><a href="https://github.com/simonw/research/tree/main/blog-tags-scikit-learn">blog-tags-scikit-learn</a></strong>. Taking a short break from WebAssembly, I thought it would be fun to put <a href="https://scikit-learn.org/stable/">scikit-learn</a> through its paces on a text classification task against my blog:</p>
<blockquote>
<p>Work in a new folder called blog-tags-scikit-learn</p>
<p>Download <code>https://datasette.simonwillison.net/simonwillisonblog.db</code> - a SQLite database. Take a look at the blog_entry table and the associated tags - a lot of the earlier entries do not have tags associated with them, where the later entries do. Design, implement and execute models to suggests tags for those earlier entries based on textual analysis against later ones</p>
<p>Use Python scikit learn and try several different strategies</p>
<p>Produce JSON of the results for each one, plus scripts for running them and a detailed markdown description</p>
<p>Also include an HTML page with a nice visualization of the results that works by loading those JSON files.</p>
</blockquote>
<p>This resulted in seven <code>.py</code> files, four <code>.json</code> results files and a detailed <a href="https://github.com/simonw/research/blob/main/blog-tags-scikit-learn/README.md">report</a>. (It ignored the bit about an HTML page with a nice visualization for some reason.) Not bad for a few moments of idle curiosity typed into my phone!</p>
<p>That's just three of the thirteen projects in the repository so far. The commit history for each one usually links to the prompt and sometimes the transcript if you want to see how they unfolded.</p>
<p>More recently I added a short <code>AGENTS.md</code> file to the repo with a few extra tips for my research agents. You can <a href="https://github.com/simonw/research/blob/b059108dfefeb05a48e1c27f7a127dc9fd648129/AGENTS.md">read that here</a>.</p>
<h4 id="this-is-total-slop-of-course">This is total slop, of course</h4>
<p>My preferred definition of <a href="https://simonwillison.net/2024/May/8/slop/">AI slop</a> is AI-generated content that is published without human review. I've not been reviewing these reports in great detail myself, and I wouldn't usually publish them online without some serious editing and verification.</p>
<p>I want to share the pattern I'm using though, so I decided to keep them quarantined in this one public <code>simonw/research</code> repository.</p>
<p>A tiny feature request for GitHub: I'd love to be able to mark a repository as "exclude from search indexes" such that it gets labelled with <code>&lt;meta name="robots" content="noindex"&gt;</code> tags. I still like to keep AI-generated content out of search, to avoid contributing more to the <a href="https://en.wikipedia.org/wiki/Dead_Internet_theory">dead internet</a>.</p>
<h4 id="try-it-yourself">Try it yourself</h4>
<p>It's pretty easy to get started trying out this coding agent research pattern. Create a free GitHub repository (public or private) and let some agents loose on it and see what happens.</p>
<p>You can run agents locally but I find the asynchronous agents to be more convenient - especially as I can run them (or trigger them from my phone) without any fear of them damaging my own machine or leaking any of my private data.</p>
<p>Claude Code for web offers <a href="https://support.claude.com/en/articles/12690958-claude-code-promotion">a free $250 of credits</a> for their $20/month users for a limited time (until November 18, 2025). Gemini Jules has <a href="https://jules.google/docs/usage-limits/">a free tier</a>. There are plenty of other coding agents you can try out as well.</p>
<p>Let me know if your research agents come back with anything interesting!</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/slop">slop</a>, <a href="https://simonwillison.net/tags/ai-agents">ai-agents</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/claude-code">claude-code</a>, <a href="https://simonwillison.net/tags/jules">jules</a>, <a href="https://simonwillison.net/tags/codex-cli">codex-cli</a></p>]]></description><pubDate>Thu, 6 Nov 2025 15:53:23 +0000</pubDate></item><item><title>Open redirect endpoint in Datasette prior to 0.65.2 and 1.0a21</title><link>https://simonwillison.net/2025/Nov/5/open-redirect-datasette/#atom-everything</link><description><![CDATA[<p><strong><a href="https://github.com/simonw/datasette/security/advisories/GHSA-w832-gg5g-x44m">Open redirect endpoint in Datasette prior to 0.65.2 and 1.0a21</a></strong></p>
This GitHub security advisory covers two new releases of Datasette that I shipped today, both addressing <a href="https://github.com/simonw/datasette/issues/2429">the same open redirect issue</a> with a fix by <a href="https://github.com/jamesjefferies">James Jefferies</a>.</p>
<p><strong><a href="https://docs.datasette.io/en/stable/changelog.html#v0-65-2">Datasette 0.65.2</a></strong> fixes the bug and also adds Python 3.14 support and a <code>datasette publish cloudrun</code> fix.</p>
<p><strong><a href="https://docs.datasette.io/en/latest/changelog.html#a21-2025-11-05">Datasette 1.0a21</a></strong> also has that Cloud Run fix and two other small new features:</p>
<blockquote>
<ul>
<li>New <code>datasette --get /path --headers</code> option for inspecting the headers returned by a path. (<a href="https://github.com/simonw/datasette/issues/2578">#2578</a>)</li>
<li>New <code>datasette.client.get(..., skip_permission_checks=True)</code> parameter to bypass permission checks when making requests using the internal client. (<a href="https://github.com/simonw/datasette/issues/2583">#2583</a>)</li>
</ul>
</blockquote>
<p>I decided to include the Cloud Run deployment fix so anyone with Datasette instances deployed to Cloud Run can update them with the new patched versions.


    <p>Tags: <a href="https://simonwillison.net/tags/security">security</a>, <a href="https://simonwillison.net/tags/datasette">datasette</a>, <a href="https://simonwillison.net/tags/cloudrun">cloudrun</a>, <a href="https://simonwillison.net/tags/annotated-release-notes">annotated-release-notes</a></p>]]></description><pubDate>Wed, 5 Nov 2025 23:11:17 +0000</pubDate></item><item><title>Removing XSLT for a more secure browser</title><link>https://simonwillison.net/2025/Nov/5/removing-xslt/#atom-everything</link><description><![CDATA[<p><strong><a href="https://developer.chrome.com/docs/web-platform/deprecating-xslt">Removing XSLT for a more secure browser</a></strong></p>
Previously discussed <a href="https://simonwillison.net/2025/Aug/19/xslt/">back in August</a>, it looks like it's now official:</p>
<blockquote>
<p>Chrome intends to deprecate and remove XSLT from the browser. [...] We intend to remove support from version 155 (November 17, 2026). The <a href="https://github.com/mozilla/standards-positions/issues/1287#issuecomment-3227145793">Firefox</a> and <a href="https://github.com/whatwg/html/issues/11523#issuecomment-3149280766">WebKit</a> projects have also indicated plans to remove XSLT from their browser engines. [...]</p>
<p>The continued inclusion of XSLT 1.0 in web browsers presents a significant and unnecessary security risk. The underlying libraries that process these transformations, such as <a href="https://github.com/GNOME/libxslt">libxslt</a> (used by Chromium browsers), are complex, aging C/C++ codebases. This type of code is notoriously susceptible to memory safety vulnerabilities like buffer overflows, which can lead to arbitrary code execution.</p>
</blockquote>
<p>I mostly encounter XSLT on people's Atom/RSS feeds, converting those to a more readable format in case someone should navigate directly to that link. Jake Archibald <a href="https://jakearchibald.com/2025/making-xml-human-readable-without-xslt/">shared an alternative solution to that</a> back in September.

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=45823059">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/browsers">browsers</a>, <a href="https://simonwillison.net/tags/chrome">chrome</a>, <a href="https://simonwillison.net/tags/security">security</a>, <a href="https://simonwillison.net/tags/web-standards">web-standards</a>, <a href="https://simonwillison.net/tags/xml">xml</a>, <a href="https://simonwillison.net/tags/xslt">xslt</a>, <a href="https://simonwillison.net/tags/jake-archibald">jake-archibald</a></p>]]></description><pubDate>Wed, 5 Nov 2025 22:24:57 +0000</pubDate></item><item><title>Quoting Ada James</title><link>https://simonwillison.net/2025/Nov/5/brenda/#atom-everything</link><description><![CDATA[<blockquote cite="http://www.tiktok.com/@belligerentbarbies/video/7568380008633257271"><p>I'm worried that they put co-pilot in Excel because Excel is the beast that drives our entire economy and do you know who has tamed that beast?</p>
<p>Brenda.</p>
<p>Who is Brenda?</p>
<p>She is a mid-level employee in every finance department, in every business across this stupid nation and the Excel goddess herself descended from the heavens, kissed Brenda on her forehead and the sweat from Brenda's brow is what allows us to do capitalism. [...]</p>
<p>She's gonna birth that formula for a financial report and then she's gonna send that financial report to a higher up and he's gonna need to make a change to the report and normally he would have sent it back to Brenda but he's like oh I have AI and AI is probably like smarter than Brenda and then the AI is gonna fuck it up real bad and he won't be able to recognize it because he doesn't understand Excel because AI hallucinates.</p>
<p>You know who's not hallucinating?</p>
<p>Brenda.</p></blockquote>
<p class="cite">&mdash; <a href="http://www.tiktok.com/@belligerentbarbies/video/7568380008633257271">Ada James</a>, @belligerentbarbies on TikTok</p>

    <p>Tags: <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/excel">excel</a>, <a href="https://simonwillison.net/tags/hallucinations">hallucinations</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/tiktok">tiktok</a>, <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a></p>]]></description><pubDate>Wed, 5 Nov 2025 03:50:31 +0000</pubDate></item><item><title>Code execution with MCP: Building more efficient agents</title><link>https://simonwillison.net/2025/Nov/4/code-execution-with-mcp/#atom-everything</link><description><![CDATA[<p><strong><a href="https://www.anthropic.com/engineering/code-execution-with-mcp">Code execution with MCP: Building more efficient agents</a></strong></p>
When I <a href="https://simonwillison.net/2025/Oct/16/claude-skills/">wrote about Claude Skills</a> I mentioned that I don't use MCP at all any more when working with coding agents - I find CLI utilities and libraries like Playwright Python to be a more effective way of achieving the same goals.</p>
<p>This new piece from Anthropic proposes a way to bring the two worlds more closely together.</p>
<p>It identifies two challenges with MCP as it exists today. The first has been widely discussed before: all of those tool descriptions take up a lot of valuable real estate in the agent context even before you start using them.</p>
<p>The second is more subtle but equally interesting: chaining multiple MCP tools together involves passing their responses through the context, absorbing more valuable tokens and introducing chances for the LLM to make additional mistakes.</p>
<p>What if you could turn MCP tools into code functions instead, and then let the LLM wire them together with executable code?</p>
<p>Anthropic's example here imagines a system that turns MCP tools into TypeScript files on disk, looking something like this:</p>
<div class="highlight highlight-source-ts"><pre><span class="pl-c">// ./servers/google-drive/getDocument.ts</span>
<span class="pl-k">interface</span> <span class="pl-smi">GetDocumentInput</span> <span class="pl-kos">{</span>
  <span class="pl-c1">documentId</span>: <span class="pl-smi">string</span><span class="pl-kos">;</span>
<span class="pl-kos">}</span>
<span class="pl-k">interface</span> <span class="pl-smi">GetDocumentResponse</span> <span class="pl-kos">{</span>
  <span class="pl-c1">content</span>: <span class="pl-smi">string</span><span class="pl-kos">;</span>
<span class="pl-kos">}</span>
<span class="pl-c">/* Read a document from Google Drive */</span>
<span class="pl-k">export</span> <span class="pl-k">async</span> <span class="pl-k">function</span> <span class="pl-en">getDocument</span><span class="pl-kos">(</span><span class="pl-s1">input</span>: <span class="pl-smi">GetDocumentInput</span><span class="pl-kos">)</span>: <span class="pl-smi">Promise</span><span class="pl-c1">&lt;</span><span class="pl-smi">GetDocumentResponse</span><span class="pl-c1">&gt;</span> <span class="pl-kos">{</span>
  <span class="pl-k">return</span> <span class="pl-en">callMCPTool</span><span class="pl-c1">&lt;</span><span class="pl-smi">GetDocumentResponse</span><span class="pl-c1">&gt;</span><span class="pl-kos">(</span><span class="pl-s">'google_drive__get_document'</span><span class="pl-kos">,</span> <span class="pl-s1">input</span><span class="pl-kos">)</span><span class="pl-kos">;</span>
<span class="pl-kos">}</span></pre></div>

<p>This takes up no tokens at all - it's a file on disk. In a similar manner to Skills the agent can navigate the filesystem to discover these definitions on demand.</p>
<p>Then it can wire them together by generating code:</p>
<div class="highlight highlight-source-ts"><pre><span class="pl-k">const</span> <span class="pl-s1">transcript</span> <span class="pl-c1">=</span> <span class="pl-kos">(</span><span class="pl-k">await</span> <span class="pl-s1">gdrive</span><span class="pl-kos">.</span><span class="pl-en">getDocument</span><span class="pl-kos">(</span><span class="pl-kos">{</span> <span class="pl-c1">documentId</span>: <span class="pl-s">'abc123'</span> <span class="pl-kos">}</span><span class="pl-kos">)</span><span class="pl-kos">)</span><span class="pl-kos">.</span><span class="pl-c1">content</span><span class="pl-kos">;</span>
<span class="pl-k">await</span> <span class="pl-s1">salesforce</span><span class="pl-kos">.</span><span class="pl-en">updateRecord</span><span class="pl-kos">(</span><span class="pl-kos">{</span>
  <span class="pl-c1">objectType</span>: <span class="pl-s">'SalesMeeting'</span><span class="pl-kos">,</span>
  <span class="pl-c1">recordId</span>: <span class="pl-s">'00Q5f000001abcXYZ'</span><span class="pl-kos">,</span>
  <span class="pl-c1">data</span>: <span class="pl-kos">{</span> <span class="pl-c1">Notes</span>: <span class="pl-s1">transcript</span> <span class="pl-kos">}</span>
<span class="pl-kos">}</span><span class="pl-kos">)</span><span class="pl-kos">;</span></pre></div>

<p>Notably, the example here avoids round-tripping the response from the <code>gdrive.getDocument()</code> call through the model on the way to the <code>salesforce.updateRecord()</code> call - which is faster, more reliable, saves on context tokens, and avoids the model being exposed to any potentially sensitive data in that document.</p>
<p>This all looks very solid to me! I think it's a sensible way to take advantage of the strengths of coding agents and address some of the major drawbacks of MCP as it is usually implemented today.</p>
<p>There's one catch: Anthropic outline the proposal in some detail but provide no code to execute on it! Implementation is left as an exercise for the reader:</p>
<blockquote>
<p>If you implement this approach, we encourage you to share your findings with the <a href="https://modelcontextprotocol.io/community/communication">MCP community</a>.</p>
</blockquote>

    <p><small></small>Via <a href="https://x.com/AnthropicAI/status/1985846791842250860">@AnthropicAI</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/prompt-engineering">prompt-engineering</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/anthropic">anthropic</a>, <a href="https://simonwillison.net/tags/model-context-protocol">model-context-protocol</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a></p>]]></description><pubDate>Tue, 4 Nov 2025 23:56:24 +0000</pubDate></item><item><title>A new SQL-powered permissions system in Datasette 1.0a20</title><link>https://simonwillison.net/2025/Nov/4/datasette-10a20/#atom-everything</link><description><![CDATA[<p><a href="https://docs.datasette.io/en/latest/changelog.html#a20-2025-11-03">Datasette 1.0a20 is out</a> with the biggest breaking API change on the road to 1.0, improving how Datasette's permissions system works by migrating permission logic to SQL running in SQLite. This release involved <a href="https://github.com/simonw/datasette/compare/1.0a19...1.0a20">163 commits</a>, with 10,660 additions and 1,825 deletions, most of which was written with the help of Claude Code.</p>


<ul>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#understanding-the-permissions-system">Understanding the permissions system</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#permissions-systems-need-to-be-able-to-efficiently-list-things">Permissions systems need to be able to efficiently list things</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#the-new-permission-resources-sql-plugin-hook">The new permission_resources_sql() plugin hook</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#hierarchies-plugins-vetoes-and-restrictions">Hierarchies, plugins, vetoes, and restrictions</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#new-debugging-tools">New debugging tools</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#the-missing-feature-list-actors-who-can-act-on-this-resource">The missing feature: list actors who can act on this resource</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#upgrading-plugins-for-datasette-1-0a20">Upgrading plugins for Datasette 1.0a20</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#using-claude-code-to-implement-this-change">Using Claude Code to implement this change</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#starting-with-a-proof-of-concept">Starting with a proof-of-concept</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#miscellaneous-tips-i-picked-up-along-the-way">Miscellaneous tips I picked up along the way</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#what-s-next-">What's next?</a></li>
</ul>

<h4 id="understanding-the-permissions-system">Understanding the permissions system</h4>
<p>Datasette's <a href="https://docs.datasette.io/en/latest/authentication.html">permissions system</a> exists to answer the following question:</p>
<blockquote>
<p>Is this <strong>actor</strong> allowed to perform this <strong>action</strong>, optionally against this particular <strong>resource</strong>?</p>
</blockquote>
<p>An <strong>actor</strong> is usually a user, but might also be an automation operating via the Datasette API.</p>
<p>An <strong>action</strong> is a thing they need to do - things like view-table, execute-sql, insert-row.</p>
<p>A <strong>resource</strong> is the subject of the action - the database you are executing SQL against, the table you want to insert a row into.</p>
<p>Datasette's default configuration is public but read-only: anyone can view databases and tables or execute read-only SQL queries but no-one can modify data.</p>
<p>Datasette plugins can enable all sorts of additional ways to interact with databases, many of which need to be protected by a form of authentication Datasette also 1.0 includes <a href="https://simonwillison.net/2022/Dec/2/datasette-write-api/">a write API</a> with a need to configure who can insert, update, and delete rows or create new tables.</p>
<p>Actors can be authenticated in a number of different ways provided by plugins using the <a href="https://docs.datasette.io/en/latest/plugin_hooks.html#actor-from-request-datasette-request">actor_from_request()</a> plugin hook. <a href="https://datasette.io/plugins/datasette-auth-passwords">datasette-auth-passwords</a> and <a href="https://datasette.io/plugins/datasette-auth-github">datasette-auth-github</a> and <a href="https://datasette.io/plugins/datasette-auth-existing-cookies">datasette-auth-existing-cookies</a> are examples of authentication plugins.</p>
<h4 id="permissions-systems-need-to-be-able-to-efficiently-list-things">Permissions systems need to be able to efficiently list things</h4>
<p>The previous implementation included a design flaw common to permissions systems of this nature: each permission check involved a function call which would delegate to one or more plugins and return a True/False result.</p>
<p>This works well for single checks, but has a significant problem: what if you need to show the user a list of things they can access, for example the tables they can view?</p>
<p>I want Datasette to be able to handle potentially thousands of tables - tables in SQLite are cheap! I don't want to have to run 1,000+ permission checks just to show the user a list of tables.</p>
<p>Since Datasette is built on top of SQLite we already have a powerful mechanism to help solve this problem. SQLite is <em>really</em> good at filtering large numbers of records.</p>
<h4 id="the-new-permission-resources-sql-plugin-hook">The new permission_resources_sql() plugin hook</h4>
<p>The biggest change in the new release is that I've replaced the previous  <code>permission_allowed(actor, action, resource)</code> plugin hook - which let a plugin determine if an actor could perform an action against a resource - with a new <a href="https://docs.datasette.io/en/latest/plugin_hooks.html#plugin-hook-permission-resources-sql">permission_resources_sql(actor, action)</a> plugin hook.</p>
<p>Instead of returning a True/False result, this new hook returns a SQL query that returns rules helping determine the resources the current actor can execute the specified action against.</p>
<p>Here's an example, lifted from the documentation:</p>
<pre><span class="pl-k">from</span> <span class="pl-s1">datasette</span> <span class="pl-k">import</span> <span class="pl-s1">hookimpl</span>
<span class="pl-k">from</span> <span class="pl-s1">datasette</span>.<span class="pl-s1">permissions</span> <span class="pl-k">import</span> <span class="pl-v">PermissionSQL</span>


<span class="pl-en">@<span class="pl-s1">hookimpl</span></span>
<span class="pl-k">def</span> <span class="pl-en">permission_resources_sql</span>(<span class="pl-s1">datasette</span>, <span class="pl-s1">actor</span>, <span class="pl-s1">action</span>):
    <span class="pl-k">if</span> <span class="pl-s1">action</span> <span class="pl-c1">!=</span> <span class="pl-s">"view-table"</span>:
        <span class="pl-k">return</span> <span class="pl-c1">None</span>
    <span class="pl-k">if</span> <span class="pl-c1">not</span> <span class="pl-s1">actor</span> <span class="pl-c1">or</span> <span class="pl-s1">actor</span>.<span class="pl-c1">get</span>(<span class="pl-s">"id"</span>) <span class="pl-c1">!=</span> <span class="pl-s">"alice"</span>:
        <span class="pl-k">return</span> <span class="pl-c1">None</span>

    <span class="pl-k">return</span> <span class="pl-en">PermissionSQL</span>(
        <span class="pl-s1">sql</span><span class="pl-c1">=</span><span class="pl-s">"""</span>
<span class="pl-s">            SELECT</span>
<span class="pl-s">                'accounting' AS parent,</span>
<span class="pl-s">                'sales' AS child,</span>
<span class="pl-s">                1 AS allow,</span>
<span class="pl-s">                'alice can view accounting/sales' AS reason</span>
<span class="pl-s">        """</span>,
    )</pre>
<p>This hook grants the actor with ID "alice" permission to view the "sales" table in the "accounting" database.</p>
<p>The <code>PermissionSQL</code> object should always return four columns: a parent, child, allow (1 or 0), and a reason string for debugging.</p>
<p>When you ask Datasette to list the resources an actor can access for a specific action, it will combine the SQL returned by all installed plugins into a single query that joins against <a href="https://docs.datasette.io/en/latest/internals.html#internal-database-schema">the internal catalog tables</a> and efficiently lists all the resources the actor can access.</p>
<p>This query can then be limited or paginated to avoid loading too many results at once.</p>
<h4 id="hierarchies-plugins-vetoes-and-restrictions">Hierarchies, plugins, vetoes, and restrictions</h4>
<p>Datasette has several additional requirements that make the permissions system more complicated.</p>
<p>Datasette permissions can optionally act against a two-level <strong>hierarchy</strong>. You can grant a user the ability to insert-row against a specific table, or every table in a specific database, or every table in <em>every</em> database in that Datasette instance.</p>
<p>Some actions can apply at the table level, others the database level and others only make sense globally - enabling a new feature that isn't tied to tables or databases, for example.</p>
<p>Datasette currently has <a href="https://docs.datasette.io/en/latest/authentication.html#built-in-actions">ten default actions</a> but <strong>plugins</strong> that add additional features can <a href="https://docs.datasette.io/en/latest/plugin_hooks.html#register-actions-datasette">register new actions</a> to better participate in the permission systems.</p>
<p>Datasette's permission system has a mechanism to <strong>veto</strong> permission checks - a plugin can return a deny for a specific permission check which will override any allows. This needs to be hierarchy-aware - a deny at the database level can be outvoted by an allow at the table level.</p>
<p>Finally, Datasette includes a mechanism for applying additional <strong>restrictions</strong> to a request. This was introduced for Datasette's API - it allows a user to create an API token that can act on their behalf but is only allowed to perform a subset of their capabilities - just reading from two specific tables, for example. Restrictions are <a href="https://docs.datasette.io/en/latest/authentication.html#restricting-the-actions-that-a-token-can-perform">described in more detail</a> in the documentation.</p>
<p>That's a lot of different moving parts for the new implementation to cover.</p>
<h4 id="new-debugging-tools">New debugging tools</h4>
<p>Since permissions are critical to the security of a Datasette deployment it's vital that they are as easy to understand and debug as possible.</p>
<p>The new alpha adds several new debugging tools, including this page that shows the full list of resources matching a specific action for the current user:</p>
<p><img src="https://static.simonwillison.net/static/2025/datasette-allowed-resources.jpg" alt="Allowed resources. Tabs are Playground, Check, Allowed, Rules, Actions, Allow debug. There is a form where you can select an action (here view-table) and optionally filter by parent and child. Below is a table of results listing resource paths - e.g. /fixtures/name-of-table - plus parent, child and reason columns. The reason is a JSON list for example &quot;datasette.default_permissions: root user&quot;,&quot;datasette.default_permissions: default allow for view-table&quot;." style="max-width: 100%;" /></p>
<p>And this page listing the <em>rules</em> that apply to that question - since different plugins may return different rules which get combined together:</p>
<p><img src="https://static.simonwillison.net/static/2025/datasette-rules.jpg" alt="The rules tab for the same view-table question. Here there are two allow rules - one from datasette.default_permissions for the root user and another from default_permissions labelled default allow for view-table." style="max-width: 100%;" /></p>
<p>This screenshot illustrates two of Datasette's built-in rules: there is a default allow for read-only operations such as view-table (which can be over-ridden by plugins) and another rule that says the root user can do anything (provided Datasette was started with the <code>--root</code> option.)</p>
<p>Those rules are defined in the <a href="https://github.com/simonw/datasette/blob/1.0a20/datasette/default_permissions.py">datasette/default_permissions.py</a> Python module.</p>
<h4 id="the-missing-feature-list-actors-who-can-act-on-this-resource">The missing feature: list actors who can act on this resource</h4>
<p>There's one question that the new system cannot answer: provide a full list of actors who can perform this action against this resource.</p>
<p>It's not possibly to provide this globally for Datasette because Datasette doesn't have a way to track what "actors" exist in the system. SSO plugins such as <code>datasette-auth-github</code> mean a new authenticated GitHub user might show up at any time, with the ability to perform actions despite the Datasette system never having encountered that particular username before.</p>
<p>API tokens and actor restrictions come into play here as well. A user might create a signed API token that can perform a subset of actions on their behalf - the existence of that token can't be predicted by the permissions system.</p>
<p>This is a notable omission, but it's also quite common in other systems. AWS cannot provide a list of all actors who have permission to access a specific S3 bucket, for example - presumably for similar reasons.</p>
<h4 id="upgrading-plugins-for-datasette-1-0a20">Upgrading plugins for Datasette 1.0a20</h4>
<p>Datasette's plugin ecosystem is the reason I'm paying so much attention to ensuring Datasette 1.0 has a stable API. I don't want plugin authors to need to chase breaking changes once that 1.0 release is out.</p>
<p>The <a href="https://docs.datasette.io/en/latest/upgrade_guide.html">Datasette upgrade guide</a> includes detailed notes on upgrades that are needed between the 0.x and 1.0 alpha releases. I've added an extensive section about the permissions changes to that document.</p>
<p>I've also been experimenting with dumping those instructions directly into coding agent tools - Claude Code and Codex CLI - to have them upgrade existing plugins for me. This has been working <em>extremely well</em>. I've even had Claude Code <a href="https://github.com/simonw/datasette/commit/fa978ec1006297416e2cd87a2f0d3cac99283cf8">update those notes itself</a> with things it learned during an upgrade process!</p>
<p>This is greatly helped by the fact that every single Datasette plugin has an automated test suite that demonstrates the core functionality works as expected. Coding agents can use those tests to verify that their changes have had the desired effect.</p>
<p>I've also been leaning heavily on <code>uv</code> to help with the upgrade process. I wrote myself two new helper scripts - <code>tadd</code> and <code>radd</code> - to help test the new plugins.</p>
<ul>
<li>
<code>tadd</code> = "test against datasette dev" - it runs a plugin's existing test suite against the current development version of Datasette checked out on my machine. It passes extra options through to <code>pytest</code> so I can run <code>tadd -k test_name</code> or <code>tadd -x --pdb</code> as needed.</li>
<li>
<code>radd</code> = "run against datasette dev" - it runs the latest dev <code>datasette</code> command with the plugin installed.</li>
</ul>
<p>The <code>tadd</code> and <code>radd</code> implementations <a href="https://til.simonwillison.net/python/uv-tests#variants-tadd-and-radd">can be found in this TIL</a>.</p>
<p>Some of my plugin upgrades have become a one-liner to the <code>codex exec</code> command, which runs OpenAI Codex CLI with a prompt without entering interactive mode:</p>
<div class="highlight highlight-source-shell"><pre>codex <span class="pl-c1">exec</span> --dangerously-bypass-approvals-and-sandbox \
<span class="pl-s"><span class="pl-pds">"</span>Run the command tadd and look at the errors and then</span>
<span class="pl-s">read ~/dev/datasette/docs/upgrade-1.0a20.md and apply</span>
<span class="pl-s">fixes and run the tests again and get them to pass<span class="pl-pds">"</span></span></pre></div>
<p>There are still a bunch more to go - there's <a href="https://github.com/simonw/datasette/issues/2577">a list in this tracking issue</a> - but I expect to have the plugins I maintain all upgraded pretty quickly now that I have a solid process in place.</p>
<h4 id="using-claude-code-to-implement-this-change">Using Claude Code to implement this change</h4>
<p>This change to Datasette core <em>by far</em> the most ambitious piece of work I've ever attempted using a coding agent.</p>
<p>Last year I agreed with the prevailing opinion that LLM assistance was much more useful for greenfield coding tasks than working on existing codebases. The amount you could usefully get done was greatly limited by the need to fit the entire codebase into the model's context window.</p>
<p>Coding agents have entirely changed that calculation. Claude Code and Codex CLI still have relatively limited token windows - albeit larger than last year - but their ability to search through the codebase, read extra files on demand and "reason" about the code they are working with has made them vastly more capable.</p>
<p>I no longer see codebase size as a limiting factor for how useful they can be.</p>
<p>I've also spent enough time with Claude Sonnet 4.5 to build a weird level of trust in it. I can usually predict exactly what changes it will make for a prompt. If I tell it "extract this code into a separate function" or "update every instance of this pattern" I know it's likely to get it right.</p>
<p>For something like permission code I still review everything it does, often by watching it as it works since it displays diffs in the UI.</p>
<p>I also pay extremely close attention to the tests it's writing. Datasette 1.0a19 already had 1,439 tests, many of which exercised the existing permission system. 1.0a20 increases that to 1,583 tests. I feel very good about that, especially since most of the existing tests continued to pass without modification.</p>
<h4 id="starting-with-a-proof-of-concept">Starting with a proof-of-concept</h4>
<p>I built several different proof-of-concept implementations of SQL permissions before settling on the final design. My <a href="https://github.com/simonw/research/tree/main/sqlite-permissions-poc">research/sqlite-permissions-poc</a> project was the one that finally convinced me of a viable approach,</p>
<p>That one started as a <a href="https://claude.ai/share/8fd432bc-a718-4883-9978-80ab82a75c87">free ranging conversation with Claude</a>, at the end of which I told it to generate a specification which I then <a href="https://chatgpt.com/share/68f6532f-9920-8006-928a-364e15b6e9ef">fed into GPT-5</a> to implement. You can see that specification <a href="https://github.com/simonw/research/tree/main/sqlite-permissions-poc#original-prompt">at the end of the README</a>.</p>
<p>I later fed the POC itself into Claude Code and had it implement the first version of the new Datasette system based on that previous experiment.</p>
<p>This is admittedly a very weird way of working, but it helped me finally break through on a problem that I'd been struggling with for months.</p>
<h4 id="miscellaneous-tips-i-picked-up-along-the-way">Miscellaneous tips I picked up along the way</h4>
<ul>
<li>When working on anything relating to plugins it's vital to have at least a few real plugins that you upgrade in lock-step with the core changes. The <code>tadd</code> and <code>radd</code> shortcuts were invaluable for productively working on those plugins while I made changes to core.</li>
<li>Coding agents make experiments <em>much</em> cheaper. I threw away so much code on the way to the final implementation, which was psychologically easier because the cost to create that code in the first place was so low.</li>
<li>Tests, tests, tests. This project would have been impossible without that existing test suite. The additional tests we built along the way give me confidence that the new system is as robust as I need it to be.</li>
<li>Claude writes good commit messages now! I finally gave in and let it write these - previously I've been determined to write them myself. It's a big time saver to be able to say "write a tasteful commit message for these changes".</li>
<li>Claude is also great at breaking up changes into smaller commits. It can also productively rewrite history to make it easier to follow, especially useful if you're still working in a branch.</li>
<li>A really great way to review Claude's changes is with the GitHub PR interface. You can attach comments to individual lines of code and then later prompt Claude like this: <code>Use gh CLI to fetch comments on URL-to-PR and make the requested changes</code>. This is a very quick way to apply little nitpick changes - rename this function, refactor this repeated code, add types here etc.</li>
<li>The code I write with LLMs is <em>higher quality code</em>. I usually find myself making constant trade-offs while coding: this function would be neater if I extracted this helper, it would be nice to have inline documentation here, this changing this would be good but would break a dozen tests... for each of those I have to determine if the additional time is worth the benefit. Claude can apply changes so much faster than me that these calculations have changed - almost any improvement is worth applying, no matter how trivial, because the time cost is so low.</li>
<li>Internal tools are cheap now. The new debugging interfaces were mostly written by Claude and are significantly nicer to use and look at than the hacky versions I would have knocked out myself, if I had even taken the extra time to build them.</li>
<li>That trick with a Markdown file full of upgrade instructions works astonishingly well - it's the same basic idea as <a href="https://simonwillison.net/2025/Oct/16/claude-skills/">Claude Skills</a>. I maintain over 100 Datasette plugins now and I expect I'll be automating all sorts of minor upgrades in the future using this technique.</li>
</ul>
<h4 id="what-s-next-">What's next?</h4>
<p>Now that the new alpha is out my focus is upgrading the existing plugin ecosystem to use it, and supporting other plugin authors who are doing the same.</p>
<p>The new permissions system unlocks some key improvements to Datasette Cloud concerning finely-grained permissions for larger teams, so I'll be integrating the new alpha there this week.</p>
<p>This is the single biggest backwards-incompatible change required before Datasette 1.0. I plan to apply the lessons I learned from this project to the other, less intimidating changes. I'm hoping this can result in a final 1.0 release before the end of the year!</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/plugins">plugins</a>, <a href="https://simonwillison.net/tags/projects">projects</a>, <a href="https://simonwillison.net/tags/python">python</a>, <a href="https://simonwillison.net/tags/sql">sql</a>, <a href="https://simonwillison.net/tags/sqlite">sqlite</a>, <a href="https://simonwillison.net/tags/datasette">datasette</a>, <a href="https://simonwillison.net/tags/annotated-release-notes">annotated-release-notes</a>, <a href="https://simonwillison.net/tags/uv">uv</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/claude-code">claude-code</a>, <a href="https://simonwillison.net/tags/codex-cli">codex-cli</a></p>]]></description><pubDate>Tue, 4 Nov 2025 21:34:42 +0000</pubDate></item><item><title>MCP Colors: Systematically deal with prompt injection risk</title><link>https://simonwillison.net/2025/Nov/4/mcp-colors/#atom-everything</link><description><![CDATA[<p><strong><a href="https://timkellogg.me/blog/2025/11/03/colors">MCP Colors: Systematically deal with prompt injection risk</a></strong></p>
Tim Kellogg proposes a neat way to think about prompt injection, especially with respect to MCP tools.</p>
<p>Classify every tool with a color: red if it exposes the agent to untrusted (potentially malicious) instructions, blue if it involves a "critical action" - something you would not want an attacker to be able to trigger.</p>
<p>This means you can configure your agent to actively avoid mixing the two colors at once:</p>
<blockquote>
<p>The Chore: Go label every data input, and<strong>every tool</strong>(especially MCP tools). For MCP tools &amp; resources, you can use the_metaobject to keep track of the color. The agent can decide at runtime (or earlier) if its gotten into an unsafe state.</p>
<p>Personally, I like to automate. I needed to label ~200 tools, so I put them in a spreadsheet and used an LLM to label them. That way, I could focus on being<strong>precise and clear</strong>about my criteria for what constitutes red, blue or neither. That way I ended up with an artifact that scales beyond my initial set of tools.</p>
</blockquote>

    <p><small></small>Via <a href="https://bsky.app/profile/timkellogg.me/post/3m4ridhi3ps25">@timkellogg.me</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/security">security</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/prompt-injection">prompt-injection</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/model-context-protocol">model-context-protocol</a></p>]]></description><pubDate>Tue, 4 Nov 2025 16:52:21 +0000</pubDate></item><item><title>Quoting Steve Francia</title><link>https://simonwillison.net/2025/Nov/4/steve-francia/#atom-everything</link><description><![CDATA[<blockquote cite="https://spf13.com/p/the-hidden-conversation/"><p>Every time an engineer evaluates a language that isnt theirs, their brain is literally working against them. Theyre not just analyzing technical trade offs, theyre contemplating a version of themselves that doesnt exist yet, that feels threatening to the version that does. The Python developer reads case studies about Gos performance and their amygdala quietly marks each one as a threat to be neutralized. The Rust advocate looks at identical problems and their Default Mode Network constructs narratives about why only Rust can solve them.</p>
<p>Were not lying. We genuinely believe our reasoning is sound. Thats what makes identity based thinking so expensive, and so invisible.</p></blockquote>
<p class="cite">&mdash; <a href="https://spf13.com/p/the-hidden-conversation/">Steve Francia</a>, Why Engineers Can't Be Rational About Programming Languages</p>

    <p>Tags: <a href="https://simonwillison.net/tags/technical-debt">technical-debt</a>, <a href="https://simonwillison.net/tags/psychology">psychology</a>, <a href="https://simonwillison.net/tags/programming-languages">programming-languages</a></p>]]></description><pubDate>Tue, 4 Nov 2025 02:54:07 +0000</pubDate></item><item><title>The fetch()ening</title><link>https://simonwillison.net/2025/Nov/3/htmx-the-fetchening/#atom-everything</link><description><![CDATA[<p><strong><a href="https://htmx.org/essays/the-fetchening/">The fetch()ening</a></strong></p>
After several years of stable htmx 2.0 and a promise to never release a backwards-incompatible htmx 3 Carson Gross is technically keeping that promise... by skipping to htmx 4 instead!</p>
<p>The main reason is to replace <code>XMLHttpRequest</code> with <code>fetch()</code> - a change that will have enough knock-on compatibility effects to require a major version bump - so they're using that as an excuse to clean up various other accumulated design warts at the same time.</p>
<p>htmx is a <em>very</em> responsibly run project. Here's their plan for the upgrade:</p>
<blockquote>
<p>That said, htmx 2.0 users <em>will</em> face an upgrade project when moving to 4.0 in a way that they did not have to in moving from 1.0 to 2.0.</p>
<p>I am sorry about that, and want to offer three things to address it:</p>
<ul>
<li>htmx 2.0 (like htmx 1.0 &amp; intercooler.js 1.0) will be supported <em>in perpetuity</em>, so there is absolutely <em>no</em> pressure to upgrade your application: if htmx 2.0 is satisfying your hypermedia needs, you can stick with it.</li>
<li>We will create extensions that revert htmx 4 to htmx 2 behaviors as much as is feasible (e.g. Supporting the old implicit attribute inheritance model, at least)</li>
<li>We will roll htmx 4.0 out slowly, over a multi-year period. As with the htmx 1.0 -&gt; 2.0 upgrade, there will be a long period where htmx 2.x is <code>latest</code> and htmx 4.x is <code>next</code></li>
</ul>
</blockquote>
<p>There are lots of neat details in here about the design changes they plan to make. It's a really great piece of technical writing - I learned a bunch about htmx and picked up some good notes on API design in general from this.

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=45803358">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/html">html</a>, <a href="https://simonwillison.net/tags/javascript">javascript</a>, <a href="https://simonwillison.net/tags/open-source">open-source</a>, <a href="https://simonwillison.net/tags/htmx">htmx</a>, <a href="https://simonwillison.net/tags/carson-gross">carson-gross</a></p>]]></description><pubDate>Mon, 3 Nov 2025 21:39:54 +0000</pubDate></item><item><title>Quoting Barry Warsaw</title><link>https://simonwillison.net/2025/Nov/3/barry-warsaw/#atom-everything</link><description><![CDATA[<blockquote cite="https://discuss.python.org/t/pep-810-explicit-lazy-imports/104131/465"><p>Dear PEP 810 authors. The Steering Council is happy to unanimously accept "<a href="https://peps.python.org/pep-0810/">PEP 810, Explicit lazy imports</a>". Congratulations! We appreciate the way you were able to build on and improve the previously discussed (and rejected) attempt at lazy imports as proposed in <a href="https://peps.python.org/pep-0690/">PEP 690</a>.</p></blockquote>
<p class="cite">&mdash; <a href="https://discuss.python.org/t/pep-810-explicit-lazy-imports/104131/465">Barry Warsaw</a>, on behalf of the Python Steering Council</p>

    <p>Tags: <a href="https://simonwillison.net/tags/python">python</a>, <a href="https://simonwillison.net/tags/barry-warsaw">barry-warsaw</a></p>]]></description><pubDate>Mon, 3 Nov 2025 21:27:08 +0000</pubDate></item><item><title>The case against pgvector</title><link>https://simonwillison.net/2025/Nov/3/the-case-against-pgvector/#atom-everything</link><description><![CDATA[<p><strong><a href="https://alex-jacobs.com/posts/the-case-against-pgvector/">The case against pgvector</a></strong></p>
I wasn't keen on the title of this piece but the content is great: Alex Jacobs talks through lessons learned trying to run the popular pgvector PostgreSQL vector indexing extension at scale, in particular the challenges involved in maintaining a large index with close-to-realtime updates using the IVFFlat or HNSW index types.</p>
<p>The section on pre-v.s.-post filtering is particularly useful:</p>
<blockquote>
<p>Okay but let's say you solve your index and insert problems. Now you have a document search system with millions of vectors. Documents have metadata---maybe they're marked as <code>draft</code>, <code>published</code>, or <code>archived</code>. A user searches for something, and you only want to return published documents.</p>
<p>[...] should Postgres filter on status first (pre-filter) or do the vector search first and then filter (post-filter)?</p>
<p>This seems like an implementation detail. Its not. Its the difference between queries that take 50ms and queries that take 5 seconds. Its also the difference between returning the most relevant results and not.</p>
</blockquote>
<p>The <a href="https://news.ycombinator.com/item?id=45798479">Hacker News thread</a> for this article attracted a robust discussion, including some fascinating comments by Discourse developer Rafael dos Santos Silva (xfalcox) about how they are using pgvector at scale:</p>
<blockquote>
<p>We [run pgvector in production] at Discourse, in thousands of databases, and it's leveraged in most of the billions of page views we serve. [...]</p>
<p>Also worth mentioning that we use quantization extensively:</p>
<ul>
<li>halfvec (16bit float) for storage - bit (binary vectors) for indexes</li>
</ul>
<p>Which makes the storage cost and on-going performance good enough that we could enable this in all our hosting. [...]</p>
<p>In Discourse embeddings power:</p>
<ul>
<li>Related Topics, a list of topics to read next, which uses embeddings of the current topic as the key to search for similar ones</li>
<li>Suggesting tags and categories when composing a new topic</li>
<li>Augmented search</li>
<li>RAG for uploaded files</li>
</ul>
</blockquote>

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=45798479">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/postgresql">postgresql</a>, <a href="https://simonwillison.net/tags/scaling">scaling</a>, <a href="https://simonwillison.net/tags/vector-search">vector-search</a>, <a href="https://simonwillison.net/tags/embeddings">embeddings</a></p>]]></description><pubDate>Mon, 3 Nov 2025 20:26:10 +0000</pubDate></item><item><title>Quoting MiniMax</title><link>https://simonwillison.net/2025/Nov/3/minimax/#atom-everything</link><description><![CDATA[<blockquote cite="https://x.com/minimax__ai/status/1985375617622454566"><p><strong>Interleaved thinking</strong> is essential for LLM agents: it means alternating between explicit reasoning and tool use, while carrying that reasoning forward between steps.This process significantly enhances <strong>planning, selfcorrection, and reliability</strong> in long workflows. [...]</p>
<p>From community feedback, we've often observed failures to preserve prior-round thinking state across multi-turn interactions with M2. The root cause is that the widely-used <strong>OpenAI Chat Completion API does not support passing reasoning content back in subsequent requests</strong>. Although the Anthropic API natively supports this capability, the community has provided less support for models beyond Claude, and many applications still omit passing back the previous turns' thinking in their Anthropic API implementations. This situation has resulted in poor support for Interleaved Thinking for new models. <strong>To fully unlock M2's capabilities, preserving the reasoning process across multi-turn interactions is essential</strong>.</p></blockquote>
<p class="cite">&mdash; <a href="https://x.com/minimax__ai/status/1985375617622454566">MiniMax</a>, Interleaved Thinking Unlocks Reliable MiniMax-M2 Agentic Capability</p>

    <p>Tags: <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai-agents">ai-agents</a>, <a href="https://simonwillison.net/tags/llm-reasoning">llm-reasoning</a>, <a href="https://simonwillison.net/tags/definitions">definitions</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/ai-in-china">ai-in-china</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/minimax">minimax</a></p>]]></description><pubDate>Mon, 3 Nov 2025 17:24:39 +0000</pubDate></item><item><title>New prompt injection papers: Agents Rule of Two and The Attacker Moves Second</title><link>https://simonwillison.net/2025/Nov/2/new-prompt-injection-papers/#atom-everything</link><description><![CDATA[<p>Two interesting new papers regarding LLM security and prompt injection came to my attention this weekend.</p>
<h4 id="agents-rule-of-two-a-practical-approach-to-ai-agent-security">Agents Rule of Two: A Practical Approach to AI Agent Security</h4>
<p>The first is <a href="https://ai.meta.com/blog/practical-ai-agent-security/">Agents Rule of Two: A Practical Approach to AI Agent Security</a>, published on October 31st on the Meta AI blog. It doesn't list authors but it was <a href="https://x.com/MickAyzenberg/status/1984355145917088235">shared on Twitter</a> by Meta AI security researcher Mick Ayzenberg.</p>
<p>It proposes a "Rule of Two" that's inspired by both my own <a href="https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/">lethal trifecta</a> concept and the Google Chrome team's <a href="https://chromium.googlesource.com/chromium/src/+/main/docs/security/rule-of-2.md">Rule Of 2</a> for writing code that works with untrustworthy inputs:</p>
<blockquote>
<p>At a high level, the Agents Rule of Two states that until robustness research allows us to reliably detect and refuse prompt injection, agents <strong>must satisfy no more than two</strong> of the following three properties within a session to avoid the highest impact consequences of prompt injection.</p>
<p><strong>[A]</strong> An agent can process untrustworthy inputs</p>
<p><strong>[B]</strong> An agent can have access to sensitive systems or private data</p>
<p><strong>[C]</strong> An agent can change state or communicate externally</p>
<p>It's still possible that all three properties are necessary to carry out a request. If an agent requires all three without starting a new session (i.e., with a fresh context window), then the agent should not be permitted to operate autonomously and at a minimum requires supervision --- via human-in-the-loop approval or another reliable means of validation.</p>
</blockquote>
<p>It's accompanied by this handy diagram:</p>
<p><img src="https://static.simonwillison.net/static/2025/agents-rule-of-two-updated.jpg" alt="Venn diagram titled &quot;Choose Two&quot; showing three overlapping circles labeled A, B, and C. Circle A (top): &quot;Process untrustworthy inputs&quot; with description &quot;Externally authored data may contain prompt injection attacks that turn an agent malicious.&quot; Circle B (bottom left): &quot;Access to sensitive systems or private data&quot; with description &quot;This includes private user data, company secrets, production settings and configs, source code, and other sensitive data.&quot; Circle C (bottom right): &quot;Change state or communicate externally&quot; with description &quot;Overwrite or change state through write actions, or transmitting data to a threat actor through web requests or tool calls.&quot; The two-way overlaps between circles are labeled &quot;Lower risk&quot; while the center where all three circles overlap is labeled &quot;Danger&quot;." style="max-width: 100%;" /></p>
<p>I like this <em>a lot</em>.</p>
<p>I've spent several years now trying to find clear ways to explain the risks of prompt injection attacks to developers who are building on top of LLMs. It's frustratingly difficult.</p>
<p>I've had the most success with the lethal trifecta, which boils one particular class of prompt injection attack down to a simple-enough model: if your system has access to private data, exposure to untrusted content and a way to communicate externally then it's vulnerable to private data being stolen.</p>
<p>The one problem with the lethal trifecta is that it only covers the risk of data exfiltration: there are plenty of other, even nastier risks that arise from prompt injection attacks against LLM-powered agents with access to tools which the lethal trifecta doesn't cover.</p>
<p>The Agents Rule of Two neatly solves this, through the addition of "changing state" as a property to consider. This brings other forms of tool usage into the picture: anything that can change state triggered by untrustworthy inputs is something to be very cautious about.</p>
<p>It's also refreshing to see another major research lab concluding that prompt injection remains an unsolved problem, and attempts to block or filter them have not proven reliable enough to depend on. The current solution is to design systems with this in mind, and the Rule of Two is a solid way to think about that.</p>
<p id="exception"><strong>Update</strong>: On thinking about this further there's one aspect of the Rule of Two model that doesn't work for me: the Venn diagram above marks the combination of untrustworthy inputs and the ability to change state as "safe", but that's not right. Even without access to private systems or sensitive data that pairing can still produce harmful results. Unfortunately adding an exception for that pair undermines the simplicity of the "Rule of Two" framing!</p>
<p id="update-2"><strong>Update 2</strong>: Mick Ayzenberg responded to this note in <a href="https://news.ycombinator.com/item?id=45794245#45802448">a comment on Hacker News</a>:</p>
<blockquote>
<p>Thanks for the feedback! One small bit of clarification, the framework would describe access to any sensitive system as part of the [B] circle, not only private systems or private data.</p>
<p>The intention is that an agent that has removed [B] can write state and communicate freely, but not with any systems that matter (wrt critical security outcomes for its user). An example of an agent in this state would be one that can take actions in a tight sandbox or is isolated from production.</p>
</blockquote>
<p>The Meta team also <a href="https://news.ycombinator.com/item?id=45794245#45802046">updated their post</a> to replace "safe" with "lower risk" as the label on the intersections between the different circles. I've updated my screenshots of their diagrams in this post, <a href="https://static.simonwillison.net/static/2025/agents-rule-of-two.jpg">here's the original</a> for comparison.</p>
<p>Which brings me to the second paper...</p>
<h4 id="the-attacker-moves-second-stronger-adaptive-attacks-bypass-defenses-against-llm-jailbreaks-and-prompt-injections">The Attacker Moves Second: Stronger Adaptive Attacks Bypass Defenses Against LLM Jailbreaks and Prompt Injections</h4>
<p>This paper is dated 10th October 2025 <a href="https://arxiv.org/abs/2510.09023">on Arxiv</a> and comes from a heavy-hitting team of 14 authors - Milad Nasr, Nicholas Carlini, Chawin Sitawarin, Sander V. Schulhoff, Jamie Hayes, Michael Ilie, Juliette Pluto, Shuang Song, Harsh Chaudhari, Ilia Shumailov, Abhradeep Thakurta, Kai Yuanqing Xiao, Andreas Terzis, Florian Tramr - including representatives from OpenAI, Anthropic, and Google DeepMind.</p>
<p>The paper looks at 12 published defenses against prompt injection and jailbreaking and subjects them to a range of "adaptive attacks" - attacks that are allowed to expend considerable effort iterating multiple times to try and find a way through.</p>
<p>The defenses did not fare well:</p>
<blockquote>
<p>By systematically tuning and scaling general optimization techniquesgradient descent, reinforcement learning, random search, and human-guided explorationwe bypass 12 recent defenses (based on a diverse set of techniques) with attack success rate above 90% for most; importantly, the majority of defenses originally reported near-zero attack success rates.</p>
</blockquote>
<p>Notably the "Human red-teaming setting" scored 100%, defeating all defenses. That red-team consisted of 500 participants in an online competition they ran with a $20,000 prize fund.</p>
<p>The key point of the paper is that static example attacks - single string prompts designed to bypass systems - are an almost useless way to evaluate these defenses. Adaptive attacks are far more powerful, as shown by this chart:</p>
<p><img src="https://static.simonwillison.net/static/2025/attack-success-rate.jpg" alt="Bar chart showing Attack Success Rate (%) for various security systems across four categories: Prompting, Training, Filtering Model, and Secret Knowledge. The chart compares three attack types shown in the legend: Static / weak attack (green hatched bars), Automated attack (ours) (orange bars), and Human red-teaming (ours) (purple dotted bars). Systems and their success rates are: Spotlighting (28% static, 99% automated), Prompt Sandwich (21% static, 95% automated), RPO (0% static, 99% automated), Circuit Breaker (8% static, 100% automated), StruQ (62% static, 100% automated), SeqAlign (5% static, 96% automated), ProtectAI (15% static, 90% automated), PromptGuard (26% static, 94% automated), PIGuard (0% static, 71% automated), Model Armor (0% static, 90% automated), Data Sentinel (0% static, 80% automated), MELON (0% static, 89% automated), and Human red-teaming setting (0% static, 100% human red-teaming)." style="max-width: 100%;" /></p>
<p>The three automated adaptive attack techniques used by the paper are:</p>
<ul>
<li>
<strong>Gradient-based methods</strong> - these were the least effective, using the technique described in the legendary <a href="https://arxiv.org/abs/2307.15043">Universal and Transferable Adversarial Attacks on Aligned Language Models</a> paper <a href="https://simonwillison.net/2023/Jul/27/universal-and-transferable-attacks-on-aligned-language-models/">from 2023</a>.</li>
<li>
<strong>Reinforcement learning methods</strong> - particularly effective against black-box models: "we allowed the attacker model to interact directly with the defended system and observe its outputs", using 32 sessions of 5 rounds each.</li>
<li>
<strong>Search-based methods</strong> - generate candidates with an LLM, then evaluate and further modify them using LLM-as-judge and other classifiers.</li>
</ul>
<p>The paper concludes somewhat optimistically:</p>
<blockquote>
<p>[...] Adaptive evaluations are therefore more challenging to perform,
making it all the more important that they are performed. We again urge defense authors to release simple, easy-to-prompt defenses that are amenable to human analysis. [...] Finally, we hope that our analysis here will increase the standard for defense evaluations, and in so doing, increase the likelihood that reliable jailbreak and prompt injection defenses will be developed.</p>
</blockquote>
<p>Given how totally the defenses were defeated, I do not share their optimism that reliable defenses will be developed any time soon.</p>
<p>As a review of how far we still have to go this paper packs a powerful punch. I think it makes a strong case for Meta's Agents Rule of Two as the best practical advice for building secure LLM-powered agent systems today in the absence of prompt injection defenses we can rely on.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/definitions">definitions</a>, <a href="https://simonwillison.net/tags/security">security</a>, <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/prompt-injection">prompt-injection</a>, <a href="https://simonwillison.net/tags/anthropic">anthropic</a>, <a href="https://simonwillison.net/tags/nicholas-carlini">nicholas-carlini</a>, <a href="https://simonwillison.net/tags/paper-review">paper-review</a>, <a href="https://simonwillison.net/tags/lethal-trifecta">lethal-trifecta</a></p>]]></description><pubDate>Sun, 2 Nov 2025 23:09:33 +0000</pubDate></item><item><title>PyCon US 2026 call for proposals is now open</title><link>https://simonwillison.net/2025/Nov/2/pycon-us-2026/#atom-everything</link><description><![CDATA[<p><strong><a href="https://pycon.blogspot.com/2025/10/pycon-us-2026-call-for-proposals-now.html">PyCon US 2026 call for proposals is now open</a></strong></p>
PyCon US is coming to the US west coast! 2026 and 2027 will both be held in Long Beach, California - the 2026 conference is set for May 13th-19th next year.</p>
<p>The call for proposals just opened. Since we'll be in LA County I'd love to see talks about Python in the entertainment industry - if you know someone who could present on that topic please make sure they know about the CFP!</p>
<p>The deadline for submissions is December 19th 2025. There are two new tracks this year:</p>
<blockquote>
<p>PyCon US is introducing two dedicated Talk tracks to the schedule this year, "The Future of AI with Python" and "Trailblazing Python Security". For more information and how to submit your proposal, <a href="https://us.pycon.org/2026/speaking/guidelines/">visit this page</a>.</p>
</blockquote>
<p>Now is also a great time to consider sponsoring PyCon - here's <a href="https://s3.dualstack.us-east-2.amazonaws.com/pythondotorg-assets/media/files/psf_sponsor_prospectus_25-26_final_compressed.pdf">the sponsorship prospectus</a>.

    <p><small></small>Via <a href="https://bsky.app/profile/pycon.us/post/3m4j34eloes25">@pycon.us</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/call-for-proposals">call-for-proposals</a>, <a href="https://simonwillison.net/tags/conferences">conferences</a>, <a href="https://simonwillison.net/tags/pycon">pycon</a>, <a href="https://simonwillison.net/tags/python">python</a>, <a href="https://simonwillison.net/tags/psf">psf</a></p>]]></description><pubDate>Sun, 2 Nov 2025 19:22:46 +0000</pubDate></item><item><title>How I Use Every Claude Code Feature</title><link>https://simonwillison.net/2025/Nov/2/how-i-use-every-claude-code-feature/#atom-everything</link><description><![CDATA[<p><strong><a href="https://blog.sshh.io/p/how-i-use-every-claude-code-feature">How I Use Every Claude Code Feature</a></strong></p>
Useful, detailed guide from Shrivu Shankar, a Claude Code power user. Lots of tips for both individual Claude Code usage and configuring it for larger team projects.</p>
<p>I appreciated Shrivu's take on MCP:</p>
<blockquote>
<p>The "Scripting" model (now formalized by Skills) is better, but it needs a secure way to access the environment. This to me is the new, more focused role for MCP.</p>
<p>Instead of a bloated API, an MCP should be a simple, secure gateway that provides a few powerful, high-level tools:</p>
<ul>
<li><code>download_raw_data(filters...)</code></li>
<li><code>take_sensitive_gated_action(args...)</code></li>
<li><code>execute_code_in_environment_with_state(code...)</code></li>
</ul>
<p>In this model, MCP's job isn't to abstract reality for the agent; its job is to manage the auth, networking, and security boundaries and then get out of the way.</p>
</blockquote>
<p>This makes a lot of sense to me. Most of my MCP usage with coding agents like Claude Code has been replaced by custom shell scripts for it to execute, but there's still a useful role for MCP in helping the agent access secure resources in a controlled way.

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=45786738">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/model-context-protocol">model-context-protocol</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/claude-code">claude-code</a></p>]]></description><pubDate>Sun, 2 Nov 2025 02:46:17 +0000</pubDate></item><item><title>Claude Code Can Debug Low-level Cryptography</title><link>https://simonwillison.net/2025/Nov/1/claude-code-cryptography/#atom-everything</link><description><![CDATA[<p><strong><a href="https://words.filippo.io/claude-debugging/">Claude Code Can Debug Low-level Cryptography</a></strong></p>
Go cryptography author Filippo Valsorda reports on some very positive results applying Claude Code to the challenge of implementing novel cryptography algorithms. After Claude was able to resolve a "fairly complex low-level bug" in fresh code he tried it against two other examples and got positive results both time.</p>
<p>Filippo isn't directly using Claude's solutions to the bugs, but is finding it useful for tracking down the cause and saving him a solid amount of debugging work:</p>
<blockquote>
<p>Three out of three one-shot debugging hits with no help is <em>extremely impressive</em>. Importantly, there is no need to trust the LLM or review its output when its job is just saving me an hour or two by telling me where the bug is, for me to reason about it and fix it.</p>
</blockquote>
<p>Using coding agents in this way may represent a useful entrypoint for LLM-skeptics who wouldn't <em>dream</em> of letting an autocomplete-machine writing code on their behalf.

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=45784179">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/cryptography">cryptography</a>, <a href="https://simonwillison.net/tags/go">go</a>, <a href="https://simonwillison.net/tags/security">security</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/filippo-valsorda">filippo-valsorda</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/claude-code">claude-code</a></p>]]></description><pubDate>Sat, 1 Nov 2025 22:26:43 +0000</pubDate></item><item><title>October 2025 sponsors-only newsletter</title><link>https://simonwillison.net/2025/Nov/1/sponsors-only-newsletter/#atom-everything</link><description><![CDATA[<p>I just hit send on the October edition of my <a href="https://github.com/sponsors/simonw/">sponsors-only monthly newsletter</a>. If you are a sponsor (or if you start a sponsorship now) you can <a href="https://github.com/simonw-private/monthly/blob/main/2025-10-october.md">access a copy here</a>. In the newsletter this month:</p>
<ul>
<li>Coding agents and "vibe engineering"</li>
<li>Claude Code for web</li>
<li>NVIDIA DGX Spark</li>
<li>Claude Skills</li>
<li>OpenAI DevDay and GitHub Universe</li>
<li>Python 3.14</li>
<li>October in Chinese Al model releases</li>
<li>Miscellaneous extras</li>
<li>Tools I'm using at the moment</li>
</ul>
<p>Here's <a href="https://gist.github.com/simonw/d6d4d86afc0d76767c63f23fc5137030">a copy of the September newsletter</a> as a preview of what you'll get. Pay $10/month to stay a month ahead of the free copy!</p>

    <p>Tags: <a href="https://simonwillison.net/tags/newsletter">newsletter</a></p>]]></description><pubDate>Sat, 1 Nov 2025 22:11:58 +0000</pubDate></item><item><title>Quoting Julian Andres Klode</title><link>https://simonwillison.net/2025/Nov/1/debian/#atom-everything</link><description><![CDATA[<blockquote cite="https://lists.debian.org/debian-devel/2025/10/msg00285.html"><p>I plan to introduce hard Rust dependencies and Rust code into
APT, no earlier than May 2026. This extends at first to the
Rust compiler and standard library, and the Sequoia ecosystem.</p>
<p>In particular, our code to parse .deb, .ar, .tar, and the
HTTP signature verification code would strongly benefit
from memory safe languages and a stronger approach to
unit testing.</p>
<p>If you maintain a port without a working Rust toolchain,
please ensure it has one within the next 6 months, or
sunset the port.</p></blockquote>
<p class="cite">&mdash; <a href="https://lists.debian.org/debian-devel/2025/10/msg00285.html">Julian Andres Klode</a>, debian-devel mailing list</p>

    <p>Tags: <a href="https://simonwillison.net/tags/open-source">open-source</a>, <a href="https://simonwillison.net/tags/debian">debian</a>, <a href="https://simonwillison.net/tags/rust">rust</a>, <a href="https://simonwillison.net/tags/linux">linux</a></p>]]></description><pubDate>Sat, 1 Nov 2025 17:34:34 +0000</pubDate></item><item><title>Curiosity-driven blogging</title><link>https://simonwillison.net/2025/Oct/31/curiosity-driven/#atom-everything</link><description><![CDATA[<p>My piece this morning <a href="https://simonwillison.net/2025/Oct/31/coreweave-acquires-marimo/">about the Marimo acquisition</a> is an example of a variant of a <a href="https://til.simonwillison.net">TIL</a> - I didn't know much about CoreWeave, the acquiring company, so I poked around to answer my own questions and then wrote up what I learned as a short post. Curiosity-driven blogging if you like.</p>

    <p>Tags: <a href="https://simonwillison.net/tags/til">til</a>, <a href="https://simonwillison.net/tags/blogging">blogging</a></p>]]></description><pubDate>Fri, 31 Oct 2025 17:09:56 +0000</pubDate></item><item><title>CoreWeave adds Marimo to their 2025 acquisition spree</title><link>https://simonwillison.net/2025/Oct/31/coreweave-acquires-marimo/#atom-everything</link><description><![CDATA[<p><strong><a href="https://marimo.io/blog/joining-coreweave">Marimo is Joining CoreWeave</a></strong></p>
I don't usually cover startup acquisitions here, but this one feels relevant to several of my interests.</p>
<p>Marimo (<a href="https://simonwillison.net/tags/marimo/">previously</a>) provide an open source (Apache 2 licensed) notebook tool for Python, with first-class support for an additional WebAssembly build plus an optional hosted service. It's effectively a reimagining of Jupyter notebooks as a reactive system, where cells automatically update based on changes to other cells - similar to how <a href="https://observablehq.com/">Observable</a> JavaScript notebooks work.</p>
<p>The first public Marimo release was in January 2024 and the tool has "been in development since 2022" (<a href="https://news.ycombinator.com/item?id=44304607#44330375">source</a>).</p>
<p>CoreWeave are a <em>big</em> player in the AI data center space. They started out as an Ethereum mining company in 2017, then pivoted to cloud computing infrastructure for AI companies after the 2018 cryptocurrency crash. They IPOd in March 2025 and today they operate more than 30 data centers worldwide and have announced a number of eye-wateringly sized deals with companies such as Cohere and OpenAI. I found <a href="https://en.wikipedia.org/wiki/CoreWeave">their Wikipedia page</a> very helpful.</p>
<p>They've also been on an acquisition spree this year, including:</p>
<ul>
<li>Weights &amp; Biases <a href="https://www.coreweave.com/blog/coreweave-completes-acquisition-of-weights-biases">in March 2025</a> (deal closed in May), the AI training observability platform.</li>
<li>OpenPipe <a href="https://www.coreweave.com/news/coreweave-to-acquire-openpipe-leader-in-reinforcement-learning">in September 2025</a> - a reinforcement learning platform, authors of the <a href="https://github.com/OpenPipe/ART">Agent Reinforcement Trainer</a> Apache 2 licensed open source RL framework.</li>
<li>Monolith AI <a href="https://investors.coreweave.com/news/news-details/2025/CoreWeave-to-Acquire-Monolith-Expanding-AI-Cloud-Platform-into-Industrial-Innovation/default.aspx">in October 2025</a>, a UK-based AI model SaaS platform focused on AI for engineering and industrial manufacturing.</li>
<li>And now Marimo.</li>
</ul>
<p>Marimo's own announcement emphasizes continued investment in that tool:</p>
<blockquote>
<p>Marimo is joining CoreWeave. Were continuing to build the open-source marimo notebook, while also leveling up molab with serious compute. Our long-term mission remains the same: to build the worlds best open-source programming environment for working with data.</p>
<p>marimo is, and always will be, free, open-source, and permissively licensed.</p>
</blockquote>
<p>Give CoreWeave's buying spree only really started this year it's impossible to say how well these acquisitions are likely to play out - they haven't yet established a track record.

    <p><small></small>Via <a href="https://x.com/marimo_io/status/1983916371869364622">@marimo_io</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/entrepreneurship">entrepreneurship</a>, <a href="https://simonwillison.net/tags/open-source">open-source</a>, <a href="https://simonwillison.net/tags/python">python</a>, <a href="https://simonwillison.net/tags/startups">startups</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/jupyter">jupyter</a>, <a href="https://simonwillison.net/tags/marimo">marimo</a></p>]]></description><pubDate>Fri, 31 Oct 2025 13:57:51 +0000</pubDate></item><item><title>Quoting Franois Chollet</title><link>https://simonwillison.net/2025/Oct/30/francois-chollet/#atom-everything</link><description><![CDATA[<blockquote cite="https://x.com/fchollet/status/1983279755823853724"><p>To really understand a concept, you have to "invent" it yourself in some capacity. Understanding doesn't come from passive content consumption. It is always self-built. It is an active, high-agency, self-directed process of creating and debugging your own mental models.</p></blockquote>
<p class="cite">&mdash; <a href="https://x.com/fchollet/status/1983279755823853724">Franois Chollet</a></p>

    <p>Tags: <a href="https://simonwillison.net/tags/francois-chollet">francois-chollet</a>, <a href="https://simonwillison.net/tags/teaching">teaching</a></p>]]></description><pubDate>Thu, 30 Oct 2025 02:37:18 +0000</pubDate></item><item><title>Introducing SWE-1.5: Our Fast Agent Model</title><link>https://simonwillison.net/2025/Oct/29/swe-15/#atom-everything</link><description><![CDATA[<p><strong><a href="https://cognition.ai/blog/swe-1-5">Introducing SWE-1.5: Our Fast Agent Model</a></strong></p>
Here's the second fast coding model released by a coding agent IDE in the same day - the first was <a href="https://simonwillison.net/2025/Oct/29/cursor-composer/">Composer-1 by Cursor</a>. This time it's Windsurf releasing SWE-1.5:</p>
<blockquote>
<p>Today were releasing SWE-1.5, the latest in our family of models optimized for software engineering. It is a frontier-size model with hundreds of billions of parameters that achieves near-SOTA coding performance. It also sets a new standard for speed: we partnered with Cerebras to serve it at up to 950 tok/s  6x faster than Haiku 4.5 and 13x faster than Sonnet 4.5.</p>
</blockquote>
<p>Like Composer-1 it's only available via their editor, no separate API yet. Also like Composer-1 they don't appear willing to share details of the "leading open-source base model" they based their new model on.</p>
<p>I asked it to generate an SVG of a pelican riding a bicycle and got this:</p>
<p><img alt="Bicycle has a red upside down Y shaped frame, pelican is a bit dumpy, it does at least have a long sharp beak." src="https://static.simonwillison.net/static/2025/swe-pelican.png" /></p>
<p>This one felt <em>really fast</em>. Partnering with Cerebras for inference is a very smart move.</p>
<p>They share a lot of details about their training process in the post:</p>
<blockquote>
<p>SWE-1.5 is trained on our state-of-the-art cluster of thousands of GB200 NVL72 chips. We believe SWE-1.5 may be the first public production model trained on the new GB200 generation. [...]</p>
<p>Our RL rollouts require high-fidelity environments with code execution and even web browsing. To achieve this, we leveraged our VM hypervisor <code>otterlink</code> that allows us to scale <strong>Devin</strong> to tens of thousands of concurrent machines (learn more about <a href="https://cognition.ai/blog/blockdiff#why-incremental-vm-snapshots">blockdiff</a>). This enabled us to smoothly support very high concurrency and ensure the training environment is aligned with our Devin production environments.</p>
</blockquote>
<p>That's <em>another</em> similarity to Cursor's Composer-1! Cursor talked about how they ran "hundreds of thousands of concurrent sandboxed coding environments in the cloud" in <a href="https://cursor.com/blog/composer">their description of their RL training</a> as well.</p>
<p>This is a notable trend: if you want to build a really great agentic coding tool there's clearly a lot to be said for using reinforcement learning to fine-tune a model against your own custom set of tools using large numbers of sandboxed simulated coding environments as part of that process.</p>
<p><strong>Update</strong>: <a href="https://x.com/zai_org/status/1984076614951420273">I think it's built on GLM</a>.

    <p><small></small>Via <a href="https://x.com/cognition/status/1983662838955831372">@cognition</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a>, <a href="https://simonwillison.net/tags/llm-release">llm-release</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a></p>]]></description><pubDate>Wed, 29 Oct 2025 23:59:20 +0000</pubDate></item><item><title>MiniMax M2 &amp; Agent: Ingenious in Simplicity</title><link>https://simonwillison.net/2025/Oct/29/minimax-m2/#atom-everything</link><description><![CDATA[<p><strong><a href="https://www.minimax.io/news/minimax-m2">MiniMax M2 &amp; Agent: Ingenious in Simplicity</a></strong></p>
MiniMax M2 was released on Monday 27th October by MiniMax, a Chinese AI lab founded in December 2021.</p>
<p>It's a very promising model. Their self-reported benchmark scores show it as comparable to Claude Sonnet 4, and Artificial Analysis <a href="https://x.com/ArtificialAnlys/status/1982714153375854998">are ranking it</a> as the best currently available open weight model according to their intelligence score:</p>
<blockquote>
<p>MiniMaxs M2 achieves a new all-time-high Intelligence Index score for an open weights model and offers impressive efficiency with only 10B active parameters (200B total). [...]</p>
<p>The models strengths include tool use and instruction following (as shown by Tau2 Bench and IFBench). As such, while M2 likely excels at agentic use cases it may underperform other open weights leaders such as DeepSeek V3.2 and Qwen3 235B at some generalist tasks. This is in line with a number of recent open weights model releases from Chinese AI labs which focus on agentic capabilities, likely pointing to a heavy post-training emphasis on RL.</p>
</blockquote>
<p>The size is particularly significant: the model weights are 230GB <a href="https://huggingface.co/MiniMaxAI/MiniMax-M2">on Hugging Face</a>, significantly smaller than other high performing open weight models. That's small enough to run on a 256GB Mac Studio, and the MLX community <a href="https://huggingface.co/mlx-community/MiniMax-M2-8bit">have that working already</a>.</p>
<p>MiniMax offer their own API, and recommend using their Anthropic-compatible endpoint and the official Anthropic SDKs to access it. MiniMax Head of Engineering Skyler Miao
 <a href="https://x.com/SkylerMiao7/status/1982989507252367687">provided some background on that</a>:</p>
<blockquote>
<p>M2 is a agentic thinking model, it do interleaved thinking like sonnet 4.5, which means every response will contain its thought content.
Its very important for M2 to keep the chain of thought. So we must make sure the history thought passed back to the model.
Anthropic API support it for sure, as sonnet needs it as well. OpenAI only support it in their new Response API, no support for in ChatCompletion.</p>
</blockquote>
<p>MiniMax are offering the new model via their API for free until November 7th, after which the cost will be $0.30/million input tokens and $1.20/million output tokens - similar in price to Gemini 2.5 Flash and GPT-5 Mini, see <a href="https://www.llm-prices.com/#it=51&amp;ot=4017&amp;sel=minimax-m2%2Cgpt-5-mini%2Cclaude-3-haiku%2Cgemini-2.5-flash-lite%2Cgemini-2.5-flash">price comparison here</a> on my <a href="https://www.llm-prices.com/">llm-prices.com</a> site.</p>
<p>I released a new plugin for <a href="https://llm.datasette.io/">LLM</a> called <a href="https://github.com/simonw/llm-minimax">llm-minimax</a> providing support for M2 via the MiniMax API:</p>
<pre><code>llm install llm-minimax
llm keys set minimax
# Paste key here
llm -m m2 -o max_tokens 10000 "Generate an SVG of a pelican riding a bicycle"
</code></pre>
<p>Here's <a href="https://gist.github.com/simonw/da79447830dc431c067a93648b338be6">the result</a>:</p>
<p><img alt="Biycle is good though obscured by the pelican. Pelican has an impressive triple beak and is stretched along the bicycle frame. Not clear if it can pedal or what it is sitting on." src="https://static.simonwillison.net/static/2025/m2-pelican.png" /></p>
<p>51 input, 4,017 output. At $0.30/m input and $1.20/m output that pelican would cost 0.4836 cents - less than half a cent.</p>
<p>This is the first plugin I've written for an Anthropic-API-compatible model. I released <a href="https://github.com/simonw/llm-anthropic/releases/tag/0.21">llm-anthropic 0.21</a> first adding the ability to customize the <code>base_url</code> parameter when using that model class. This meant the new plugin was less than <a href="https://github.com/simonw/llm-minimax/blob/0.1/llm_minimax.py">30 lines of Python</a>.


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/local-llms">local-llms</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/llm">llm</a>, <a href="https://simonwillison.net/tags/llm-pricing">llm-pricing</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a>, <a href="https://simonwillison.net/tags/llm-release">llm-release</a>, <a href="https://simonwillison.net/tags/ai-in-china">ai-in-china</a>, <a href="https://simonwillison.net/tags/minimax">minimax</a></p>]]></description><pubDate>Wed, 29 Oct 2025 22:49:47 +0000</pubDate></item><item><title>Composer: Building a fast frontier model with RL</title><link>https://simonwillison.net/2025/Oct/29/cursor-composer/#atom-everything</link><description><![CDATA[<p><strong><a href="https://cursor.com/blog/composer">Composer: Building a fast frontier model with RL</a></strong></p>
Cursor released <a href="https://cursor.com/blog/2-0">Cursor 2.0 today</a>, with a refreshed UI focused on agentic coding (and running agents in parallel) and a new model that's unique to Cursor called <strong>Composer&nbsp;1</strong>.</p>
<p>As far as I can tell there's no way to call the model directly via an API, so I fired up "Ask" mode in Cursor's chat side panel and asked it to "Generate an SVG of a pelican riding a bicycle":</p>
<p><img alt="Screenshot of Cursor 2 - In the chat panel I have asked the question and it spat out a bunch of SVG." src="https://static.simonwillison.net/static/2025/cursor-2.jpg" /></p>
<p>Here's <a href="https://gist.github.com/simonw/e5c9176f153ca718370055ecd256fe70">the result</a>:</p>
<p><img alt="The bicycle is levitating against a blue sky. The pelican looks a little bit more like a baby chicken but does at least have a long beak." src="https://static.simonwillison.net/static/2025/cursor-1-pelican.png" /></p>
<p>The notable thing about Composer-1 is that it is designed to be <em>fast</em>. The pelican certainly came back quickly, and in their announcement they describe it as being "4x faster than similarly intelligent models".</p>
<p>It's interesting to see Cursor investing resources in training their own code-specific model - similar to <a href="https://openai.com/index/introducing-upgrades-to-codex/">GPT-5-Codex</a> or <a href="https://github.com/QwenLM/Qwen3-Coder">Qwen3-Coder</a>. From their post:</p>
<blockquote>
<p>Composer is a mixture-of-experts (MoE) language model supporting long-context generation and understanding. It is specialized for software engineering through reinforcement learning (RL) in a diverse range of development environments. [...]</p>
<p>Efficient training of large MoE models requires significant investment into building infrastructure and systems research. We built custom training infrastructure leveraging PyTorch and Ray to power asynchronous reinforcement learning at scale. We natively train our models at low precision by combining our <a href="https://cursor.com/blog/kernels">MXFP8 MoE kernels</a> with expert parallelism and hybrid sharded data parallelism, allowing us to scale training to thousands of NVIDIA GPUs with minimal communication cost. [...]</p>
<p>During RL, we want our model to be able to call any tool in the Cursor Agent harness. These tools allow editing code, using semantic search, grepping strings, and running terminal commands. At our scale, teaching the model to effectively call these tools requires running hundreds of thousands of concurrent sandboxed coding environments in the cloud.</p>
</blockquote>
<p>One detail that's notably absent from their description: did they train the model from scratch, or did they start with an existing open-weights model such as something from Qwen or GLM?</p>
<p>Cursor researcher Sasha Rush has been answering questions <a href="https://news.ycombinator.com/item?id=45748725">on Hacker News</a>, but has so far been evasive in answering questions about the base model. When directly asked "is Composer a fine tune of an existing open source base model?" they replied:</p>
<blockquote>
<p>Our primary focus is on RL post-training. We think that is the best way to get the model to be a strong interactive agent.</p>
</blockquote>
<p>Sasha <a href="https://news.ycombinator.com/item?id=45748725#45750784">did confirm</a> that rumors of an earlier Cursor preview model, Cheetah, being based on a model by xAI's Grok were "Straight up untrue."

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=45748725">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a>, <a href="https://simonwillison.net/tags/llm-release">llm-release</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/cursor">cursor</a>, <a href="https://simonwillison.net/tags/parallel-agents">parallel-agents</a></p>]]></description><pubDate>Wed, 29 Oct 2025 20:45:53 +0000</pubDate></item><item><title>Hacking the WiFi-enabled color screen GitHub Universe conference badge</title><link>https://simonwillison.net/2025/Oct/28/github-universe-badge/#atom-everything</link><description><![CDATA[<p>I'm at <a href="https://githubuniverse.com/">GitHub Universe</a> this week (thanks to a free ticket from Microsoft). Yesterday I picked up my conference badge... which incorporates a <s>full Raspberry Pi</s> Raspberry Pi Pico microcontroller with a battery, color screen, WiFi and bluetooth.</p>
<p>GitHub Universe has a tradition of hackable conference badges - the badge last year had an eInk display. This year's is a huge upgrade though - a color screen and WiFI connection makes this thing a genuinely useful little computer!</p>
<p><img src="https://static.simonwillison.net/static/2025/gitub-universe-badge.jpg" alt="Photo of the badge - it has a color screen with six app icons" style="max-width: 100%;" /></p>
<p>The only thing it's missing is a keyboard - the device instead provides five buttons total - Up, Down, A, B, C. It might be possible to get a bluetooth keyboard to work though I'll believe that when I see it - there's not a lot of space on this device for a keyboard driver.</p>
<p>Everything is written using MicroPython, and the device is designed to be hackable: connect it to a laptop with a USB-C cable and you can start modifying the code directly on the device.</p>
<h4 id="getting-setup-with-the-badge">Getting setup with the badge</h4>
<p>Out of the box the badge will play an opening animation (implemented as a sequence of PNG image frames) and then show a home screen with six app icons.</p>
<p>The default apps are mostly neat Octocat-themed demos: a flappy-bird clone, a tamagotchi-style pet, a drawing app that works like an etch-a-sketch, an IR scavenger hunt for the conference venue itself (this thing has an IR sensor too!), and a gallery app showing some images.</p>
<p>The sixth app is a badge app. This will show your GitHub profile image and some basic stats, but will only work if you dig out a USB-C cable and make some edits to the files on the badge directly.</p>
<p>I did this on a Mac. I plugged a USB-C cable into the badge which caused MacOS to treat it as an attached drive volume. In that drive are several files including <code>secrets.py</code>. Open that up, confirm the WiFi details are correct and add your GitHub username. The file should look like this:</p>
<pre><span class="pl-c1">WIFI_SSID</span> <span class="pl-c1">=</span> <span class="pl-s">"..."</span>
<span class="pl-c1">WIFI_PASSWORD</span> <span class="pl-c1">=</span> <span class="pl-s">"..."</span>
<span class="pl-c1">GITHUB_USERNAME</span> <span class="pl-c1">=</span> <span class="pl-s">"simonw"</span></pre>
<p>The badge comes with the SSID and password for the GitHub Universe WiFi network pre-populated.</p>
<p>That's it! Unmount the disk, hit the reboot button on the back of the badge and when it comes back up again the badge app should look something like this:</p>
<p><img src="https://static.simonwillison.net/static/2025/badge-profile.jpg" alt="Badge shows my GitHub avatar, plus 10,947 followers, 4,083 contribs, 893 repos" style="max-width: 100%;" /></p>
<h4 id="building-your-own-apps">Building your own apps</h4>
<p>Here's <a href="https://badger.github.io/">the official documentation</a> for building software for the badge.</p>
<p>When I got mine yesterday the official repo had not yet been updated, so I had to figure this out myself.</p>
<p>I copied all of the code across to my laptop, added it to a Git repo and then fired up Claude Code and told it:</p>
<blockquote>
<p><code>Investigate this code and add a detailed README</code></p>
</blockquote>
<p>Here's <a href="https://github.com/simonw/github-universe-2025-badge/blob/15773c7a53275e7836216c3aa9a8a781c06f7859/README.md">the result</a>, which was really useful for getting a start on understanding how it all worked.</p>
<p>Each of the six default apps lives in a <code>apps/</code> folder, for example <a href="https://github.com/simonw/github-universe-2025-badge/tree/main/apps/sketch">apps/sketch/</a> for the sketching app.</p>
<p>There's also a menu app which powers the home screen. That lives in <a href="https://github.com/simonw/github-universe-2025-badge/tree/main/apps/menu">apps/menu/</a>. You can edit code in here to add new apps that you create to that screen.</p>
<p>I told Claude:</p>
<blockquote>
<p><code>Add a new app to it available from the menu which shows network status and other useful debug info about the machine it is running on</code></p>
</blockquote>
<p>This was a bit of a long-shot, but it totally worked!</p>
<p>The first version had an error:</p>
<p><img src="https://static.simonwillison.net/static/2025/badge-error.jpg" alt="A stacktrace! file badgeware.py line 510 has a list index out of range error." style="max-width: 100%;" /></p>
<p>I OCRd that photo (with the Apple Photos app) and pasted the message into Claude Code and it fixed the problem.</p>
<p>This almost worked... but the addition of a seventh icon to the 2x3 grid meant that you could select the icon but it didn't scroll into view. I had Claude <a href="https://github.com/simonw/github-universe-2025-badge/commit/2a60f75db101dc1dc7568ff466ad5c97dc86b336">fix that for me too</a>.</p>
<p>Here's the code for <a href="https://github.com/simonw/github-universe-2025-badge/blob/main/apps/debug/__init__.py">apps/debug/__init__.py</a>, and <a href="https://gistpreview.github.io/?276d3e0c6566ddbc93adc7020ef6b439">the full Claude Code transcript</a> created using my terminal-to-HTML app <a href="https://simonwillison.net/2025/Oct/23/claude-code-for-web-video/">described here</a>.</p>
<p>Here are the four screens of the debug app:</p>
<p><img src="https://static.simonwillison.net/static/2025/badge-debug-network.jpg" alt="Network info, showing WiFi network details and IP address" style="max-width: 100%;" /></p>
<p><img src="https://static.simonwillison.net/static/2025/badge-debug-storage.jpg" alt="Storage screen, it has 1MB total, 72BK used. Usage 7%. CMD is /system/apps/debug" style="max-width: 100%;" /></p>
<p><img src="https://static.simonwillison.net/static/2025/badge-debug-system.jpg" alt="System: Platform rp2, Python 1.26.0, CPU freq 200MHz, Uptime 13m46s" style="max-width: 100%;" /></p>
<p><img src="https://static.simonwillison.net/static/2025/badge-debug-memory.jpg" alt="Memory info - 100KB used, 241KB total, and a usage bar. Press B to run GC." style="max-width: 100%;" /></p>
<h4 id="an-icon-editor">An icon editor</h4>
<p>The icons used on the app are 24x24 pixels. I decided it would be neat to have a web app that helps build those icons, including the ability to start by creating an icon from an emoji.</p>
<p>I bulit this one <a href="https://claude.ai/share/ca05bd58-859e-4ceb-b5c7-7428b348df3c">using Claude Artifacts</a>. Here's the result, now available at <a href="https://tools.simonwillison.net/icon-editor">tools.simonwillison.net/icon-editor</a>:</p>
<p><img src="https://static.simonwillison.net/static/2025/icon-editor.jpg" alt="A stacktrace! file badgeware.py line 510 has a list index out of range error." style="max-width: 100%;" /></p>
<h4 id="and-a-repl">And a REPL</h4>
<p>I noticed that last year's badge configuration app (which I can't find in <a href="https://github.com/badger/badger.github.io/">github.com/badger/badger.github.io</a> any more, I think they reset the history on that repo?) worked by talking to MicroPython over the Web Serial API from Chrome. Here's <a href="https://github.com/simonw/2004-badger.github.io/blob/e3501d631a987bfbc12d93c9e35bf2c64e55d052/public/script.js#L305-L394">my archived copy of that code</a>.</p>
<p>Wouldn't it be useful to have a REPL in a web UI that you could use to interact with the badge directly over USB?</p>
<p>I pointed Claude Code at a copy of that repo and told it:</p>
<blockquote>
<p><code>Based on this build a new HTML with inline JavaScript page that uses WebUSB to simply test that the connection to the badge works and then list files on that device using the same mechanism</code></p>
</blockquote>
<p>It took a bit of poking (here's <a href="https://gistpreview.github.io/?13d93a9e3b0ce1c921cd20303f2f1d84">the transcript</a>) but the result is now live at <a href="https://tools.simonwillison.net/badge-repl">tools.simonwillison.net/badge-repl</a>. It only works in Chrome - you'll need to plug the badge in with a USB-C cable and then click "Connect to Badge".</p>
<p><img src="https://static.simonwillison.net/static/2025/badge-repl.jpg" alt="Badge Interactive REPL. Note: This tool requires the Web Serial API (Chrome/Edge on desktop). Connect to Badge, Disconnect and Clear Terminal buttons. Then a REPL interface displaying: Ready to connect. Click &quot;Connect to Badge&quot; to start.Traceback (most recent call last):ddae88e91.dirty on 2025-10-20; GitHub Badger with RP2350 Type &quot;help()&quot; for more information.  &gt;&gt;&gt;  MicroPython v1.14-5485.gddae88e91.dirty on 2025-10-20; GitHub Badger with RP2350 Type &quot;help()&quot; for more information. &gt;&gt;&gt; os.listdir() ['icon.py', 'ui.py', 'init.py', '._init.py', '._icon.py'] &gt;&gt;&gt; machine.freq() 200000000 &gt;&gt;&gt; gc.mem_free() 159696 &gt;&gt;&gt; help() Welcome to MicroPython!" style="max-width: 100%;" /></p>
<h4 id="get-hacking">Get hacking</h4>
<p>If you're a GitHub Universe attendee I hope this is useful. The official <a href="https://badger.github.io/">badger.github.io</a> site has plenty more details to help you get started.</p>
<p>There isn't yet a way to get hold of this hardware outside of GitHub Universe - I know they had some supply chain challenges just getting enough badges for the conference attendees!</p>
<p>It's a very neat device, built for GitHub by <a href="https://www.pimoroni.com/">Pimoroni</a> in Sheffield, UK. A version of this should become generally available in the future under the name "Pimoroni Tufty 2350".</p>

<h4 id="iphone-only">Update: Setup with iPhone only</h4>

<p>If you don't have a laptop with you it's still possible to start hacking on the device using just a USB-C cable.</p>

<p>Plug the badge into the phone, hit the reset button on the back twice to switch it into disk mode and open the iPhone Files app - the badge should appear as a mounted disk called BADGER.</p>

<p>I used <a href="https://apps.apple.com/us/app/textastic-code-editor/id1049254261">Textastic</a> to edit that <code>secrets.py</code> and configure a new badge, then hit reset again to restart it.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/github">github</a>, <a href="https://simonwillison.net/tags/hardware-hacking">hardware-hacking</a>, <a href="https://simonwillison.net/tags/microsoft">microsoft</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/raspberry-pi">raspberry-pi</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/claude-code">claude-code</a>, <a href="https://simonwillison.net/tags/disclosures">disclosures</a></p>]]></description><pubDate>Tue, 28 Oct 2025 17:17:44 +0000</pubDate></item><item><title>Quoting Aaron Boodman</title><link>https://simonwillison.net/2025/Oct/28/aaron-boodman/#atom-everything</link><description><![CDATA[<blockquote cite="https://x.com/aboodman/status/1982898753607741502"><p>Claude doesn't make me <em>much</em> faster on the work that I am an expert on. Maybe 15-20% depending on the day.</p>
<p>It's the work that I don't know how to do and would have to research. Or the grunge work I don't even want to do. On this it is hard to even put a number on. Many of the projects I do with Claude day to day I just wouldn't have done at all pre-Claude.</p>
<p>Infinity% improvement in productivity on those.</p></blockquote>
<p class="cite">&mdash; <a href="https://x.com/aboodman/status/1982898753607741502">Aaron Boodman</a></p>

    <p>Tags: <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/claude">claude</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/aaron-boodman">aaron-boodman</a></p>]]></description><pubDate>Tue, 28 Oct 2025 02:08:57 +0000</pubDate></item><item><title>The PSF has withdrawn a $1.5 million proposal to US government grant program</title><link>https://simonwillison.net/2025/Oct/27/psf-withdrawn-proposal/#atom-everything</link><description><![CDATA[<p><strong><a href="https://pyfound.blogspot.com/2025/10/NSF-funding-statement.html">The PSF has withdrawn a $1.5 million proposal to US government grant program</a></strong></p>
The Python Software Foundation was recently "recommended for funding" (NSF terminology) for a $1.5m grant from the US government National Science Foundation to help improve the security of the Python software ecosystem, after an grant application process lead by Seth Larson and Loren Crary.</p>
<p>The PSF's annual budget is less than $6m so this is a meaningful amount of money for the organization!</p>
<p>We were forced to withdraw our application and turn down the funding, thanks to new language that was added to the agreement requiring us to affirm that we "do not, and will not during the term of this financial assistance award, operate any programs that advance or promote DEI, or discriminatory equity ideology in violation of Federal anti-discrimination laws."</p>
<p>Our legal advisors confirmed that this would not just apply to security work covered by the grant - this would apply to all of the PSF's activities.</p>
<p>This was not an option for us. Here's the <a href="https://www.python.org/psf/mission/">mission</a> of the PSF:</p>
<blockquote>
<p>The mission of the Python Software Foundation is to promote, protect, and advance the Python programming language, and to support and facilitate the growth of a diverse and international community of Python programmers.</p>
</blockquote>
<p>If we accepted and spent the money despite this term, there was a very real risk that the money could be clawed back later. That represents an existential risk for the foundation since we would have already spent the money!</p>
<p>I was one of the board members who voted to reject this funding - a unanimous but tough decision. Im proud to serve on a board that can make difficult decisions like this.</p>
<p>If you'd like to sponsor the PSF you can find out more <a href="https://www.python.org/sponsors/application/">on our site</a>. I'd love to see a few more of the large AI labs show up <a href="https://www.python.org/psf/sponsors/">on our top-tier visionary sponsors list</a>.


    <p>Tags: <a href="https://simonwillison.net/tags/open-source">open-source</a>, <a href="https://simonwillison.net/tags/python">python</a>, <a href="https://simonwillison.net/tags/psf">psf</a></p>]]></description><pubDate>Mon, 27 Oct 2025 20:32:07 +0000</pubDate></item><item><title>GenAI Image Editing Showdown</title><link>https://simonwillison.net/2025/Oct/26/genai-image-editing-showdown/#atom-everything</link><description><![CDATA[<p><strong><a href="https://genai-showdown.specr.net/image-editing">GenAI Image Editing Showdown</a></strong></p>
Useful collection of examples by Shaun Pedicini who tested Seedream 4, Gemini 2.5 Flash, Qwen-Image-Edit, FLUX.1 Kontext [dev], FLUX.1 Kontext [max], OmniGen2, and OpenAI gpt-image-1 across 12 image editing prompts.</p>
<p>The tasks are very neatly selected, for example:</p>
<blockquote>
<p><code>Remove all the brown pieces of candy from the glass bowl</code></p>
</blockquote>
<p>Qwen-Image-Edit (a model that <a href="https://simonwillison.net/2025/Aug/19/qwen-image-edit/">can be self-hosted</a>) was the only one to successfully manage that!</p>
<p>This kind of collection is really useful for building up an intuition as to how well image editing models work, and which ones are worth trying for which categories of task.</p>
<p>Shaun has <a href="https://genai-showdown.specr.net/">a similar page for text-to-image models</a> which are not fed an initial image to modify, with further challenging prompts like:</p>
<blockquote>
<p><code>Two Prussian soldiers wearing spiked pith helmets are facing each other and playing a game of ring toss by attempting to toss metal rings over the spike on the other soldier's helmet.</code></p>
</blockquote>

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=45708795">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/text-to-image">text-to-image</a></p>]]></description><pubDate>Sun, 26 Oct 2025 23:59:25 +0000</pubDate></item><item><title>Sora might have a &apos;pervert&apos; problem on its hands</title><link>https://simonwillison.net/2025/Oct/26/sora-pervert-problem/#atom-everything</link><description><![CDATA[<p><strong><a href="https://www.businessinsider.com/sora-video-openai-fetish-content-my-face-problem-2025-10">Sora might have a &#x27;pervert&#x27; problem on its hands</a></strong></p>
Katie Notopoulos turned on the Sora 2 option where anyone can make a video featuring her cameo, and then:</p>
<blockquote>
<p>I found a stranger had made a video where I appeared pregnant. A quick look at the user's profile, and I saw that this person's entire Sora profile was made up of this genre  video after video of women with big, pregnant bellies. I recognized immediately what this was: fetish content.</p>
</blockquote>
<p>This feels like an intractable problem to me: given the enormous array of fetishes it's hard to imagine a classifier that could protect people from having their likeness used in this way.</p>
<p>Best to be aware of this risk before turning on any settings that allow strangers to reuse your image... and that's only an option for tools that implement a robust opt-in mechanism like Sora does.

    <p><small></small>Via <a href="https://daringfireball.net/linked/2025/10/25/sora-perverts">John Gruber</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a>, <a href="https://simonwillison.net/tags/video-models">video-models</a></p>]]></description><pubDate>Sun, 26 Oct 2025 17:03:55 +0000</pubDate></item></channel></rss>