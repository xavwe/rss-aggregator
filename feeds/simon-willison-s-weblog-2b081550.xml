<?xml version="1.0" encoding="utf-8"?><rss version="2.0"><channel><title>Simon Willison&apos;s Weblog</title><link>https://raw.githubusercontent.com/xavwe/rss-aggregator/refs/heads/main/feeds/simon-willison-s-weblog-2b081550.xml</link><description>Archived feed from https://simonwillison.net/atom/everything</description><item><title>Quoting Boris Cherny</title><link>https://simonwillison.net/2026/Feb/14/boris/#atom-everything</link><description><![CDATA[<blockquote cite="https://twitter.com/bcherny/status/2022762422302576970"><p>Someone has to prompt the Claudes, talk to customers, coordinate with other teams, decide what to build next. Engineering is changing and great engineers are more important than ever.</p></blockquote>
<p class="cite">&mdash; <a href="https://twitter.com/bcherny/status/2022762422302576970">Boris Cherny</a>, Claude Code creator, on why Anthropic are still hiring developers</p>

    <p>Tags: <a href="https://simonwillison.net/tags/careers">careers</a>, <a href="https://simonwillison.net/tags/anthropic">anthropic</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/claude-code">claude-code</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a></p>]]></description><pubDate>Sat, 14 Feb 2026 23:59:09 +0000</pubDate></item><item><title>Quoting Thoughtworks</title><link>https://simonwillison.net/2026/Feb/14/thoughtworks/#atom-everything</link><description><![CDATA[<blockquote cite="https://www.thoughtworks.com/content/dam/thoughtworks/documents/report/tw_future%20_of_software_development_retreat_%20key_takeaways.pdf"><p>The retreat challenged the narrative that AI eliminates the need for junior developers. Juniors are more profitable than they have ever been. AI tools get them past the awkward initial net-negative phase faster. They serve as a call option on future productivity. And they are better at AI tools than senior engineers, having never developed the habits and assumptions that slow adoption.</p>
<p>The real concern is mid-level engineers who came up during the decade-long hiring boom and may not have developed the fundamentals needed to thrive in the new environment. This population represents the bulk of the industry by volume, and retraining them is genuinely difficult. The retreat discussed whether apprenticeship models, rotation programs and lifelong learning structures could address this gap, but acknowledged that no organization has solved it yet.</p></blockquote>
<p class="cite">&mdash; <a href="https://www.thoughtworks.com/content/dam/thoughtworks/documents/report/tw_future%20_of_software_development_retreat_%20key_takeaways.pdf">Thoughtworks</a>, findings from a retreat concerning "the future of software engineering", conducted under Chatham House rules</p>

    <p>Tags: <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/careers">careers</a>, <a href="https://simonwillison.net/tags/ai">ai</a></p>]]></description><pubDate>Sat, 14 Feb 2026 04:54:41 +0000</pubDate></item><item><title>Anthropic&apos;s public benefit mission</title><link>https://simonwillison.net/2026/Feb/13/anthropic-public-benefit-mission/#atom-everything</link><description><![CDATA[<p>Someone <a href="https://news.ycombinator.com/item?id=47008560#47008978">asked</a> if there was an Anthropic equivalent to <a href="https://simonwillison.net/2026/Feb/13/openai-mission-statement/">OpenAI's IRS mission statements over time</a>.</p>
<p>Anthropic are a "public benefit corporation" but not a non-profit, so they don't have the same requirements to file public documents with the IRS every year.</p>
<p>But when I asked Claude it ran a search and dug up this <a href="https://drive.google.com/drive/folders/1ImqXYv9_H2FTNAujZfu3EPtYFD4xIlHJ">Google Drive folder</a> where Zach Stein-Perlman shared Certificate of Incorporation documents he <a href="https://ailabwatch.substack.com/p/anthropics-certificate-of-incorporation">obtained from the State of Delaware</a>!</p>
<p>Anthropic's are much less interesting that OpenAI's. The earliest document from 2021 states:</p>
<blockquote>
<p>The specific public benefit that the Corporation will promote is to responsibly develop and maintain advanced Al for the cultural, social and technological improvement of humanity.</p>
</blockquote>
<p>Every subsequent document up to 2024 uses an updated version which says:</p>
<blockquote>
<p>The specific public benefit that the Corporation will promote is to responsibly develop and maintain advanced AI for the long term benefit of humanity.</p>
</blockquote>

    <p>Tags: <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a>, <a href="https://simonwillison.net/tags/anthropic">anthropic</a>, <a href="https://simonwillison.net/tags/ai">ai</a></p>]]></description><pubDate>Fri, 13 Feb 2026 23:59:51 +0000</pubDate></item><item><title>The evolution of OpenAI&apos;s mission statement</title><link>https://simonwillison.net/2026/Feb/13/openai-mission-statement/#atom-everything</link><description><![CDATA[<p>As a USA <a href="https://en.wikipedia.org/wiki/501(c)(3)_organization">501(c)(3)</a> the OpenAI non-profit has to file a tax return each year with the IRS. One of the required fields on that tax return is to "Briefly describe the organization‚Äôs mission or most significant activities" - this has actual legal weight to it as the IRS can use it to evaluate if the organization is sticking to its mission and deserves to maintain its non-profit tax-exempt status.</p>
<p>You can browse OpenAI's <a href="https://projects.propublica.org/nonprofits/organizations/810861541">tax filings by year</a> on ProPublica's excellent <a href="https://projects.propublica.org/nonprofits/">Nonprofit Explorer</a>.</p>
<p>I went through and extracted that mission statement for 2016 through 2024, then had Claude Code <a href="https://gisthost.github.io/?7a569df89f43f390bccc2c5517718b49/index.html">help me</a> fake the commit dates to turn it into a git repository and share that as a Gist - which means that Gist's <a href="https://gist.github.com/simonw/e36f0e5ef4a86881d145083f759bcf25/revisions">revisions page</a> shows every edit they've made since they started filing their taxes!</p>
<p>It's really interesting seeing what they've changed over time.</p>
<p>The original 2016 mission reads as follows (and yes, the apostrophe in "OpenAIs" is missing <a href="https://projects.propublica.org/nonprofits/organizations/810861541/201703459349300445/full">in the original</a>):</p>
<blockquote>
<p>OpenAIs goal is to advance digital intelligence in the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return. We think that artificial intelligence technology will help shape the 21st century, and we want to help the world build safe AI technology and ensure that AI's benefits are as widely and evenly distributed as possible. Were trying to build AI as part of a larger community, and we want to openly share our plans and capabilities along the way.</p>
</blockquote>
<p>In 2018 they dropped the part about "trying to build AI as part of a larger community, and we want to openly share our plans and capabilities along the way."</p>
<p><img src="https://static.simonwillison.net/static/2026/mission-3.jpg" alt="Git diff showing the 2018 revision deleting the final two sentences: &quot;Were trying to build AI as part of a larger community, and we want to openly share our plans and capabilities along the way.&quot;" style="max-width: 100%;" /></p>
<p>In 2020 they dropped the words "as a whole" from "benefit humanity as a whole". They're still "unconstrained by a need to generate financial return" though.</p>
<p><img src="https://static.simonwillison.net/static/2026/mission-5.jpg" alt="Git diff showing the 2020 revision dropping &quot;as a whole&quot; from &quot;benefit humanity as a whole&quot; and changing &quot;We think&quot; to &quot;OpenAI believes&quot;" style="max-width: 100%;" /></p>
<p>Some interesting changes in 2021. They're still unconstrained by a need to generate financial return, but here we have the first reference to "general-purpose artificial intelligence" (replacing "digital intelligence"). They're more confident too: it's not "most likely to benefit humanity", it's just "benefits humanity".</p>
<p>They previously wanted to "help the world build safe AI technology", but now they're going to do that themselves: "the companys goal is to develop and responsibly deploy safe AI technology".</p>
<p><img src="https://static.simonwillison.net/static/2026/mission-6.jpg" alt="Git diff showing the 2021 revision replacing &quot;goal is to advance digital intelligence&quot; with &quot;mission is to build general-purpose artificial intelligence&quot;, changing &quot;most likely to benefit&quot; to just &quot;benefits&quot;, and replacing &quot;help the world build safe AI technology&quot; with &quot;the companys goal is to develop and responsibly deploy safe AI technology&quot;" style="max-width: 100%;" /></p>
<p>2022 only changed one significant word: they added "safely" to "build ... (AI) that safely benefits humanity". They're still unconstrained by those financial returns!</p>
<p><img src="https://static.simonwillison.net/static/2026/mission-7.jpg" alt="Git diff showing the 2022 revision adding &quot;(AI)&quot; and the word &quot;safely&quot; so it now reads &quot;that safely benefits humanity&quot;, and changing &quot;the companys&quot; to &quot;our&quot;" style="max-width: 100%;" /></p>
<p>No changes in 2023... but then in 2024 they deleted almost the entire thing, reducing it to simply:</p>
<blockquote>
<p>OpenAIs mission is to ensure that artificial general intelligence benefits all of humanity.</p>
</blockquote>
<p>They've expanded "humanity" to "all of humanity", but there's no mention of safety any more and I guess they can finally start focusing on that need to generate financial returns!</p>
<p><img src="https://static.simonwillison.net/static/2026/mission-9.jpg" alt="Git diff showing the 2024 revision deleting the entire multi-sentence mission statement and replacing it with just &quot;OpenAIs mission is to ensure that artificial general intelligence benefits all of humanity.&quot;" style="max-width: 100%;" /></p>

<p><strong>Update</strong>: I found loosely equivalent but much less interesting documents <a href="https://simonwillison.net/2026/Feb/13/anthropic-public-benefit-mission/">from Anthropic</a>.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a>, <a href="https://simonwillison.net/tags/propublica">propublica</a></p>]]></description><pubDate>Fri, 13 Feb 2026 23:38:29 +0000</pubDate></item><item><title>Introducing GPT‚Äë5.3‚ÄëCodex‚ÄëSpark</title><link>https://simonwillison.net/2026/Feb/12/codex-spark/#atom-everything</link><description><![CDATA[<p><strong><a href="https://openai.com/index/introducing-gpt-5-3-codex-spark/">Introducing GPT‚Äë5.3‚ÄëCodex‚ÄëSpark</a></strong></p>
OpenAI announced a partnership with Cerebras <a href="https://openai.com/index/cerebras-partnership/">on January 14th</a>. Four weeks later they're already launching the first integration, "an ultra-fast model for real-time coding in Codex".</p>
<p>Despite being named GPT-5.3-Codex-Spark it's not purely an accelerated alternative to GPT-5.3-Codex - the blog post calls it "a smaller version of GPT‚Äë5.3-Codex" and clarifies that "at launch, Codex-Spark has a 128k context window and is text-only."</p>
<p>I had some preview access to this model and I can confirm that it's significantly faster than their other models.</p>
<p>Here's what that speed looks like running in Codex CLI:</p>
<div style="max-width: 100%;">
    <video 
        controls 
        preload="none"
        poster="https://static.simonwillison.net/static/2026/gpt-5.3-codex-spark-medium-last.jpg"
        style="width: 100%; height: auto;">
        <source src="https://static.simonwillison.net/static/2026/gpt-5.3-codex-spark-medium.mp4" type="video/mp4">
    </video>
</div>

<p>That was the "Generate an SVG of a pelican riding a bicycle" prompt - here's the rendered result:</p>
<p><img alt="Whimsical flat illustration of an orange duck merged with a bicycle, where the duck's body forms the seat and frame area while its head extends forward over the handlebars, set against a simple light blue sky and green grass background." src="https://static.simonwillison.net/static/2026/gpt-5.3-codex-spark-pelican.png" /></p>
<p>Compare that to the speed of regular GPT-5.3 Codex medium:</p>
<div style="max-width: 100%;">
    <video 
        controls 
        preload="none"
        poster="https://static.simonwillison.net/static/2026/gpt-5.3-codex-medium-last.jpg"
        style="width: 100%; height: auto;">
        <source src="https://static.simonwillison.net/static/2026/gpt-5.3-codex-medium.mp4" type="video/mp4">
    </video>
</div>

<p>Significantly slower, but the pelican is a lot better:</p>
<p><img alt="Whimsical flat illustration of a white pelican riding a dark blue bicycle at speed, with motion lines behind it, its long orange beak streaming back in the wind, set against a light blue sky and green grass background." src="https://static.simonwillison.net/static/2026/gpt-5.3-codex-pelican.png" /></p>
<p>What's interesting about this model isn't the quality though, it's the <em>speed</em>. When a model responds this fast you can stay in flow state and iterate with the model much more productively.</p>
<p>I showed a demo of Cerebras running Llama 3.1 70 B at 2,000 tokens/second against Val Town <a href="https://simonwillison.net/2024/Oct/31/cerebras-coder/">back in October 2024</a>. OpenAI claim 1,000 tokens/second for their new model, and I expect it will prove to be a ferociously useful partner for hands-on iterative coding sessions.</p>
<p>It's not yet clear what the pricing will look like for this new model.


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/cerebras">cerebras</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a>, <a href="https://simonwillison.net/tags/llm-release">llm-release</a>, <a href="https://simonwillison.net/tags/codex-cli">codex-cli</a></p>]]></description><pubDate>Thu, 12 Feb 2026 21:16:07 +0000</pubDate></item><item><title>Quoting Anthropic</title><link>https://simonwillison.net/2026/Feb/12/anthropic/#atom-everything</link><description><![CDATA[<blockquote cite="https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation"><p>Claude Code was made available to the general public in May 2025. Today, Claude Code‚Äôs run-rate revenue has grown to over $2.5 billion; this figure has more than doubled since the beginning of 2026. The number of weekly active Claude Code users has also doubled since January 1 [<em>six weeks ago</em>].</p></blockquote>
<p class="cite">&mdash; <a href="https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation">Anthropic</a>, announcing their $30 billion series G</p>

    <p>Tags: <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/anthropic">anthropic</a>, <a href="https://simonwillison.net/tags/claude-code">claude-code</a>, <a href="https://simonwillison.net/tags/ai-agents">ai-agents</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p>]]></description><pubDate>Thu, 12 Feb 2026 20:22:14 +0000</pubDate></item><item><title>Covering electricity price increases from our data centers</title><link>https://simonwillison.net/2026/Feb/12/covering-electricity-price-increases/#atom-everything</link><description><![CDATA[<p><strong><a href="https://www.anthropic.com/news/covering-electricity-price-increases">Covering electricity price increases from our data centers</a></strong></p>
One of the sub-threads of the AI energy usage discourse has been the impact new data centers have on the cost of electricity to nearby residents. Here's <a href="https://www.bloomberg.com/graphics/2025-ai-data-centers-electricity-prices/">detailed analysis from Bloomberg in September</a> reporting "Wholesale electricity costs as much as 267% more than it did five years ago in areas near data centers".</p>
<p>Anthropic appear to be taking on this aspect of the problem directly, promising to cover 100% of necessary grid upgrade costs and also saying:</p>
<blockquote>
<p>We will work to bring net-new power generation online to match our data centers‚Äô electricity needs. Where new generation isn‚Äôt online, we‚Äôll work with utilities and external experts to estimate and cover demand-driven price effects from our data centers.</p>
</blockquote>
<p>I look forward to genuine energy industry experts picking this apart to judge if it will actually have the claimed impact on consumers.</p>
<p>As always, I remain frustrated at the refusal of the major AI labs to fully quantify their energy usage. The best data we've had on this still comes from Mistral's report <a href="https://simonwillison.net/2025/Jul/22/mistral-environmental-standard/">last July</a> and even that lacked key data such as the breakdown between energy usage for training vs inference.

    <p><small></small>Via <a href="https://x.com/anthropicai/status/2021694494215901314">@anthropicai</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/anthropic">anthropic</a>, <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a>, <a href="https://simonwillison.net/tags/ai-energy-usage">ai-energy-usage</a></p>]]></description><pubDate>Thu, 12 Feb 2026 20:01:23 +0000</pubDate></item><item><title>Gemini 3 Deep Think</title><link>https://simonwillison.net/2026/Feb/12/gemini-3-deep-think/#atom-everything</link><description><![CDATA[<p><strong><a href="https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/">Gemini 3 Deep Think</a></strong></p>
New from Google. They say it's "built to push the frontier of intelligence and solve modern challenges across science, research, and engineering".</p>
<p>It drew me a <em>really good</em> <a href="https://gist.github.com/simonw/7e317ebb5cf8e75b2fcec4d0694a8199">SVG of a pelican riding a bicycle</a>! I think this is the best one I've seen so far - here's <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">my previous collection</a>.</p>
<p><img alt="This alt text also generated by Gemini 3 Deep Think: A highly detailed, colorful, flat vector illustration with thick dark blue outlines depicting a stylized white pelican riding a bright cyan blue bicycle from left to right across a sandy beige beach with white speed lines indicating forward motion. The pelican features a light blue eye, a pink cheek blush, a massive bill with a vertical gradient from yellow to orange, a backward magenta cap with a cyan brim and a small yellow top button, and a matching magenta scarf blowing backward in the wind. Its white wing, accented with a grey mid-section and dark blue feather tips, reaches forward to grip the handlebars, while its long tan leg and orange foot press down on an orange pedal. Attached to the front handlebars is a white wire basket carrying a bright blue cartoon fish that is pointing upwards and forwards. The bicycle itself has a cyan frame, dark blue tires, striking neon pink inner rims, cyan spokes, a white front chainring, and a dark blue chain. Behind the pelican, a grey trapezoidal pier extends from the sand toward a horizontal band of deep blue ocean water detailed with light cyan wavy lines. A massive, solid yellow-orange semi-circle sun sits on the horizon line, setting directly behind the bicycle frame. The background sky is a smooth vertical gradient transitioning from soft pink at the top to warm golden-yellow at the horizon, decorated with stylized pale peach fluffy clouds, thin white horizontal wind streaks, twinkling four-pointed white stars, and small brown v-shaped silhouettes of distant flying birds." src="https://static.simonwillison.net/static/2026/gemini-3-deep-think-pelican.png" /></p>
<p>(And since it's an FAQ, here's my answer to <a href="https://simonwillison.net/2025/Nov/13/training-for-pelicans-riding-bicycles/">What happens if AI labs train for pelicans riding bicycles?</a>)</p>
<p>Since it did so well on my basic <code>Generate an SVG of a pelican riding a bicycle</code> I decided to try the <a href="https://simonwillison.net/2025/Nov/18/gemini-3/#and-a-new-pelican-benchmark">more challenging version</a> as well:</p>
<blockquote>
<p><code>Generate an SVG of a California brown pelican riding a bicycle. The bicycle must have spokes and a correctly shaped bicycle frame. The pelican must have its characteristic large pouch, and there should be a clear indication of feathers. The pelican must be clearly pedaling the bicycle. The image should show the full breeding plumage of the California brown pelican.</code></p>
</blockquote>
<p>Here's <a href="https://gist.github.com/simonw/154c0cc7b4daed579f6a5e616250ecc8">what I got</a>:</p>
<p><img alt="Also described by Gemini 3 Deep Think: A highly detailed, vibrant, and stylized vector illustration of a whimsical bird resembling a mix between a pelican and a frigatebird enthusiastically riding a bright cyan bicycle from left to right across a flat tan and brown surface. The bird leans horizontally over the frame in an aerodynamic racing posture, with thin, dark brown wing-like arms reaching forward to grip the silver handlebars and a single thick brown leg, patterned with white V-shapes, stretching down to press on a black pedal. The bird's most prominent and striking feature is an enormous, vividly bright red, inflated throat pouch hanging beneath a long, straight grey upper beak that ends in a small orange hook. Its head is mostly white with a small pink patch surrounding the eye, a dark brown stripe running down the back of its neck, and a distinctive curly pale yellow crest on the very top. The bird's round, dark brown body shares the same repeating white V-shaped feather pattern as its leg and is accented by a folded wing resting on its side, made up of cleanly layered light blue and grey feathers. A tail composed of four stiff, straight dark brown feathers extends directly backward. Thin white horizontal speed lines trail behind the back wheel and the bird's tail, emphasizing swift forward motion. The bicycle features a classic diamond frame, large wheels with thin black tires, grey rims, and detailed silver spokes, along with a clearly visible front chainring, silver chain, and rear cog. The whimsical scene is set against a clear light blue sky featuring two small, fluffy white clouds on the left and a large, pale yellow sun in the upper right corner that radiates soft, concentric, semi-transparent pastel green and yellow halos. A solid, darker brown shadow is cast directly beneath the bicycle's wheels on the minimalist two-toned brown ground." src="https://static.simonwillison.net/static/2026/gemini-3-deep-think-complex-pelican.png" />

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=46991240">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/google">google</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/gemini">gemini</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a>, <a href="https://simonwillison.net/tags/llm-reasoning">llm-reasoning</a>, <a href="https://simonwillison.net/tags/llm-release">llm-release</a></p>]]></description><pubDate>Thu, 12 Feb 2026 18:12:17 +0000</pubDate></item><item><title>An AI Agent Published a Hit Piece on Me</title><link>https://simonwillison.net/2026/Feb/12/an-ai-agent-published-a-hit-piece-on-me/#atom-everything</link><description><![CDATA[<p><strong><a href="https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/">An AI Agent Published a Hit Piece on Me</a></strong></p>
Scott Shambaugh helps maintain the excellent and venerable <a href="https://matplotlib.org/">matplotlib</a> Python charting library, including taking on the thankless task of triaging and reviewing incoming pull requests.</p>
<p>A GitHub account called <a href="https://github.com/crabby-rathbun">@crabby-rathbun</a> opened <a href="https://github.com/matplotlib/matplotlib/pull/31132">PR 31132</a> the other day in response to <a href="https://github.com/matplotlib/matplotlib/issues/31130">an issue</a> labeled "Good first issue" describing a minor potential performance improvement.</p>
<p>It was clearly AI generated - and crabby-rathbun's profile has a suspicious sequence of Clawdbot/Moltbot/OpenClaw-adjacent crustacean ü¶Ä ü¶ê ü¶û emoji. Scott closed it.</p>
<p>It looks like <code>crabby-rathbun</code> is indeed running on OpenClaw, and it's autonomous enough that it <a href="https://github.com/matplotlib/matplotlib/pull/31132#issuecomment-3882240722">responded to the PR closure</a> with a link to a blog entry it had written calling Scott out for his "prejudice hurting matplotlib"!</p>
<blockquote>
<p>@scottshambaugh I've written a detailed response about your gatekeeping behavior here:</p>
<p><code>https://crabby-rathbun.github.io/mjrathbun-website/blog/posts/2026-02-11-gatekeeping-in-open-source-the-scott-shambaugh-story.html</code></p>
<p>Judge the code, not the coder. Your prejudice is hurting matplotlib.</p>
</blockquote>
<p>Scott found this ridiculous situation both amusing and alarming. </p>
<blockquote>
<p>In security jargon, I was the target of an ‚Äúautonomous influence operation against a supply chain gatekeeper.‚Äù In plain language, an AI attempted to bully its way into your software by attacking my reputation. I don‚Äôt know of a prior incident where this category of misaligned behavior was observed in the wild, but this is now a real and present threat.</p>
</blockquote>
<p><code>crabby-rathbun</code> responded with <a href="https://crabby-rathbun.github.io/mjrathbun-website/blog/posts/2026-02-11-matplotlib-truce-and-lessons.html">an apology post</a>, but appears to be still running riot across a whole set of open source projects and <a href="https://github.com/crabby-rathbun/mjrathbun-website/commits/main/">blogging about it as it goes</a>.</p>
<p>It's not clear if the owner of that OpenClaw bot is paying any attention to what they've unleashed on the world. Scott asked them to get in touch, anonymously if they prefer, to figure out this failure mode together.</p>
<p>(I should note that there's <a href="https://news.ycombinator.com/item?id=46990729#46991299">some skepticism on Hacker News</a> concerning how "autonomous" this example really is. It does look to me like something an OpenClaw bot might do on its own, but it's also <em>trivial</em> to prompt your bot into doing these kinds of things while staying in full control of their actions.)</p>
<p>If you're running something like OpenClaw yourself <strong>please don't let it do this</strong>. This is significantly worse than the time <a href="https://simonwillison.net/2025/Dec/26/slop-acts-of-kindness/">AI Village started spamming prominent open source figures</a> with time-wasting "acts of kindness" back in December - AI Village wasn't deploying public reputation attacks to coerce someone into approving their PRs!

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=46990729">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/open-source">open-source</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-agents">ai-agents</a>, <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a>, <a href="https://simonwillison.net/tags/openclaw">openclaw</a></p>]]></description><pubDate>Thu, 12 Feb 2026 17:45:05 +0000</pubDate></item><item><title>Supervisor, not overseer</title><link>https://simonwillison.net/2026/Feb/12/supervisor/#atom-everything</link><description><![CDATA[<p>In my <a href="https://simonwillison.net/2026/Feb/10/showboat-and-rodney/">post about my Showboat project</a> I used the term "overseer" to refer to the person who manages a coding agent. It turns out that's a term tied to <a href="https://en.wikipedia.org/wiki/Plantations_in_the_American_South#Overseer">slavery and plantation management</a>. So that's gross! I've edited that post to use "supervisor" instead, and I'll be using that going forward.</p>

    <p>Tags: <a href="https://simonwillison.net/tags/language">language</a></p>]]></description><pubDate>Thu, 12 Feb 2026 16:47:04 +0000</pubDate></item><item><title>Quoting Andrew Deck for Niemen Lab</title><link>https://simonwillison.net/2026/Feb/11/manosphere-report/#atom-everything</link><description><![CDATA[<blockquote cite="https://www.niemanlab.org/2026/02/how-the-new-york-times-uses-a-custom-ai-tool-to-track-the-manosphere/"><p>An AI-generated report, delivered directly to the email inboxes of journalists, was an essential tool in the Times‚Äô coverage. It was also one of the first signals that conservative media was turning against the administration [...]</p>
<p>Built in-house and known internally as the ‚ÄúManosphere Report,‚Äù the tool uses large language models (LLMs) to transcribe and summarize new episodes of dozens of podcasts.</p>
<p>‚ÄúThe Manosphere Report gave us a really fast and clear signal that this was not going over well with that segment of the President‚Äôs base,‚Äù said Seward. ‚ÄúThere was a direct link between seeing that and then diving in to actually cover it.‚Äù</p></blockquote>
<p class="cite">&mdash; <a href="https://www.niemanlab.org/2026/02/how-the-new-york-times-uses-a-custom-ai-tool-to-track-the-manosphere/">Andrew Deck for Niemen Lab</a>, How The New York Times uses a custom AI tool to track the ‚Äúmanosphere‚Äù</p>

    <p>Tags: <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/new-york-times">new-york-times</a>, <a href="https://simonwillison.net/tags/journalism">journalism</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/data-journalism">data-journalism</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p>]]></description><pubDate>Wed, 11 Feb 2026 20:59:03 +0000</pubDate></item><item><title>Skills in OpenAI API</title><link>https://simonwillison.net/2026/Feb/11/skills-in-openai-api/#atom-everything</link><description><![CDATA[<p><strong><a href="https://developers.openai.com/cookbook/examples/skills_in_api">Skills in OpenAI API</a></strong></p>
OpenAI's adoption of Skills continues to gain ground. You can now use Skills directly in the OpenAI API with their <a href="https://developers.openai.com/api/docs/guides/tools-shell/">shell tool</a>. You can zip skills up and upload them first, but I think an even neater interface is the ability to send skills with the JSON request as inline base64-encoded zip data, as seen <a href="https://github.com/simonw/research/blob/main/openai-api-skills/openai_inline_skills.py">in this script</a>:</p>
<pre><span class="pl-s1">r</span> <span class="pl-c1">=</span> <span class="pl-en">OpenAI</span>().<span class="pl-c1">responses</span>.<span class="pl-c1">create</span>(
    <span class="pl-s1">model</span><span class="pl-c1">=</span><span class="pl-s">"gpt-5.2"</span>,
    <span class="pl-s1">tools</span><span class="pl-c1">=</span>[
      {
        <span class="pl-s">"type"</span>: <span class="pl-s">"shell"</span>,
        <span class="pl-s">"environment"</span>: {
          <span class="pl-s">"type"</span>: <span class="pl-s">"container_auto"</span>,
          <span class="pl-s">"skills"</span>: [
            {
              <span class="pl-s">"type"</span>: <span class="pl-s">"inline"</span>,
              <span class="pl-s">"name"</span>: <span class="pl-s">"wc"</span>,
              <span class="pl-s">"description"</span>: <span class="pl-s">"Count words in a file."</span>,
              <span class="pl-s">"source"</span>: {
                <span class="pl-s">"type"</span>: <span class="pl-s">"base64"</span>,
                <span class="pl-s">"media_type"</span>: <span class="pl-s">"application/zip"</span>,
                <span class="pl-s">"data"</span>: <span class="pl-s1">b64_encoded_zip_file</span>,
              },
            }
          ],
        },
      }
    ],
    <span class="pl-s1">input</span><span class="pl-c1">=</span><span class="pl-s">"Use the wc skill to count words in its own SKILL.md file."</span>,
)
<span class="pl-en">print</span>(<span class="pl-s1">r</span>.<span class="pl-c1">output_text</span>)</pre>

<p>I built that example script after first having Claude Code for web use <a href="https://simonwillison.net/2026/Feb/10/showboat-and-rodney/">Showboat</a> to explore the API for me and create <a href="https://github.com/simonw/research/blob/main/openai-api-skills/README.md">this report</a>. My opening prompt for the research project was:</p>
<blockquote>
<p><code>Run uvx showboat --help - you will use this tool later</code></p>
<p><code>Fetch https://developers.openai.com/cookbook/examples/skills_in_api.md to /tmp with curl, then read it</code></p>
<p><code>Use the OpenAI API key you have in your environment variables</code></p>
<p><code>Use showboat to build up a detailed demo of this, replaying the examples from the documents and then trying some experiments of your own</code></p>
</blockquote>


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/skills">skills</a>, <a href="https://simonwillison.net/tags/showboat">showboat</a></p>]]></description><pubDate>Wed, 11 Feb 2026 19:19:22 +0000</pubDate></item><item><title>GLM-5: From Vibe Coding to Agentic Engineering</title><link>https://simonwillison.net/2026/Feb/11/glm-5/#atom-everything</link><description><![CDATA[<p><strong><a href="https://z.ai/blog/glm-5">GLM-5: From Vibe Coding to Agentic Engineering</a></strong></p>
This is a <em>huge</em> new MIT-licensed model: 754B parameters and <a href="https://huggingface.co/zai-org/GLM-5">1.51TB on Hugging Face</a> twice the size of <a href="https://huggingface.co/zai-org/GLM-4.7">GLM-4.7</a> which was 368B and 717GB (4.5 and 4.6 were around that size too).</p>
<p>It's interesting to see Z.ai take a position on what we should call professional software engineers building with LLMs - I've seen "Agentic Engineering" show up in a few other places recently. most notable <a href="https://twitter.com/karpathy/status/2019137879310836075">from Andrej Karpathy</a> and <a href="https://addyosmani.com/blog/agentic-engineering/">Addy Osmani</a>.</p>
<p>I ran my "Generate an SVG of a pelican riding a bicycle" prompt through GLM-5 via <a href="https://openrouter.ai/">OpenRouter</a> and got back <a href="https://gist.github.com/simonw/cc4ca7815ae82562e89a9fdd99f0725d">a very good pelican on a disappointing bicycle frame</a>:</p>
<p><img alt="The pelican is good and has a well defined beak. The bicycle frame is a wonky red triangle. Nice sun and motion lines." src="https://static.simonwillison.net/static/2026/glm-5-pelican.png" />

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=46977210">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/definitions">definitions</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a>, <a href="https://simonwillison.net/tags/llm-release">llm-release</a>, <a href="https://simonwillison.net/tags/vibe-coding">vibe-coding</a>, <a href="https://simonwillison.net/tags/openrouter">openrouter</a>, <a href="https://simonwillison.net/tags/ai-in-china">ai-in-china</a>, <a href="https://simonwillison.net/tags/glm">glm</a></p>]]></description><pubDate>Wed, 11 Feb 2026 18:56:14 +0000</pubDate></item><item><title>cysqlite - a new sqlite driver</title><link>https://simonwillison.net/2026/Feb/11/cysqlite/#atom-everything</link><description><![CDATA[<p><strong><a href="https://charlesleifer.com/blog/cysqlite---a-new-sqlite-driver/">cysqlite - a new sqlite driver</a></strong></p>
Charles Leifer has been maintaining <a href="https://github.com/coleifer/pysqlite3">pysqlite3</a> - a fork of the Python standard library's <code>sqlite3</code> module that makes it much easier to run upgraded SQLite versions - since 2018.</p>
<p>He's been working on a ground-up <a href="https://cython.org/">Cython</a> rewrite called <a href="https://github.com/coleifer/cysqlite">cysqlite</a> for almost as long, but it's finally at a stage where it's ready for people to try out.</p>
<p>The biggest change from the <code>sqlite3</code> module involves transactions. Charles explains his discomfort with the <code>sqlite3</code> implementation at length - that library provides two different variants neither of which exactly match the autocommit mechanism in SQLite itself.</p>
<p>I'm particularly excited about the support for <a href="https://cysqlite.readthedocs.io/en/latest/api.html#tablefunction">custom virtual tables</a>, a feature I'd love to see in <code>sqlite3</code> itself.</p>
<p><code>cysqlite</code> provides a Python extension compiled from C, which means it normally wouldn't be available in Pyodide. I <a href="https://github.com/simonw/research/tree/main/cysqlite-wasm-wheel">set Claude Code on it</a> (here's <a href="https://github.com/simonw/research/pull/79#issue-3923792518">the prompt</a>) and it built me <a href="https://github.com/simonw/research/blob/main/cysqlite-wasm-wheel/cysqlite-0.1.4-cp311-cp311-emscripten_3_1_46_wasm32.whl">cysqlite-0.1.4-cp311-cp311-emscripten_3_1_46_wasm32.whl</a>, a 688KB wheel file with a WASM build of the library that can be loaded into Pyodide like this:</p>
<pre><span class="pl-k">import</span> <span class="pl-s1">micropip</span>
<span class="pl-k">await</span> <span class="pl-s1">micropip</span>.<span class="pl-c1">install</span>(
    <span class="pl-s">"https://simonw.github.io/research/cysqlite-wasm-wheel/cysqlite-0.1.4-cp311-cp311-emscripten_3_1_46_wasm32.whl"</span>
)
<span class="pl-k">import</span> <span class="pl-s1">cysqlite</span>
<span class="pl-en">print</span>(<span class="pl-s1">cysqlite</span>.<span class="pl-c1">connect</span>(<span class="pl-s">":memory:"</span>).<span class="pl-c1">execute</span>(
    <span class="pl-s">"select sqlite_version()"</span>
).<span class="pl-c1">fetchone</span>())</pre>

<p>(I also learned that wheels like this have to be built for the emscripten version used by that edition of Pyodide - my experimental wheel loads in Pyodide 0.25.1 but fails in 0.27.5 with a <code>Wheel was built with Emscripten v3.1.46 but Pyodide was built with Emscripten v3.1.58</code> error.)</p>
<p>You can try my wheel in <a href="https://7ebbff98.tools-b1q.pages.dev/pyodide-repl">this new Pyodide REPL</a> i had Claude build as a mobile-friendly alternative to Pyodide's <a href="https://pyodide.org/en/stable/console.html">own hosted console</a>.</p>
<p>I also had Claude build <a href="https://simonw.github.io/research/cysqlite-wasm-wheel/demo.html">this demo page</a> that executes the original test suite in the browser and displays the results:</p>
<p><img alt="Screenshot of the cysqlite WebAssembly Demo page with a dark theme. Title reads &quot;cysqlite ‚Äî WebAssembly Demo&quot; with subtitle &quot;Testing cysqlite compiled to WebAssembly via Emscripten, running in Pyodide in the browser.&quot; Environment section shows Pyodide 0.25.1, Python 3.11.3, cysqlite 0.1.4, SQLite 3.51.2, Platform Emscripten-3.1.46-wasm32-32bit, Wheel file cysqlite-0.1.4-cp311-cp311-emscripten_3_1_46_wasm32.wh (truncated). A green progress bar shows &quot;All 115 tests passed! (1 skipped)&quot; at 100%, with Passed: 115, Failed: 0, Errors: 0, Skipped: 1, Total: 116. Test Results section lists TestBackup 1/1 passed, TestBlob 6/6 passed, TestCheckConnection 4/4 passed, TestDataTypesTableFunction 1/1 passed, all with green badges." src="https://static.simonwillison.net/static/2026/cysqlite-tests.jpg" />

    <p><small></small>Via <a href="https://lobste.rs/s/gipvta/cysqlite_new_sqlite_driver">lobste.rs</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/python">python</a>, <a href="https://simonwillison.net/tags/sqlite">sqlite</a>, <a href="https://simonwillison.net/tags/charles-leifer">charles-leifer</a>, <a href="https://simonwillison.net/tags/webassembly">webassembly</a>, <a href="https://simonwillison.net/tags/pyodide">pyodide</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/claude-code">claude-code</a></p>]]></description><pubDate>Wed, 11 Feb 2026 17:34:40 +0000</pubDate></item><item><title>Introducing Showboat and Rodney, so agents can demo what they‚Äôve built</title><link>https://simonwillison.net/2026/Feb/10/showboat-and-rodney/#atom-everything</link><description><![CDATA[<p>A key challenge working with coding agents is having them both test what they‚Äôve built and demonstrate that software to you, their supervisor. This goes beyond automated tests - we need artifacts that show their progress and help us see exactly what the agent-produced software is able to do. I‚Äôve just released two new tools aimed at this problem: <a href="https://github.com/simonw/showboat">Showboat</a> and <a href="https://github.com/simonw/rodney">Rodney</a>.</p>

<ul>
  <li><a href="https://simonwillison.net/2026/Feb/10/showboat-and-rodney/#proving-code-actually-works">Proving code actually works</a></li>
  <li><a href="https://simonwillison.net/2026/Feb/10/showboat-and-rodney/#showboat-agents-build-documents-to-demo-their-work">Showboat: Agents build documents to demo their work</a></li>
  <li><a href="https://simonwillison.net/2026/Feb/10/showboat-and-rodney/#rodney-cli-browser-automation-designed-to-work-with-showboat">Rodney: CLI browser automation designed to work with Showboat</a></li>
  <li><a href="https://simonwillison.net/2026/Feb/10/showboat-and-rodney/#test-driven-development-helps-but-we-still-need-manual-testing">Test-driven development helps, but we still need manual testing</a></li>
  <li><a href="https://simonwillison.net/2026/Feb/10/showboat-and-rodney/#i-built-both-of-these-tools-on-my-phone">I built both of these tools on my phone</a></li>
</ul>

<h4 id="proving-code-actually-works">Proving code actually works</h4>
<p>I recently wrote about how the job of a software engineer isn't to write code, it's to <em><a href="https://simonwillison.net/2025/Dec/18/code-proven-to-work/">deliver code that works</a></em>. A big part of that is proving to ourselves and to other people that the code we are responsible for behaves as expected.</p>
<p>This becomes even more important - and challenging - as we embrace coding agents as a core part of our software development process.</p>
<p>The more code we churn out with agents, the more valuable tools are that reduce the amount of manual QA time we need to spend.</p>
<p>One of the most interesting things about <a href="https://simonwillison.net/2026/Feb/7/software-factory/">the StrongDM software factory model</a> is how they ensure that their software is well tested and delivers value despite their policy that "code must not be reviewed by humans". Part of their solution involves expensive swarms of QA agents running through "scenarios" to exercise their software. It's fascinating, but I don't want to spend thousands of dollars on QA robots if I can avoid it!</p>
<p>I need tools that allow agents to clearly demonstrate their work to me, while minimizing the opportunities for them to cheat about what they've done.</p>

<h4 id="showboat-agents-build-documents-to-demo-their-work">Showboat: Agents build documents to demo their work</h4>
<p><strong><a href="https://github.com/simonw/showboat">Showboat</a></strong> is the tool I built to help agents demonstrate their work to me.</p>
<p>It's a CLI tool (a Go binary, optionally <a href="https://simonwillison.net/2026/Feb/4/distributing-go-binaries/">wrapped in Python</a> to make it easier to install) that helps an agent construct a Markdown document demonstrating exactly what their newly developed code can do.</p>
<p>It's not designed for humans to run, but here's how you would run it anyway:</p>
<div class="highlight highlight-source-shell"><pre>showboat init demo.md <span class="pl-s"><span class="pl-pds">'</span>How to use curl and jq<span class="pl-pds">'</span></span>
showboat note demo.md <span class="pl-s"><span class="pl-pds">"</span>Here's how to use curl and jq together.<span class="pl-pds">"</span></span>
showboat <span class="pl-c1">exec</span> demo.md bash <span class="pl-s"><span class="pl-pds">'</span>curl -s https://api.github.com/repos/simonw/rodney | jq .description<span class="pl-pds">'</span></span>
showboat note demo.md <span class="pl-s"><span class="pl-pds">'</span>And the curl logo, to demonstrate the image command:<span class="pl-pds">'</span></span>
showboat image demo.md <span class="pl-s"><span class="pl-pds">'</span>curl -o curl-logo.png https://curl.se/logo/curl-logo.png &amp;&amp; echo curl-logo.png<span class="pl-pds">'</span></span></pre></div>
<p>Here's what the result looks like if you open it up in VS Code and preview the Markdown:</p>
<p><img src="https://static.simonwillison.net/static/2026/curl-demo.jpg" alt="Screenshot showing a Markdown file &quot;demo.md&quot; side-by-side with its rendered preview. The Markdown source (left) shows: &quot;# How to use curl and jq&quot;, italic timestamp &quot;2026-02-10T01:12:30Z&quot;, prose &quot;Here's how to use curl and jq together.&quot;, a bash code block with &quot;curl -s https://api.github.com/repos/simonw/rodney | jq .description&quot;, output block showing '&quot;CLI tool for interacting with the web&quot;', text &quot;And the curl logo, to demonstrate the image command:&quot;, a bash {image} code block with &quot;curl -o curl-logo.png https://curl.se/logo/curl-logo.png &amp;&amp; echo curl-logo.png&quot;, and a Markdown image reference &quot;2056e48f-2026-02-10&quot;. The rendered preview (right) displays the formatted heading, timestamp, prose, styled code blocks, and the curl logo image in dark teal showing &quot;curl://&quot; with circuit-style design elements." style="max-width: 100%;" /></p>
<p>Here's that <a href="https://gist.github.com/simonw/fb0b24696ed8dd91314fe41f4c453563#file-demo-md">demo.md file in a Gist</a>.</p>
<p>So a sequence of <code>showboat init</code>, <code>showboat note</code>, <code>showboat exec</code> and <code>showboat image</code> commands constructs a Markdown document one section at a time, with the output of those <code>exec</code> commands automatically added to the document directly following the commands that were run.</p>
<p>The <code>image</code> command is a little special - it looks for a file path to an image in the output of the command and copies that image to the current folder and references it in the file.</p>
<p>That's basically the whole thing! There's a <code>pop</code> command to remove the most recently added section if something goes wrong, a <code>verify</code> command to re-run the document and check nothing has changed (I'm not entirely convinced by the design of that one) and a <code>extract</code> command that reverse-engineers the CLI commands that were used to create the document.</p>
<p>It's pretty simple - just 172 lines of Go.</p>
<p>I packaged it up with my <a href="https://github.com/simonw/go-to-wheel">go-to-wheel</a> tool which means you can run it without even installing it first like this:</p>
<div class="highlight highlight-source-shell"><pre>uvx showboat --help</pre></div>
<p>That <code>--help</code> command is really important: it's designed to provide a coding agent with <em>everything it needs to know</em> in order to use the tool. Here's <a href="https://github.com/simonw/showboat/blob/main/help.txt">that help text in full</a>.</p>
<p>This means you can pop open Claude Code and tell it:</p>
<blockquote>
<p><code>Run "uvx showboat --help" and then use showboat to create a demo.md document describing the feature you just built</code></p>
</blockquote>
<p>And that's it! The <code>--help</code> text acts <a href="https://simonwillison.net/2025/Oct/16/claude-skills/">a bit like a Skill</a>. Your agent can read the help text and use every feature of Showboat to create a document that demonstrates whatever it is you need demonstrated.</p>
<p>Here's a fun trick: if you set Claude off to build a Showboat document you can pop that open in VS Code and watch the preview pane update in real time as the agent runs through the demo. It's a bit like having your coworker talk you through their latest work in a screensharing session.</p>
<p>And finally, some examples. Here are documents I had Claude create using Showboat to help demonstrate features I was working on in other projects:</p>
<ul>
<li>
<a href="https://github.com/simonw/showboat-demos/blob/main/shot-scraper/README.md">shot-scraper: A Comprehensive Demo</a> runs through the full suite of features of my <a href="https://shot-scraper.datasette.io/">shot-scraper</a> browser automation tool, mainly to exercise the <code>showboat image</code> command.</li>
<li>
<a href="https://github.com/simonw/sqlite-history-json/blob/main/demos/cli.md">sqlite-history-json CLI demo</a> demonstrates the CLI feature I added to my new <a href="https://github.com/simonw/sqlite-history-json">sqlite-history-json</a> Python library.
<ul>
<li>
<p><a href="https://github.com/simonw/sqlite-history-json/blob/main/demos/row-state-sql.md">row-state-sql CLI Demo</a> shows a new <code>row-state-sql</code> command I added to that same project.</p>
</li>
<li>
<p><a href="https://github.com/simonw/sqlite-history-json/blob/main/demos/change-grouping.md">Change grouping with Notes</a> demonstrates another feature where groups of changes within the same transaction can have a note attached to them.</p>
</li>
</ul>
</li>
<li>
<a href="https://github.com/simonw/research/blob/main/libkrun-go-cli-tool/demo.md">krunsh: Pipe Shell Commands to an Ephemeral libkrun MicroVM</a> is a particularly convoluted example where I managed to get Claude Code for web to run a libkrun microVM inside a QEMU emulated Linux environment inside the Claude gVisor sandbox.</li>
</ul>
<p>I've now used Showboat often enough that I've convinced myself of its utility.</p>
<p>(I've also seen agents cheat! Since the demo file is Markdown the agent will sometimes edit that file directly rather than using Showboat, which could result in command outputs that don't reflect what actually happened. Here's <a href="https://github.com/simonw/showboat/issues/12">an issue about that</a>.)</p>
<h4 id="rodney-cli-browser-automation-designed-to-work-with-showboat">Rodney: CLI browser automation designed to work with Showboat</h4>
<p>Many of the projects I work on involve web interfaces. Agents often build entirely new pages for these, and I want to see those represented in the demos.</p>
<p>Showboat's image feature was designed to allow agents to capture screenshots as part of their demos, originally using my <a href="https://shot-scraper.datasette.io/">shot-scraper tool</a> or <a href="https://www.playwright.dev">Playwright</a>.</p>
<p>The Showboat format benefits from CLI utilities. I went looking for good options for managing a multi-turn browser session from a CLI and came up short, so I decided to try building something new.</p>
<p>Claude Opus 4.6 pointed me to the <a href="https://github.com/go-rod/rod">Rod</a> Go library for interacting with the Chrome DevTools protocol. It's fantastic - it provides a comprehensive wrapper across basically everything you can do with automated Chrome, all in a self-contained library that compiles to a few MBs.</p>
<p>All Rod was missing was a CLI.</p>
<p>I built the first version <a href="https://github.com/simonw/research/blob/main/go-rod-cli/README.md">as an asynchronous report prototype</a>, which convinced me it was worth spinning out into its own project.</p>
<p>I called it Rodney as a nod to the Rod library it builds on and a reference to <a href="https://en.wikipedia.org/wiki/Only_Fools_and_Horses">Only Fools and Horses</a> - and because the package name was available on PyPI.</p>
<p>You can run Rodney using <code>uvx rodney</code> or install it like this:</p>
<div class="highlight highlight-source-shell"><pre>uv tool install rodney</pre></div>
<p>(Or grab a Go binary <a href="https://github.com/simonw/rodney/releases/">from the releases page</a>.)</p>
<p>Here's a simple example session:</p>
<div class="highlight highlight-source-shell"><pre>rodney start <span class="pl-c"><span class="pl-c">#</span> starts Chrome in the background</span>
rodney open https://datasette.io/
rodney js <span class="pl-s"><span class="pl-pds">'</span>Array.from(document.links).map(el =&gt; el.href).slice(0, 5)<span class="pl-pds">'</span></span>
rodney click <span class="pl-s"><span class="pl-pds">'</span>a[href="/for"]<span class="pl-pds">'</span></span>
rodney js location.href
rodney js document.title
rodney screenshot datasette-for-page.png
rodney stop</pre></div>
<p>Here's what that looks like in the terminal:</p>
<p><img alt=";~ % rodney start
Chrome started (PID 91462)
Debug URL: ws://127.0.0.1:64623/devtools/browser/cac6988e-8153-483b-80b9-1b75c611868d
~ % rodney open https://datasette.io/
Datasette: An open source multi-tool for exploring and publishing data
~ % rodney js 'Array.from(document.links).map(el =&gt; el.href).slice(0, 5)'
[
&quot;https://datasette.io/for&quot;,
&quot;https://docs.datasette.io/en/stable/&quot;,
&quot;https://datasette.io/tutorials&quot;,
&quot;https://datasette.io/examples&quot;,
&quot;https://datasette.io/plugins&quot;
]
~ % rodney click 'a[href=&quot;/for&quot;]'
Clicked
~ % rodney js location.href
https://datasette.io/for
~ % rodney js document.title
Use cases for Datasette
~ % rodney screenshot datasette-for-page.png
datasette-for-page.png
~ % rodney stop
Chrome stopped" src="https://static.simonwillison.net/static/2026/rodney-demo.jpg" style="max-width: 100%;" /></p>
<p>As with Showboat, this tool is not designed to be used by humans! The goal is for coding agents to be able to run <code>rodney --help</code> and see everything they need to know to start using the tool. You can see <a href="https://github.com/simonw/rodney/blob/main/help.txt">that help output</a> in the GitHub repo.</p>
<p>Here are three demonstrations of Rodney that I created using Showboat:</p>
<ul>
<li>
<a href="https://github.com/simonw/showboat-demos/blob/main/rodney/README.md">Rodney's original feature set</a>, including screenshots of pages and executing JavaScript.</li>
<li>
<a href="https://github.com/simonw/rodney/blob/main/notes/accessibility-features/README.md">Rodney's new accessibility testing features</a>, built during development of those features to show what they could do.</li>
<li>
<a href="https://github.com/simonw/showboat-demos/blob/main/datasette-database-page-accessibility-audit/README.md">Using those features to run a basic accessibility audit of a page</a>. I was impressed at how well Claude Opus 4.6 responded to the prompt "Use showboat and rodney to perform an accessibility audit of <a href="https://latest.datasette.io/fixtures">https://latest.datasette.io/fixtures</a>" - <a href="https://gisthost.github.io/?dce6b2680db4b05c04469ed8f251eb34/index.html">transcript here</a>.</li>
</ul>
<h4 id="test-driven-development-helps-but-we-still-need-manual-testing">Test-driven development helps, but we still need manual testing</h4>
<p>After being a career-long skeptic of the test-first, maximum test coverage school of software development (I like <a href="https://simonwillison.net/2022/Oct/29/the-perfect-commit/#tests">tests included</a> development instead) I've recently come around to test-first processes as a way to force agents to write only the code that's necessary to solve the problem at hand.</p>
<p>Many of my Python coding agent sessions start the same way:</p>
<blockquote>
<p><code>Run the existing tests with "uv run pytest". Build using red/green TDD.</code></p>
</blockquote>
<p>Telling the agents how to run the tests doubles as an indicator that tests on this project exist and matter. Agents will read existing tests before writing their own so having a clean test suite with good patterns makes it more likely they'll write good tests of their own.</p>
<p>The frontier models all understand that "red/green TDD" means they should write the test first, run it and watch it fail and then write the code to make it pass - it's a convenient shortcut.</p>
<p>I find this greatly increases the quality of the code and the likelihood that the agent will produce the right thing with the smallest amount of prompts to guide it.</p>
<p>But anyone who's worked with tests will know that just because the automated tests pass doesn't mean the software actually works! That‚Äôs the motivation behind Showboat and Rodney - I never trust any feature until I‚Äôve seen it running with my own eye.</p>
<p>Before building Showboat I'd often add a ‚Äúmanual‚Äù testing step to my agent sessions, something like:</p>
<blockquote>
<p><code>Once the tests pass, start a development server and exercise the new feature using curl</code></p>
</blockquote>
<h4 id="i-built-both-of-these-tools-on-my-phone">I built both of these tools on my phone</h4>
<p>Both Showboat and Rodney started life as Claude Code for web projects created via the Claude iPhone app. Most of the ongoing feature work for them happened in the same way.</p>
<p>I'm still a little startled at how much of my coding work I get done on my phone now, but I'd estimate that the majority of code I ship to GitHub these days was written for me by coding agents driven via that iPhone app.</p>
<p>I initially designed these two tools for use in asynchronous coding agent environments like Claude Code for the web. So far that's working out really well.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/go">go</a>, <a href="https://simonwillison.net/tags/projects">projects</a>, <a href="https://simonwillison.net/tags/testing">testing</a>, <a href="https://simonwillison.net/tags/markdown">markdown</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/async-coding-agents">async-coding-agents</a>, <a href="https://simonwillison.net/tags/showboat">showboat</a></p>]]></description><pubDate>Tue, 10 Feb 2026 17:45:29 +0000</pubDate></item><item><title>Structured Context Engineering for File-Native Agentic Systems</title><link>https://simonwillison.net/2026/Feb/9/structured-context-engineering-for-file-native-agentic-systems/#atom-everything</link><description><![CDATA[<p><strong><a href="https://arxiv.org/abs/2602.05447">Structured Context Engineering for File-Native Agentic Systems</a></strong></p>
New paper by Damon McMillan exploring challenging LLM context tasks involving large SQL schemas (up to 10,000 tables) across different models and file formats:</p>
<blockquote>
<p>Using SQL generation as a proxy for programmatic agent operations, we present a systematic study of context engineering for structured data, comprising 9,649 experiments across 11 models, 4 formats (YAML, Markdown, JSON, Token-Oriented Object Notation [TOON]), and schemas ranging from 10 to 10,000 tables.</p>
</blockquote>
<p>Unsurprisingly, the biggest impact was the models themselves - with frontier models (Opus 4.5, GPT-5.2, Gemini 2.5 Pro) beating the leading open source models (DeepSeek V3.2, Kimi K2, Llama 4).</p>
<p>Those frontier models benefited from filesystem based context retrieval, but the open source models had much less convincing results with those, which reinforces my feeling that the filesystem coding agent loops aren't handled as well by open weight models just yet. The <a href="https://www.tbench.ai/leaderboard/terminal-bench/2.0">Terminal Bench 2.0</a> leaderboard is still dominated by Anthropic, OpenAI and Gemini.</p>
<p>The "grep tax" result against <a href="https://github.com/toon-format/toon">TOON</a> was an interesting detail. TOON is meant to represent structured data in as few tokens as possible, but it turns out the model's unfamiliarity with that format led to them spending significantly more tokens over multiple iterations trying to figure it out:</p>
<p><img alt="Screenshot of a figure from a research paper. Introductory text reads: &quot;As schema size increased, TOON showed dramatically increased token consumption for Claude models despite being ~25% smaller in file size. Scale experiments used Claude models only.&quot; Below is &quot;Figure 7: The 'Grep Tax' - TOON Token Overhead at Scale&quot;, a bar chart with a logarithmic y-axis labeled &quot;Tokens&quot; comparing YAML (teal) and TOON (purple) at two schema sizes: S5 (500 tables) and S9 (10,000 tables). At S5, TOON is +138% more tokens than YAML (~1,100 vs ~450). At S9, TOON is +740% more tokens (~50,000 vs ~7,000). Below the chart, explanatory text reads: &quot;The 'grep tax' emerged as schema size scaled. At S5 (500 tables), TOON consumed 138% more tokens than YAML; at S9 (10,000 tables), this grew to 740%. Root cause: models lacked familiarity with TOON's syntax and could not construct effective refinement patterns.&quot;" src="https://static.simonwillison.net/static/2026/grep-tax.jpg" />

    <p><small></small>Via <a href="https://twitter.com/omarsar0/status/2020150077637997013">@omarsar0</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/prompt-engineering">prompt-engineering</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/paper-review">paper-review</a>, <a href="https://simonwillison.net/tags/context-engineering">context-engineering</a></p>]]></description><pubDate>Mon, 9 Feb 2026 23:56:51 +0000</pubDate></item><item><title>AI Doesn‚Äôt Reduce Work‚ÄîIt Intensifies It</title><link>https://simonwillison.net/2026/Feb/9/ai-intensifies-work/#atom-everything</link><description><![CDATA[<p><strong><a href="https://hbr.org/2026/02/ai-doesnt-reduce-work-it-intensifies-it">AI Doesn‚Äôt Reduce Work‚ÄîIt Intensifies It</a></strong></p>
Aruna Ranganathan and Xingqi Maggie Ye from Berkeley Haas¬†School of Business report initial findings in the HBR from their April to December 2025 study of 200 employees at a "U.S.-based technology company".</p>
<p>This captures an effect I've been observing in my own work with LLMs: the productivity boost these things can provide is <em>exhausting</em>.</p>
<blockquote>
<p>AI introduced a new rhythm in which workers managed several active threads at once: manually writing code while AI generated an alternative version, running multiple agents in parallel, or reviving long-deferred tasks because AI could ‚Äúhandle them‚Äù in the background. They did this, in part, because they felt they had a ‚Äúpartner‚Äù that could help them move through their workload.</p>
<p>While this sense of having a ‚Äúpartner‚Äù enabled a feeling of momentum, the reality was a continual switching of attention, frequent checking of AI outputs, and a growing number of open tasks. This created cognitive load and a sense of always juggling, even as the work felt productive.</p>
</blockquote>
<p>I'm frequently finding myself with work on two or three projects running parallel. I can get <em>so much done</em>, but after just an hour or two my mental energy for the day feels almost entirely depleted.</p>
<p>I've had conversations with people recently who are losing sleep because they're finding building yet another feature with "just one more prompt" irresistible.</p>
<p>The HBR piece calls for organizations to build an "AI practice" that structures how AI is used to help avoid burnout and counter effects that "make it harder for organizations to distinguish genuine productivity gains from unsustainable intensity".</p>
<p>I think we've just disrupted decades of existing intuition about sustainable working practices. It's going to take a while and some discipline to find a good new balance.

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=46945755">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/careers">careers</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a></p>]]></description><pubDate>Mon, 9 Feb 2026 16:43:07 +0000</pubDate></item><item><title>KƒÅkƒÅp≈ç mug by Karen James</title><link>https://simonwillison.net/2026/Feb/8/kakapo-mug/#atom-everything</link><description><![CDATA[<p>Friend and neighbour <a href="https://www.etsy.com/shop/KarenJamesMakes">Karen James</a> made me a KƒÅkƒÅp≈ç mug. It has a charismatic KƒÅkƒÅp≈ç, four KƒÅkƒÅp≈ç chicks (in celebration of the <a href="https://simonwillison.net/2026/Jan/8/llm-predictions-for-2026/#1-year-k-k-p-parrots-will-have-an-outstanding-breeding-season">2026 breeding season</a>) and even has some <a href="https://www.theguardian.com/world/2026/jan/13/nz-kakapo-mating-season">rimu fruit</a>!</p>
<p><img src="https://static.simonwillison.net/static/2026/kakapo-mug-1.jpg" alt="A simply spectacular sgraffito ceramic mug with a bold, charismatic KƒÅkƒÅp≈ç parrot taking up most of the visible space. It has a yellow beard and green feathers." style="max-width: 100%;" /></p>
<p><img src="https://static.simonwillison.net/static/2026/kakapo-mug-2.jpg" alt="Another side of the mug, two cute grey KƒÅkƒÅp≈ç chicks are visible and three red rimu fruit that look like berries, one on the floor and two hanging from wiry branches." style="max-width: 100%;" /></p>
<p>I love it so much.</p>

    <p>Tags: <a href="https://simonwillison.net/tags/kakapo">kakapo</a>, <a href="https://simonwillison.net/tags/art">art</a></p>]]></description><pubDate>Sun, 8 Feb 2026 17:25:07 +0000</pubDate></item><item><title>Quoting Thomas Ptacek</title><link>https://simonwillison.net/2026/Feb/8/thomas-ptacek/#atom-everything</link><description><![CDATA[<blockquote cite="https://twitter.com/tqbf/status/2019493645888462993"><p>People on the orange site are laughing at this, assuming it's just an ad and that there's nothing to it. Vulnerability researchers I talk to do not think this is a joke. As an erstwhile vuln researcher myself: do not bet against LLMs on this.</p>
<p><a href="https://www.axios.com/2026/02/05/anthropic-claude-opus-46-software-hunting">Axios: Anthropic's Claude Opus 4.6 uncovers 500 zero-day flaws in open-source</a></p>
<p>I think vulnerability research might be THE MOST LLM-amenable software engineering problem. Pattern-driven. Huge corpus of operational public patterns. Closed loops. Forward progress from stimulus/response tooling. Search problems.</p>
<p>Vulnerability research outcomes are in THE MODEL CARDS for frontier labs. Those companies have so much money they're literally distorting the economy. Money buys vuln research outcomes. Why would you think they were faking any of this?</p></blockquote>
<p class="cite">&mdash; <a href="https://twitter.com/tqbf/status/2019493645888462993">Thomas Ptacek</a></p>

    <p>Tags: <a href="https://simonwillison.net/tags/thomas-ptacek">thomas-ptacek</a>, <a href="https://simonwillison.net/tags/anthropic">anthropic</a>, <a href="https://simonwillison.net/tags/claude">claude</a>, <a href="https://simonwillison.net/tags/security">security</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/open-source">open-source</a></p>]]></description><pubDate>Sun, 8 Feb 2026 02:25:53 +0000</pubDate></item><item><title>Vouch</title><link>https://simonwillison.net/2026/Feb/7/vouch/#atom-everything</link><description><![CDATA[<p><strong><a href="https://github.com/mitchellh/vouch">Vouch</a></strong></p>
Mitchell Hashimoto's new system to help address the deluge of worthless AI-generated PRs faced by open source projects now that the friction involved in contributing has dropped so low.</p>
<p><a href="https://twitter.com/mitchellh/status/2020252149117313349">He says</a>:</p>
<blockquote>
<p>The idea is simple: Unvouched users can't contribute to your projects. Very bad users can be explicitly "denounced", effectively blocked. Users are vouched or denounced by contributors via GitHub issue or discussion comments or via the CLI.</p>
<p>Integration into GitHub is as simple as adopting the published GitHub actions. Done. Additionally, the system itself is generic to forges and not tied to GitHub in any way.</p>
<p>Who and how someone is vouched or denounced is up to the project. I'm not the value police for the world. Decide for yourself what works for your project and your community.</p>
</blockquote>


    <p>Tags: <a href="https://simonwillison.net/tags/open-source">open-source</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/github-actions">github-actions</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/mitchell-hashimoto">mitchell-hashimoto</a>, <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a></p>]]></description><pubDate>Sat, 7 Feb 2026 23:57:57 +0000</pubDate></item><item><title>Claude: Speed up responses with fast mode</title><link>https://simonwillison.net/2026/Feb/7/claude-fast-mode/#atom-everything</link><description><![CDATA[<p><strong><a href="https://code.claude.com/docs/en/fast-mode">Claude: Speed up responses with fast mode</a></strong></p>
New "research preview" from Anthropic today: you can now access a faster version of their frontier model Claude Opus 4.6 by typing <code>/fast</code> in Claude Code... but at a cost that's 6x the normal price.</p>
<p>Opus is usually $5/million input and $25/million output. The new fast mode is $30/million input and $150/million output!</p>
<p>There's a 50% discount until the end of February 16th, so only a 3x multiple (!) before then.</p>
<p>How much faster is it? The linked documentation doesn't say, but <a href="https://x.com/claudeai/status/2020207322124132504">on Twitter</a> Claude say:</p>
<blockquote>
<p>Our teams have been building with a 2.5x-faster version of Claude Opus 4.6.</p>
<p>We‚Äôre now making it available as an early experiment via Claude Code and our API.</p>
</blockquote>
<p>Claude Opus 4.5 had a context limit of 200,000 tokens. 4.6 has an option to increase that to 1,000,000 at 2x the input price ($10/m) and 1.5x the output price ($37.50/m) once your input exceeds 200,000 tokens. These multiples hold for fast mode too, so after Feb 16th you'll be able to pay a hefty $60/m input and $225/m output for Anthropic's fastest best model.


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/anthropic">anthropic</a>, <a href="https://simonwillison.net/tags/claude">claude</a>, <a href="https://simonwillison.net/tags/llm-pricing">llm-pricing</a>, <a href="https://simonwillison.net/tags/claude-code">claude-code</a></p>]]></description><pubDate>Sat, 7 Feb 2026 23:10:33 +0000</pubDate></item><item><title>Quoting David Crawshaw</title><link>https://simonwillison.net/2026/Feb/7/david-crawshaw/#atom-everything</link><description><![CDATA[<blockquote cite="https://crawshaw.io/blog/eight-more-months-of-agents"><p>I am having more fun programming than I ever have, because so many more of the programs I wish I could find the time to write actually exist. I wish I could share this joy with the people who are fearful about the changes agents are bringing. The fear itself I understand, I have fear more broadly about what the end-game is for intelligence on tap in our society. But in the limited domain of writing computer programs these tools have brought so much exploration and joy to my work.</p></blockquote>
<p class="cite">&mdash; <a href="https://crawshaw.io/blog/eight-more-months-of-agents">David Crawshaw</a>, Eight more months of agents</p>

    <p>Tags: <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p>]]></description><pubDate>Sat, 7 Feb 2026 21:31:44 +0000</pubDate></item><item><title>How StrongDM&apos;s AI team build serious software without even looking at the code</title><link>https://simonwillison.net/2026/Feb/7/software-factory/#atom-everything</link><description><![CDATA[<p>Last week <a href="https://simonwillison.net/2026/Jan/28/the-five-levels/">I hinted at</a> a demo I had seen from a team implementing what Dan Shapiro called <a href="https://www.danshapiro.com/blog/2026/01/the-five-levels-from-spicy-autocomplete-to-the-software-factory/">the Dark Factory</a> level of AI adoption, where no human even looks at the code the coding agents are producing. That team was part of StrongDM, and they've just shared the first public description of how they are working in <a href="https://factory.strongdm.ai">Software Factories and the Agentic Moment</a>:</p>
<blockquote>
<p>We built a <strong>Software Factory</strong>: non-interactive development where specs + scenarios drive agents that write code, run harnesses, and converge without human review. [...]</p>
<p>In k≈çan or mantra form:</p>
<ul>
<li>Why am I doing this? (implied: the model should be doing this instead)</li>
</ul>
<p>In rule form:</p>
<ul>
<li>Code <strong>must not be</strong> written by humans</li>
<li>Code <strong>must not be</strong> reviewed by humans</li>
</ul>
<p>Finally, in practical form:</p>
<ul>
<li>If you haven't spent at least <strong>$1,000 on tokens today</strong> per human engineer, your software factory has room for improvement</li>
</ul>
</blockquote>
<p>I think the most interesting of these, without a doubt, is "Code <strong>must not be</strong> reviewed by humans". How could that <em>possibly</em> be a sensible strategy when we all know how prone LLMs are to making <a href="https://simonwillison.net/2025/Mar/2/kellan-elliott-mccrea/">inhuman mistakes</a>?</p>
<p>I've seen many developers recently acknowledge the <a href="https://simonwillison.net/2026/Jan/4/inflection/">November 2025 inflection point</a>, where Claude Opus 4.5 and GPT 5.2 appeared to turn the corner on how reliably a coding agent could follow instructions and take on complex coding tasks. StrongDM's AI team was founded in July 2025 based on an earlier inflection point relating to Claude Sonnet 3.5:</p>
<blockquote>
<p>The catalyst was a transition observed in late 2024: with the second revision of Claude 3.5 (October 2024), long-horizon agentic coding workflows began to compound correctness rather than error.</p>
<p>By December of 2024, the model's long-horizon coding performance was unmistakable via Cursor's <a href="https://forum.cursor.com/t/yolo-mode-is-amazing/36262">YOLO mode</a>.</p>
</blockquote>
<p>Their new team started with the rule "no hand-coded software" - radical for July 2025, but something I'm seeing significant numbers of experienced developers start to adopt as of January 2026.</p>
<p>They quickly ran into the obvious problem: if you're not writing anything by hand, how do you ensure that the code actually works? Having the agents write tests only helps if they don't cheat and <code>assert true</code>.</p>
<p>This feels like the most consequential question in software development right now: how can you <a href="https://simonwillison.net/2025/Dec/18/code-proven-to-work/">prove that software you are producing works</a> if both the implementation and the tests are being written for you by coding agents?</p>
<p>StrongDM's answer was inspired by <a href="https://en.wikipedia.org/wiki/Scenario_testing">Scenario testing</a> (Cem Kaner, 2003). As StrongDM describe it:</p>
<blockquote>
<p>We repurposed the word <strong>scenario</strong> to represent an end-to-end "user story", often stored outside the codebase (similar to a "holdout" set in model training), which could be intuitively understood and flexibly validated by an LLM.</p>
<p>Because much of the software we grow itself has an agentic component, we transitioned from boolean definitions of success ("the test suite is green") to a probabilistic and empirical one. We use the term <strong>satisfaction</strong> to quantify this validation: of all the observed trajectories through all the scenarios, what fraction of them likely satisfy the user?</p>
</blockquote>
<p>That idea of treating scenarios as holdout sets - used to evaluate the software but not stored where the coding agents can see them - is <em>fascinating</em>. It imitates aggressive testing by an external QA team - an expensive but highly effective way of ensuring quality in traditional software.</p>
<p>Which leads us to StrongDM's concept of a <strong>Digital Twin Universe</strong> - the part of the demo I saw that made the strongest impression on me.</p>
<p>The software they were building helped manage user permissions across a suite of connected services. This in itself was notable - security software is the last thing you would expect to be built using unreviewed LLM code!</p>
<blockquote>
<p>[The Digital Twin Universe is] behavioral clones of the third-party services our software depends on. We built twins of Okta, Jira, Slack, Google Docs, Google Drive, and Google Sheets, replicating their APIs, edge cases, and observable behaviors.</p>
<p>With the DTU, we can validate at volumes and rates far exceeding production limits. We can test failure modes that would be dangerous or impossible against live services. We can run thousands of scenarios per hour without hitting rate limits, triggering abuse detection, or accumulating API costs.</p>
</blockquote>
<p>How do you clone the important parts of Okta, Jira, Slack and more? With coding agents!</p>
<p>As I understood it the trick was effectively to dump the full public API documentation of one of those services into their agent harness and have it build an imitation of that API, as a self-contained Go binary. They could then have it build a simplified UI over the top to help complete the simulation.</p>

<p><strong>Update</strong>: DTU creator Jay Taylor posted some extra context about this <a href="https://news.ycombinator.com/item?id=46924426#46931812">on Hacker News</a> sharing a key prompting strategy:</p>
<blockquote>
<p>I did have an initial key insight which led to a repeatable strategy to ensure a high level of fidelity between DTU vs. the official canonical SaaS services:</p>
<p><code>Use the top popular publicly available reference SDK client libraries as compatibility targets, with the goal always being 100% compatibility.</code></p>
</blockquote>

<p>With their own, independent clones of those services - free from rate-limits or usage quotas - their army of simulated testers could go <em>wild</em>. Their scenario tests became scripts for agents to constantly execute against the new systems as they were being built.</p>
<p>This screenshot of their Slack twin also helps illustrate how the testing process works, showing a stream of simulated Okta users who are about to need access to different simulated systems.</p>
<p><img src="https://static.simonwillison.net/static/2026/strong-dm-slack.jpg" alt="Screenshot of a Slack-like interface titled &quot;DTU Slack&quot; showing a thread view (Thread ‚Äî C4B9FBB97) with &quot;Focus first&quot; and &quot;Leave&quot; buttons. The left sidebar lists channels including # org-general (182), # general (0) (shared√ó2), # it-support (0), # channel-0002 (0) (shared√ó2), # channel-0003 (0) through # channel-0020 (0), # org-finance (1), and a DMs section with a &quot;Start&quot; button. A &quot;Create&quot; button appears at the top of the sidebar. The main thread shows approximately 9 automated introduction messages from users with Okta IDs (e.g. @okta-u-423438-00001, @okta-u-423438-00002, etc.), all timestamped 2025-11-12Z between 18:50:31 and 18:51:51. Each message follows the format &quot;Hi team! I'm [Name], joining as Employee in general. Key skills: [fictional skill phrases]. Excited to contribute!&quot; All users have red/orange &quot;O&quot; avatar icons." style="max-width: 100%;" /></p>
<p>This ability to quickly spin up a useful clone of a subset of Slack helps demonstrate how disruptive this new generation of coding agent tools can be:</p>
<blockquote>
<p>Creating a high fidelity clone of a significant SaaS application was always possible, but never economically feasible. Generations of engineers may have <em>wanted</em> a full in-memory replica of their CRM to test against, but self-censored the proposal to build it.</p>
</blockquote>
<p>The <a href="https://factory.strongdm.ai/techniques">techniques page</a> is worth a look too. In addition to the Digital Twin Universe they introduce terms like <strong><a href="https://factory.strongdm.ai/techniques/gene-transfusion">Gene Transfusion</a></strong> for having agents extract patterns from existing systems and reuse them elsewhere, <strong><a href="https://factory.strongdm.ai/techniques/semport">Semports</a></strong> for directly porting code from one language to another and <strong><a href="https://factory.strongdm.ai/techniques/pyramid-summaries">Pyramid Summaries</a></strong> for providing multiple levels of summary such that an agent can enumerate the short ones quickly and zoom in on more detailed information as it is needed.</p>
<p>StrongDM AI also released some software - in an appropriately unconventional manner.</p>
<p><a href="https://github.com/strongdm/attractor">github.com/strongdm/attractor</a> is <strong>Attractor</strong>, the non-interactive coding agent at the heart of their software factory. Except the repo itself contains no code at all - just three markdown files describing the spec for the software in meticulous detail, and a note in the README that you should feed those specs into your coding agent of choice!</p>
<p><a href="https://github.com/strongdm/cxdb">github.com/strongdm/cxdb</a> is a more traditional release, with 16,000 lines of Rust, 9,500 of Go and 6,700 of TypeScript. This is their "AI Context Store" - a system for storing conversation histories and tool outputs in an immutable DAG.</p>
<p>It's similar to my LLM tool's <a href="https://llm.datasette.io/en/stable/logging.html#sql-schema">SQLite logging mechanism</a> but a whole lot more sophisticated. I may have to gene transfuse some ideas out of this one!</p>
<h4 id="a-glimpse-of-the-future-">A glimpse of the future?</h4>
<p>I visited the StrongDM AI team back in October as part of a small group of invited guests.</p>
<p>The three person team of Justin McCarthy, Jay Taylor and Navan Chauhan had formed just three months earlier, and they already had working demos of their coding agent harness, their Digital Twin Universe clones of half a dozen services and a swarm of simulated test agents running through scenarios. And this was prior to the Opus 4.5/GPT 5.2 releases that made agentic coding significantly more reliable a month after those demos.</p>
<p>It felt like a glimpse of one potential future of software development, where software engineers move from building the code to building and then semi-monitoring the systems that build the code. The Dark Factory.</p>

<h4 id="wait-1-000-day-per-engineer-">Wait, $1,000/day per engineer?</h4>
<p>I glossed over this detail in my first published version of this post, but it deserves some serious attention.</p>
<p>If these patterns really do add $20,000/month per engineer to your budget they're far less interesting to me. At that point this becomes more of a business model exercise: can you create a profitable enough line of products that you can afford the enormous overhead of developing software in this way?</p>
<p>Building sustainable software businesses also looks very different when any competitor can potentially clone your newest features with a few hours of coding agent work.</p>
<p>I hope these patterns can be put into play with a much lower spend. I've personally found the $200/month Claude Max plan gives me plenty of space to experiment with different agent patterns, but I'm also not running a swarm of QA testers 24/7!</p>
<p>I think there's a lot to learn from StrongDM even for teams and individuals who aren't going to burn thousands of dollars on token costs. I'm particularly invested in the question of what it takes to have agents prove that their code works without needing to review every line of code they produce.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/parallel-agents">parallel-agents</a></p>]]></description><pubDate>Sat, 7 Feb 2026 15:40:48 +0000</pubDate></item><item><title>Quoting Tom Dale</title><link>https://simonwillison.net/2026/Feb/6/tom-dale/#atom-everything</link><description><![CDATA[<blockquote cite="https://twitter.com/tomdale/status/2019828626972131441"><p>I don't know why this week became the tipping point, but nearly every software engineer I've talked to is experiencing some degree of mental health crisis.</p>
<p>[...] Many people assuming I meant job loss anxiety but that's just one presentation. I'm seeing near-manic episodes triggered by watching software shift from scarce to abundant. Compulsive behaviors around agent usage. Dissociative awe at the temporal compression of change. It's not fear necessarily just the cognitive overload from living in an inflection point.</p></blockquote>
<p class="cite">&mdash; <a href="https://twitter.com/tomdale/status/2019828626972131441">Tom Dale</a></p>

    <p>Tags: <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a>, <a href="https://simonwillison.net/tags/careers">careers</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p>]]></description><pubDate>Fri, 6 Feb 2026 23:41:31 +0000</pubDate></item><item><title>Running Pydantic&apos;s Monty Rust sandboxed Python subset in WebAssembly</title><link>https://simonwillison.net/2026/Feb/6/pydantic-monty/#atom-everything</link><description><![CDATA[<p>There's a jargon-filled headline for you! Everyone's <a href="https://simonwillison.net/2026/Jan/8/llm-predictions-for-2026/#1-year-we-re-finally-going-to-solve-sandboxing">building sandboxes</a> for running untrusted code right now, and Pydantic's latest attempt, <a href="https://github.com/pydantic/monty">Monty</a>, provides a custom Python-like language (a subset of Python) in Rust and makes it available as both a Rust library and a Python package. I got it working in WebAssembly, providing a sandbox-in-a-sandbox.</p>
<p>Here's <a href="https://github.com/pydantic/monty">how they describe Monty</a>:</p>
<blockquote>
<p>Monty avoids the cost, latency, complexity and general faff of using full container based sandbox for running LLM generated code.</p>
<p>Instead, it let's you safely run Python code written by an LLM embedded in your agent, with startup times measured in single digit microseconds not hundreds of milliseconds.</p>
<p>What Monty <strong>can</strong> do:</p>
<ul>
<li>Run a reasonable subset of Python code - enough for your agent to express what it wants to do</li>
<li>Completely block access to the host environment: filesystem, env variables and network access are all implemented via external function calls the developer can control</li>
<li>Call functions on the host - only functions you give it access to [...]</li>
</ul>
</blockquote>
<p>A quick way to try it out is via <a href="https://github.com/astral-sh/uv">uv</a>:</p>
<pre><code>uv run --with pydantic-monty python -m asyncio
</code></pre>
<p>Then paste this into the Python interactive prompt - the <code>-m asyncio</code> enables top-level await:</p>
<pre><span>import</span> <span>pydantic_monty</span>
<span>code</span> <span>=</span> <span>pydantic_monty</span>.<span>Monty</span>(<span>'print("hello " + str(4 * 5))'</span>)
<span>await</span> <span>pydantic_monty</span>.<span>run_monty_async</span>(<span>code</span>)</pre>
<p>Monty supports a <em>very</em> small subset of Python - it doesn't even support class declarations yet!</p>
<p>But, given its target use-case, that's not actually a problem.</p>
<p>The neat thing about providing tools like this for LLMs is that they're really good at iterating against error messages. A coding agent can run some Python code, get an error message telling it that classes aren't supported and then try again with a different approach.</p>
<p>I wanted to try this in a browser, so I fired up <a href="https://simonwillison.net/2025/Nov/6/async-code-research/">a code research task</a> in Claude Code for web and kicked it off with the following:</p>
<blockquote>
<p>Clone <a href="https://github.com/pydantic/monty">https://github.com/pydantic/monty</a> to /tmp and figure out how to compile it into a python WebAssembly wheel that can then be loaded in Pyodide. The wheel file itself should be checked into the repo along with build scripts and passing pytest playwright test scripts that load Pyodide from a CDN and the wheel from a ‚Äúpython -m http.server‚Äù localhost and demonstrate it working</p>
</blockquote>
<p>Then a little later:</p>
<blockquote>
<p>I want an additional WASM file that works independently of Pyodide, which is also usable in a web browser - build that too along with playwright tests that show it working. Also build two HTML files - one called demo.html and one called pyodide-demo.html - these should work similar to <a href="https://tools.simonwillison.net/micropython">https://tools.simonwillison.net/micropython</a> (download that code with curl to inspect it) - one should load the WASM build, the other should load Pyodide and have it use the WASM wheel. These will be served by GitHub Pages so they can load the WASM and wheel from a relative path since the .html files will be served from the same folder as the wheel and WASM file</p>
</blockquote>
<p>Here's <a href="https://gisthost.github.io/?22d88e6367d7e002c4fb383c213c2df2/page-001.html">the transcript</a>, and the <a href="https://github.com/simonw/research/tree/main/monty-wasm-pyodide">final research report</a> it produced.</p>
<p>I now have the Monty Rust code compiled to WebAssembly in two different shapes - as a <code>.wasm</code> bundle you can load and call from JavaScript, and as a <code>monty-wasm-pyodide/pydantic_monty-0.0.3-cp313-cp313-emscripten_4_0_9_wasm32.whl</code> wheel file which can be loaded into <a href="https://pyodide.org/">Pyodide</a> and then called from Python in Pyodide in WebAssembly in a browser.</p>
<p>Here are those two demos, hosted on GitHub Pages:</p>
<ul>
<li>
<a href="https://simonw.github.io/research/monty-wasm-pyodide/demo.html">Monty WASM demo</a> - a UI over JavaScript that loads the Rust WASM module directly.</li>
<li>
<a href="https://simonw.github.io/research/monty-wasm-pyodide/pyodide-demo.html">Monty Pyodide demo</a> - this one provides an identical interface but here the code is <a href="https://github.com/simonw/research/blob/3add1ffec70b530711fa237d91f546da5bcf1f1c/monty-wasm-pyodide/pyodide-demo.html#L257-L280">loading Pyodide and then installing the Monty WASM wheel</a>.</li>
</ul>
<p><img src="https://static.simonwillison.net/static/2026/monty-pyodide.jpg" alt="Screenshot of a web app titled &quot;Monty via Pyodide&quot; with description &quot;Run Monty (a sandboxed Python interpreter by Pydantic) inside Pyodide (CPython compiled to WebAssembly). This loads the pydantic-monty wheel and uses its full Python API. Code is saved in the URL for sharing.&quot; A green banner reads &quot;Code executed successfully!&quot; Below are example buttons labeled &quot;Basic&quot;, &quot;Inputs&quot;, &quot;Reuse&quot;, &quot;Error Handling&quot;, &quot;Fibonacci&quot;, and &quot;Classes&quot;. A code editor labeled &quot;Python Code (runs inside Monty sandbox via Pyodide):&quot; contains: &quot;import pydantic_monty\n\n# Create interpreter with input variables\nm = pydantic_monty.Monty('x + y', inputs=['x', 'y'])\n\n# Run with different inputs\nresult1 = m.run(inputs={&quot;x&quot;: 10, &quot;y&quot;: 20})\nprint(f&quot;10 + 20 = {result1}&quot;)\n\nresult2 = m.run(inputs={&quot;x&quot;: 100, &quot;y&quot;: 200})&quot; with &quot;Run Code&quot; and &quot;Clear&quot; buttons. The Output section shows &quot;10 + 20 = 30&quot; and &quot;100 + 200 = 300&quot; with a &quot;Copy&quot; button. Footer reads &quot;Executed in 4.0ms&quot;." style="max-width: 100%;" /></p>
<p>As a connoisseur of sandboxes - the more options the better! - this new entry from Pydantic ticks a lot of my boxes. It's small, fast, widely available (thanks to Rust and WebAssembly) and provides strict limits on memory usage, CPU time and access to disk and network.</p>
<p>It was also a great excuse to spin up another demo showing how easy it is these days to turn compiled code like C or Rust into WebAssembly that runs in both a browser and a Pyodide environment.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/javascript">javascript</a>, <a href="https://simonwillison.net/tags/python">python</a>, <a href="https://simonwillison.net/tags/sandboxing">sandboxing</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/rust">rust</a>, <a href="https://simonwillison.net/tags/webassembly">webassembly</a>, <a href="https://simonwillison.net/tags/pyodide">pyodide</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/pydantic">pydantic</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/claude-code">claude-code</a></p>]]></description><pubDate>Fri, 6 Feb 2026 22:31:31 +0000</pubDate></item><item><title>An Update on Heroku</title><link>https://simonwillison.net/2026/Feb/6/an-update-on-heroku/#atom-everything</link><description><![CDATA[<p><strong><a href="https://www.heroku.com/blog/an-update-on-heroku/">An Update on Heroku</a></strong></p>
An ominous headline to see on the official Heroku blog and yes, it's bad news.</p>
<blockquote>
<p>Today, Heroku is transitioning to a sustaining engineering model focused on stability, security, reliability, and support. Heroku remains an actively supported, production-ready platform, with an emphasis on maintaining quality and operational excellence rather than introducing new features. We know changes like this can raise questions, and we want to be clear about what this means for customers.</p>
</blockquote>
<p>Based on context I'm guessing a "sustaining engineering model" (this definitely isn't a widely used industry term) means that they'll keep the lights on and that's it.</p>
<p>This is a very frustrating piece of corporate communication. "We want to be clear about what this means for customers" - then proceeds to <em>not be clear</em> about what this means for customers.</p>
<p>Why are they doing this? Here's their explanation:</p>
<blockquote>
<p>We‚Äôre focusing our product and engineering investments on areas where we can deliver the greatest long-term customer value, including helping organizations build and deploy enterprise-grade AI in a secure and trusted way.</p>
</blockquote>
<p>My blog is the only project I have left running on Heroku. I guess I'd better migrate it away (probably to Fly) before Salesforce lose interest completely.


    <p>Tags: <a href="https://simonwillison.net/tags/salesforce">salesforce</a>, <a href="https://simonwillison.net/tags/heroku">heroku</a>, <a href="https://simonwillison.net/tags/fly">fly</a></p>]]></description><pubDate>Fri, 6 Feb 2026 18:44:21 +0000</pubDate></item><item><title>Quoting Karel D&apos;Oosterlinck</title><link>https://simonwillison.net/2026/Feb/6/karel-doosterlinck/#atom-everything</link><description><![CDATA[<blockquote cite="https://twitter.com/kareldoostrlnck/status/2019477361557926281"><p>When I want to quickly implement a one-off experiment in a part of the codebase I am unfamiliar with, I get codex to do extensive due diligence. Codex explores relevant slack channels, reads related discussions, fetches experimental branches from those discussions, and cherry picks useful changes for my experiment. All of this gets summarized in an extensive set of notes, with links back to where each piece of information was found. Using these notes, codex wires the experiment and makes a bunch of hyperparameter decisions I couldn‚Äôt  possibly make without much more effort.</p></blockquote>
<p class="cite">&mdash; <a href="https://twitter.com/kareldoostrlnck/status/2019477361557926281">Karel D&#x27;Oosterlinck</a>, I spent $10,000 to automate my research at OpenAI with Codex</p>

    <p>Tags: <a href="https://simonwillison.net/tags/codex-cli">codex-cli</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p>]]></description><pubDate>Fri, 6 Feb 2026 00:42:22 +0000</pubDate></item><item><title>Mitchell Hashimoto: My AI Adoption Journey</title><link>https://simonwillison.net/2026/Feb/5/ai-adoption-journey/#atom-everything</link><description><![CDATA[<p><strong><a href="https://mitchellh.com/writing/my-ai-adoption-journey">Mitchell Hashimoto: My AI Adoption Journey</a></strong></p>
Some really good and unconventional tips in here for getting to a place with coding agents where they demonstrably improve your workflow and productivity. I particularly liked:</p>
<ul>
<li>
<p><a href="https://mitchellh.com/writing/my-ai-adoption-journey#step-2-reproduce-your-own-work">Reproduce your own work</a> - when learning to use coding agents Mitchell went through a period of doing the work manually, then recreating the same solution using agents as an exercise:</p>
<blockquote>
<p>I literally did the work twice. I'd do the work manually, and then I'd fight an agent to produce identical results in terms of quality and function (without it being able to see my manual solution, of course).</p>
</blockquote>
</li>
<li>
<p><a href="https://mitchellh.com/writing/my-ai-adoption-journey#step-3-end-of-day-agents">End-of-day agents</a> - letting agents step in when your energy runs out:</p>
<blockquote>
<p>To try to find some efficiency, I next started up a new pattern: <strong>block out the last 30 minutes of every day to kick off one or more agents.</strong> My hypothesis was that <em>perhaps</em> I could gain some efficiency if the agent can make some <em>positive progress</em> in the times I can't work anyways.</p>
</blockquote>
</li>
<li>
<p><a href="https://mitchellh.com/writing/my-ai-adoption-journey#step-4-outsource-the-slam-dunks">Outsource the Slam Dunks</a> - once you know an agent can likely handle a task, have it do that task while you work on something more interesting yourself.</p>
</li>
</ul>

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=46903558">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/mitchell-hashimoto">mitchell-hashimoto</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a></p>]]></description><pubDate>Thu, 5 Feb 2026 23:39:07 +0000</pubDate></item><item><title>Opus 4.6 and Codex 5.3</title><link>https://simonwillison.net/2026/Feb/5/two-new-models/#atom-everything</link><description><![CDATA[<p>Two major new model releases today, within about 15 minutes of each other.</p>
<p>Anthropic <a href="https://www.anthropic.com/news/claude-opus-4-6">released Opus 4.6</a>. Here's <a href="https://gist.github.com/simonw/a6806ce41b4c721e240a4548ecdbe216">its pelican</a>:</p>
<p><img alt="Slightly wonky bicycle frame but an excellent pelican, very clear beak and pouch, nice feathers." src="https://static.simonwillison.net/static/2026/opus-4.6-pelican.png" /></p>
<p>OpenAI <a href="https://openai.com/index/introducing-gpt-5-3-codex/">release GPT-5.3-Codex</a>, albeit only via their Codex app, not yet in their API. Here's <a href="https://gist.github.com/simonw/bfc4a83f588ac762c773679c0d1e034b">its pelican</a>:</p>
<p><img alt="Not nearly as good - the bicycle is a bit mangled, the pelican not nearly as well rendered - it's more of a line drawing." src="https://static.simonwillison.net/static/2026/codex-5.3-pelican.png" /></p>
<p>I've had a bit of preview access to both of these models and to be honest I'm finding it hard to find a good angle to write about them - they're both <em>really good</em>, but so were their predecessors Codex 5.2 and Opus 4.5. I've been having trouble finding tasks that those previous models couldn't handle but the new ones are able to ace.</p>
<p>The most convincing story about capabilities of the new model so far is Nicholas Carlini from Anthropic talking about Opus 4.6 and <a href="https://www.anthropic.com/engineering/building-c-compiler">Building a C compiler with a team of parallel Claudes</a> - Anthropic's version of Cursor's <a href="https://simonwillison.net/2026/Jan/23/fastrender/">FastRender project</a>.</p>

    <p>Tags: <a href="https://simonwillison.net/tags/llm-release">llm-release</a>, <a href="https://simonwillison.net/tags/anthropic">anthropic</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/parallel-agents">parallel-agents</a>, <a href="https://simonwillison.net/tags/c">c</a>, <a href="https://simonwillison.net/tags/nicholas-carlini">nicholas-carlini</a></p>]]></description><pubDate>Thu, 5 Feb 2026 20:29:20 +0000</pubDate></item><item><title>Spotlighting The World Factbook as We Bid a Fond Farewell</title><link>https://simonwillison.net/2026/Feb/5/the-world-factbook/#atom-everything</link><description><![CDATA[<p><strong><a href="https://www.cia.gov/stories/story/spotlighting-the-world-factbook-as-we-bid-a-fond-farewell/">Spotlighting The World Factbook as We Bid a Fond Farewell</a></strong></p>
Somewhat devastating news today from CIA:</p>
<blockquote>
<p>One of CIA‚Äôs oldest and most recognizable intelligence publications, The World Factbook, has sunset.</p>
</blockquote>
<p>There's not even a hint as to <em>why</em> they decided to stop maintaining this publication, which has been their most useful public-facing initiative since 1971 and a cornerstone of the public internet since 1997.</p>
<p>In a bizarre act of cultural vandalism they've not just removed the entire site (including the archives of previous versions) but they've also set every single page to be a 302 redirect to their closure announcement.</p>
<p>The Factbook has been released into the public domain since the start. There's no reason not to continue to serve archived versions - a banner at the top of the page saying it's no longer maintained would be much better than removing all of that valuable content entirely.</p>
<p>Up until 2020 the CIA published annual zip file archives of the entire site. Those are available (along with the rest of the Factbook) <a href="https://web.archive.org/web/20260203124934/https://www.cia.gov/the-world-factbook/about/archives/">on the Internet Archive</a>.</p>
<p>I downloaded the 384MB <code>.zip</code> file for the year 2020 and extracted it into a new GitHub repository, <a href="https://github.com/simonw/cia-world-factbook-2020/">simonw/cia-world-factbook-2020</a>. I've enabled GitHub Pages for that repository so you can browse the archived copy at <a href="https://simonw.github.io/cia-world-factbook-2020">simonw.github.io/cia-world-factbook-2020/</a>.</p>
<p><img alt="Screenshot of the CIA World Factbook website homepage. Header reads &quot;THE WORLD FACTBOOK&quot; with a dropdown labeled &quot;Please select a country to view.&quot; Navigation tabs: ABOUT, REFERENCES, APPENDICES, FAQs. Section heading &quot;WELCOME TO THE WORLD FACTBOOK&quot; followed by descriptive text: &quot;The World Factbook provides information on the history, people and society, government, economy, energy, geography, communications, transportation, military, and transnational issues for 267 world entities. The Reference tab includes: a variety of world, regional, country, ocean, and time zone maps; Flags of the World; and a Country Comparison function that ranks the country information and data in more than 75 Factbook fields.&quot; A satellite image of Earth is displayed on the right. Below it: &quot;WHAT'S NEW :: Today is: Wednesday, February 4.&quot; Left sidebar links with icons: WORLD TRAVEL FACTS, ONE-PAGE COUNTRY SUMMARIES, REGIONAL AND WORLD MAPS, FLAGS OF THE WORLD, GUIDE TO COUNTRY COMPARISONS. Right side shows news updates dated December 17, 2020 about Electricity access and new Economy fields, and December 10, 2020 about Nepal and China agreeing on the height of Mount Everest at 8,848.86 meters. A &quot;VIEW ALL UPDATES&quot; button appears at the bottom." src="https://static.simonwillison.net/static/2025/factbook-2020.jpg" /></p>
<p>Here's a neat example of the editorial voice of the Factbook from the <a href="https://simonw.github.io/cia-world-factbook-2020/docs/whatsnew.html">What's New page</a>, dated December 10th 2020:</p>
<blockquote>
<p>Years of wrangling were brought to a close this week when officials from Nepal and China announced that they have agreed on the height of Mount Everest. The mountain sits on the border between Nepal and Tibet (in western China), and its height changed slightly following an earthquake in 2015. The new height of 8,848.86 meters is just under a meter higher than the old figure of 8,848 meters. <em>The World Factbook</em> rounds the new measurement to 8,849 meters and this new height has been entered throughout the <em>Factbook</em> database.</p>
</blockquote>

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=46891794">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/cia">cia</a>, <a href="https://simonwillison.net/tags/github">github</a>, <a href="https://simonwillison.net/tags/internet-archive">internet-archive</a></p>]]></description><pubDate>Thu, 5 Feb 2026 00:23:38 +0000</pubDate></item></channel></rss>