<?xml version="1.0" encoding="utf-8"?><rss version="2.0"><channel><title>Simon Willison&apos;s Weblog</title><link>https://raw.githubusercontent.com/xavwe/rss-aggregator/refs/heads/main/feeds/simon-willison-s-weblog-2b081550.xml</link><description>Archived feed from https://simonwillison.net/atom/everything</description><item><title>What happens if AI labs train for pelicans riding bicycles?</title><link>https://simonwillison.net/2025/Nov/13/training-for-pelicans-riding-bicycles/#atom-everything</link><description><![CDATA[<p>Almost every time I share a new example of <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">an SVG of a pelican riding a bicycle</a> a variant of this question pops up: how do you know the labs aren't training for your benchmark?</p>
<p>The strongest argument is that <strong>they would get caught</strong>. If a model finally comes out that produces an excellent SVG of a pelican riding a bicycle you can bet I'm going to test it on all manner of creatures riding all sorts of transportation devices. If those are notably worse it's going to be pretty obvious what happened.</p>
<p>A related note here is that, if they <em>are</em> training for my benchmark, that training clearly is not going well! The very best models still produce pelicans on bicycles that look laughably awful. It's one of the reasons I've continued to find the test useful: drawing pelicans is hard! Even getting a bicycle the right shape is a challenge that few models have achieved yet.</p>
<p>My current favorite is still <a href="https://simonwillison.net/2025/Aug/7/gpt-5/#and-some-svgs-of-pelicans">this one from GPT-5</a>. The bicycle has all of the right pieces and the pelican is clearly pedaling it!</p>
<p><img src="https://static.simonwillison.net/static/2025/gpt-5-pelican.png" alt="The bicycle is really good, spokes on wheels, correct shape frame, nice pedals. The pelican has a pelican beak and long legs stretching to the pedals." style="max-width: 100%;" /></p>
<p>I should note that OpenAI's Aidan McLaughlin has <a href="https://x.com/aidan_mclau/status/1986255202132042164">specifically denied</a> training for this particular benchmark:</p>

<blockquote><p>we do not hill climb on svg art</p></blockquote>

<p>People also ask if they're training on my published collection. If they are that would be a big mistake, because a model trained on <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">these examples</a> will produce some <em>very</em> weird looking pelicans.</p>
<p>Truth be told, I'm <strong>playing the long game</strong> here. All I've ever wanted from life is a genuinely great SVG vector illustration of a pelican riding a bicycle. My dastardly multi-year plan is to trick multiple AI labs into investing vast resources to cheat at my benchmark until I get one.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a></p>]]></description><pubDate>Thu, 13 Nov 2025 16:03:38 +0000</pubDate></item><item><title>Quoting Steve Krouse</title><link>https://simonwillison.net/2025/Nov/12/steve-krouse/#atom-everything</link><description><![CDATA[<blockquote cite="https://x.com/stevekrouse/status/1988641250329989533"><p>The fact that MCP is a difference surface from your normal API allows you to ship MUCH faster to MCP. This has been unlocked by inference at runtime</p>
<p>Normal APIs are promises to developers, because developer commit code that relies on those APIs, and then walk away. If you break the API, you break the promise, and you break that code. This means a developer gets woken up at 2am to fix the code</p>
<p>But MCP servers are called by LLMs which dynamically read the spec every time, which allow us to constantly change the MCP server. It doesn't matter! We haven't made any promises. The LLM can figure it out afresh every time</p></blockquote>
<p class="cite">&mdash; <a href="https://x.com/stevekrouse/status/1988641250329989533">Steve Krouse</a></p>

    <p>Tags: <a href="https://simonwillison.net/tags/model-context-protocol">model-context-protocol</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/steve-krouse">steve-krouse</a>, <a href="https://simonwillison.net/tags/apis">apis</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p>]]></description><pubDate>Wed, 12 Nov 2025 17:21:19 +0000</pubDate></item><item><title>Fun-reliable side-channels for cross-container communication</title><link>https://simonwillison.net/2025/Nov/12/h4x0rchat/#atom-everything</link><description><![CDATA[<p><strong><a href="https://h4x0r.org/funreliable/">Fun-reliable side-channels for cross-container communication</a></strong></p>
Here's a very clever hack for communicating between different processes running in different containers on the same machine. It's based on clever abuse of POSIX advisory locks which allow a process to create and detect locks across byte offset ranges:</p>
<blockquote>
<p>These properties combined are enough to provide a basic cross-container side-channel primitive, because a process in one container can set a read-lock at some interval on <code>/proc/self/ns/time</code>, and a process in another container can observe the presence of that lock by querying for a hypothetically intersecting write-lock.</p>
</blockquote>
<p>I dumped <a href="https://github.com/crashappsec/h4x0rchat/blob/main/h4x0rchat.c">the C proof-of-concept</a> into GPT-5 for <a href="https://chatgpt.com/share/6914aad2-397c-8006-b404-b9ddbd900c8f">a code-level explanation</a>, then had it help me figure out how to run it in Docker. Here's the recipe that worked for me:</p>
<pre><code>cd /tmp
wget https://github.com/crashappsec/h4x0rchat/blob/9b9d0bd5b2287501335acca35d070985e4f51079/h4x0rchat.c
docker run --rm -it -v "$PWD:/src" \
  -w /src gcc:13 bash -lc 'gcc -Wall -O2 \
  -o h4x0rchat h4x0rchat.c &amp;&amp; ./h4x0rchat'
</code></pre>
<p>Run that <code>docker run</code> line in two separate terminal windows and you can chat between the two of them like this:</p>
<p><a style="text-decoration: none; border-bottom: none" href="https://static.simonwillison.net/static/2025/h4x0rchat.gif"><img style="max-width: 100%" alt="Animated demo. Two terminal windows. Both run that command, then start a l33t speak chat interface. Each interface asks the user for a name, then messages that are typed in one are instantly displayed in the other and vice-versa." src="https://static.simonwillison.net/static/2025/h4x0rchat.gif"></a>

    <p><small></small>Via <a href="https://lobste.rs/s/3z4pro/fun_reliable_side_channels_for_cross">lobste.rs</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/c">c</a>, <a href="https://simonwillison.net/tags/docker">docker</a></p>]]></description><pubDate>Wed, 12 Nov 2025 16:04:03 +0000</pubDate></item><item><title>Scaling HNSWs</title><link>https://simonwillison.net/2025/Nov/11/scaling-hnsws/#atom-everything</link><description><![CDATA[<p><strong><a href="https://antirez.com/news/156">Scaling HNSWs</a></strong></p>
Salvatore Sanfilippo spent much of this year working on <a href="https://github.com/redis/redis/blob/8.2.3/modules/vector-sets/README.md">vector sets for Redis</a>, which first shipped in <a href="https://redis.io/blog/redis-8-ga/">Redis 8 in May</a>.</p>
<p>A big part of that work involved implementing HNSW - Hierarchical Navigable Small World - an indexing technique first introduced in <a href="https://arxiv.org/abs/1603.09320">this 2016 paper</a> by Yu. A. Malkov and D. A. Yashunin.</p>
<p>Salvatore's detailed notes on the Redis implementation here offer an immersive trip through a fascinating modern field of computer science. He describes several new contributions he's made to the HNSW algorithm, mainly around efficient deletion and updating of existing indexes.</p>
<p>Since embedding vectors are notoriously memory-hungry I particularly appreciated this note about how you can scale a large HNSW vector set across many different nodes and run parallel queries against them for both reads and writes:</p>
<blockquote>
<p>[...] if you have different vectors about the same use case split in different instances / keys, you can ask VSIM for the same query vector into all the instances, and add the WITHSCORES option (that returns the cosine distance) and merge the results client-side, and you have magically scaled your hundred of millions of vectors into multiple instances, splitting your dataset N times [One interesting thing about such a use case is that you can query the N instances in parallel using multiplexing, if your client library is smart enough].</p>
<p>Another very notable thing about HNSWs exposed in this raw way, is that you can finally scale writes very easily. Just hash your element modulo N, and target the resulting Redis key/instance. Multiple instances can absorb the (slow, but still fast for HNSW standards) writes at the same time, parallelizing an otherwise very slow process.</p>
</blockquote>
<p>It's always exciting to see new implementations of fundamental algorithms and data structures like this make it into Redis because Salvatore's C code is so clearly commented and pleasant to read - here's <a href="https://github.com/redis/redis/blob/8.2.3/modules/vector-sets/hnsw.c">vector-sets/hnsw.c</a> and <a href="https://github.com/redis/redis/blob/8.2.3/modules/vector-sets/vset.c">vector-sets/vset.c</a>.

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=45887466">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/algorithms">algorithms</a>, <a href="https://simonwillison.net/tags/c">c</a>, <a href="https://simonwillison.net/tags/computer-science">computer-science</a>, <a href="https://simonwillison.net/tags/data-structures">data-structures</a>, <a href="https://simonwillison.net/tags/redis">redis</a>, <a href="https://simonwillison.net/tags/salvatore-sanfilippo">salvatore-sanfilippo</a>, <a href="https://simonwillison.net/tags/vector-search">vector-search</a>, <a href="https://simonwillison.net/tags/embeddings">embeddings</a></p>]]></description><pubDate>Tue, 11 Nov 2025 23:38:39 +0000</pubDate></item><item><title>Agentic Pelican on a Bicycle</title><link>https://simonwillison.net/2025/Nov/11/agentic-pelican-on-a-bicycle/#atom-everything</link><description><![CDATA[<p><strong><a href="https://www.robert-glaser.de/agentic-pelican-on-a-bicycle/">Agentic Pelican on a Bicycle</a></strong></p>
Robert Glaser took my <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">pelican riding a bicycle</a> benchmark and applied an agentic loop to it, seeing if vision models could draw a better pelican if they got the chance to render their SVG to an image and then try again until they were happy with the end result.</p>
<p>Here's what Claude Opus 4.1 got to after four iterations - I think the most interesting result of the models Robert tried:</p>
<p><img alt="Left is a simple incorrectly shaped bicycle and a not great pelican. On the right the bicycle has more spokes, the background has more details, pedals are now visible, there's a water bottle and the pelican has a basket with some fish. It also has a slightly more clear lower beak and a red line on its head that looks a bit more like a chicken." src="https://static.simonwillison.net/static/2025/pelican-agent-opus.jpg" /></p>
<p>I tried a similar experiment to this a few months ago in preparation for the GPT-5 launch and was surprised at how little improvement it produced.</p>
<p>Robert's "skeptical take" conclusion is similar to my own:</p>
<blockquote>
<p>Most models didn’t fundamentally change their approach. They tweaked. They adjusted. They added details. But the basic composition—pelican shape, bicycle shape, spatial relationship—was determined in iteration one and largely frozen thereafter.</p>
</blockquote>

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=45891817">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/svg">svg</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-agents">ai-agents</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a></p>]]></description><pubDate>Tue, 11 Nov 2025 23:23:18 +0000</pubDate></item><item><title>Six coding agents at once</title><link>https://simonwillison.net/2025/Nov/11/six-coding-agents-at-once/#atom-everything</link><description><![CDATA[<p>I've been upgrading a <em>ton</em> of Datasette plugins recently for compatibility with the <a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/">Datasette 1.0a20 release</a> from last week - <a href="https://github.com/simonw/datasette/issues/2577#issuecomment-3483537877">35 so far</a>.</p>
<p>A lot of the work is very repetitive so I've been outsourcing it to <a href="https://github.com/openai/codex">Codex CLI</a>. Here's the recipe I've landed on:</p>
<div class="highlight highlight-source-shell"><pre style="font-size: 0.9em">codex <span class="pl-c1">exec</span> --dangerously-bypass-approvals-and-sandbox \
<span class="pl-s"><span class="pl-pds">'</span>Run the command tadd and look at the errors and then</span>
<span class="pl-s">read ~/dev/datasette/docs/upgrade-1.0a20.md and apply</span>
<span class="pl-s">fixes and run the tests again and get them to pass.</span>
<span class="pl-s"></span>
<span class="pl-s">Also delete the .github directory entirely and replace</span>
<span class="pl-s">it by running this:</span>
<span class="pl-s"></span>
<span class="pl-s">cp -r ~/dev/ecosystem/datasette-os-info/.github .</span>
<span class="pl-s"></span>
<span class="pl-s">Run a git diff against that to make sure it looks OK</span>
<span class="pl-s">- if there are any notable differences e.g. switching</span>
<span class="pl-s">from Twine to the PyPI uploader or deleting code that</span>
<span class="pl-s">does a special deploy or configures something like </span>
<span class="pl-s">playwright include that in your final report.</span>
<span class="pl-s"></span>
<span class="pl-s">If the project still uses setup.py then edit that new</span>
<span class="pl-s">test.yml and publish.yaml to mention setup.py not pyproject.toml</span>
<span class="pl-s"></span>
<span class="pl-s">If this project has pyproject.toml make sure the license</span>
<span class="pl-s">line in that looks like this:</span>
<span class="pl-s"></span>
<span class="pl-s">license = "Apache-2.0"</span>
<span class="pl-s"></span>
<span class="pl-s">And remove any license thing from the classifiers= array</span>
<span class="pl-s"></span>
<span class="pl-s">Update the Datasette dependency in pyproject.toml or</span>
<span class="pl-s">setup.py to "datasette&gt;=1.0a21"</span>
<span class="pl-s"></span>
<span class="pl-s">And make sure requires-python is &gt;=3.10<span class="pl-pds">'</span></span></pre></div>

<p>I featured a simpler version of this prompt in my <a href="https://simonwillison.net/2025/Nov/6/upgrading-datasette-plugins/">Datasette plugin upgrade video</a>, but I've expanded it quite a bit since then.</p>
<p>At one point I had six terminal windows open running this same prompt against six different repos - probably my most extreme case of <a href="https://simonwillison.net/2025/Oct/5/parallel-coding-agents/">parallel agents</a> yet.</p>
<p><img alt="Animated GIF demo. Six terminal windows are arranged in a 3x2 grid, each one of them is running the above prompt and working its way through making modifications to one of six different projects: datasette-extract, datasette-create-view, datasette-write, datasette-secrets, datasette-public, and datasette-write-ui." src="https://static.simonwillison.net/static/2025/multiple-codexes.gif" /></p>
<p>Here are the six resulting commits from those six coding agent sessions:</p>
<ul>
<li><a href="https://github.com/datasette/datasette-extract/commit/deb6ae3f3069d45c5227a57067c6621cd3b8d6ea">datasette-extract deb6ae</a></li>
<li><a href="https://github.com/datasette/datasette-create-view/commit/d940f42fdab205c645fe4a2f1d7a4e44d41104d8">datasette-create-view d940f4</a></li>
<li><a href="https://github.com/simonw/datasette-write/commit/e0af01f931498a3dfbf5f2597534df109559fe71">datasette-write e0af01</a></li>
<li><a href="https://github.com/datasette/datasette-secrets/commit/e93d1410bcd9a4af87a046b584e9e3f9cae503c4">datasette-secrets e93d14</a></li>
<li><a href="https://github.com/datasette/datasette-write-ui/commit/1d2459fbc35ad02633bb7441c92bc5f8a5d919d5">datasette-write-ui 1d2459</a></li>
<li><a href="https://github.com/datasette/datasette-public/commit/5213c41521821c03688c6099581e198a831f85d5">datasette-public 5213c4</a></li>
</ul>

    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/codex-cli">codex-cli</a>, <a href="https://simonwillison.net/tags/prompt-engineering">prompt-engineering</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/datasette">datasette</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/parallel-agents">parallel-agents</a></p>]]></description><pubDate>Tue, 11 Nov 2025 22:52:45 +0000</pubDate></item><item><title>Quoting Netflix</title><link>https://simonwillison.net/2025/Nov/10/netflix/#atom-everything</link><description><![CDATA[<blockquote cite="https://partnerhelp.netflixstudios.com/hc/en-us/articles/43393929218323-Using-Generative-AI-in-Content-Production"><p>Netflix asks partners to consider the following guiding principles before leveraging GenAI in any creative workflow: </p>
<ol>
<li>The outputs do not replicate or substantially recreate identifiable characteristics of unowned or copyrighted material, or infringe any copyright-protected works</li>
<li>The generative tools used do not store, reuse, or train on production data inputs or outputs.</li>
<li>Where possible, generative tools are used in an <a href="https://partnerhelp.netflixstudios.com/hc/en-us/articles/43393929218323-Using-Generative-AI-in-Content-Production#h_01K1BTNMBS130Y200ZWV3H6ZAT">enterprise-secured environment</a> to safeguard inputs.</li>
<li>Generated material is temporary and not part of the <a href="https://partnerhelp.netflixstudios.com/hc/en-us/articles/43393929218323-Using-Generative-AI-in-Content-Production#h_01K1BTNMBVFQYQNJCCMKR254VK">final deliverables</a>.</li>
<li>GenAI is not used to replace or generate new <a href="https://partnerhelp.netflixstudios.com/hc/en-us/articles/43393929218323-Using-Generative-AI-in-Content-Production#h_01K1BTNMBWWPTJJA79EFPY8NRJ">talent performances</a> or union-covered work without consent.</li>
</ol>
<p>[...] If you answer "no" or "unsure" to any of these principles, escalate to your Netflix contact for more guidance before proceeding, as written approval may be required.</p></blockquote>
<p class="cite">&mdash; <a href="https://partnerhelp.netflixstudios.com/hc/en-us/articles/43393929218323-Using-Generative-AI-in-Content-Production">Netflix</a>, Using Generative AI in Content Production</p>

    <p>Tags: <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a>, <a href="https://simonwillison.net/tags/netflix">netflix</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a></p>]]></description><pubDate>Mon, 10 Nov 2025 22:08:27 +0000</pubDate></item><item><title>Pelican on a Bike - Raytracer Edition</title><link>https://simonwillison.net/2025/Nov/9/pelican-on-a-bike-raytracer-edition/#atom-everything</link><description><![CDATA[<p><strong><a href="https://blog.nawaz.org/posts/2025/Oct/pelican-on-a-bike-raytracer-edition/">Pelican on a Bike - Raytracer Edition</a></strong></p>
beetle_b ran this prompt against a bunch of recent LLMs:</p>
<blockquote>
<p><code>Write a POV-Ray file that shows a pelican riding on a bicycle.</code></p>
</blockquote>
<p>This turns out to be a harder challenge than SVG, presumably because there are less examples of POV-Ray in the training data:</p>
<blockquote>
<p>Most produced a script that failed to parse. I would paste the error back into the chat and let it attempt a fix.</p>
</blockquote>
<p>The results are really fun though! A lot of them end up accompanied by a weird floating egg for some reason - <a href="https://blog.nawaz.org/posts/2025/Oct/pelican-on-a-bike-raytracer-edition/#claude-opus-4">here's Claude Opus 4</a>:</p>
<p><img alt="3D scene. The bicycle has a sort of square frame in the wrong place, but good wheels. The pelican is stood on top - a large white blob, a smaller white blob head, a cylinder neck and a conical beak in the right place, plus legs that reach out-of-place pedals. A egg floats mysteriously in front of the bird." src="https://static.simonwillison.net/static/2025/pov-pelican-opus.png" /></p>
<p>I think the best result came <a href="https://blog.nawaz.org/posts/2025/Oct/pelican-on-a-bike-raytracer-edition/#gpt-5">from GPT-5</a> - again with the floating egg though!</p>
<p><img alt="The bike is a bit mis-shapen but has most of the right pieces. The pelican has legs that reach the pedals and is bending forward with a two-segmented neck and a good beak. A weird egg floats in the front wheel." src="https://static.simonwillison.net/static/2025/pov-pelican-gpt-5.png" /></p>
<p>I decided to try this on the new <code>gpt-5-codex-mini</code>, using the <a href="https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/">trick I described yesterday</a>. Here's <a href="https://gist.github.com/simonw/059e0c5aee54258cdc62ed511ae26b4b">the code it wrote</a>.</p>
<pre><code>./target/debug/codex prompt -m gpt-5-codex-mini \
  "Write a POV-Ray file that shows a pelican riding on a bicycle."
</code></pre>
<p>It turns out you can render POV files on macOS like this:</p>
<pre><code>brew install povray
povray demo.pov # produces demo.png
</code></pre>
<p>The code GPT-5 Codex Mini created didn't quite work, so I round-tripped it through Sonnet 4.5 via Claude Code a couple of times - <a href="http://gistpreview.github.io/?71c4f0966d5d99003ace12197b9d07fe">transcript here</a>. Once it had fixed the errors I got this:</p>
<p><img alt="Two wheels (tire only) sit overlapping half embedded in the ground. The frame is a half-buried red triangle and some other lines. There is a white pall with a tiny yellow beak and two detached cylindrical arms. It's rubbish." src="https://static.simonwillison.net/static/2025/povray-pelican-gpt-5-codex-mini.png" /></p>
<p>That's significantly worse than the one beetle_b got <a href="https://blog.nawaz.org/posts/2025/Oct/pelican-on-a-bike-raytracer-edition/#gpt-5-mini">from GPT-5 Mini</a>!

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=45862802#45866639">BeetleB on Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/3d">3d</a>, <a href="https://simonwillison.net/tags/ray-tracing">ray-tracing</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a>, <a href="https://simonwillison.net/tags/gpt-5">gpt-5</a></p>]]></description><pubDate>Sun, 9 Nov 2025 16:51:42 +0000</pubDate></item><item><title>Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican</title><link>https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/#atom-everything</link><description><![CDATA[<p>OpenAI partially released a new model yesterday called GPT-5-Codex-Mini, which they <a href="https://x.com/OpenAIDevs/status/1986861734619947305">describe</a> as "a more compact and cost-efficient version of GPT-5-Codex". It's currently only available via their Codex CLI tool and VS Code extension, with proper API access "<a href="https://x.com/OpenAIDevs/status/1986861736041853368">coming soon</a>". I decided to use Codex to reverse engineer the Codex CLI tool and give me the ability to prompt the new model directly.</p>
<p>I made <a href="https://www.youtube.com/watch?v=9o1_DL9uNlM">a video</a> talking through my progress and demonstrating the final results.</p>

<p><lite-youtube videoid="9o1_DL9uNlM" js-api="js-api" title="Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican" playlabel="Play: Reverse engineering Codex CLI to get GPT-5-Codex-Mini to draw me a pelican"> </lite-youtube></p>

<ul>
  <li><a href="https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/#this-is-a-little-bit-cheeky">This is a little bit cheeky</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/#codex-cli-is-written-in-rust">Codex CLI is written in Rust</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/#iterating-on-the-code">Iterating on the code</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/#let-s-draw-some-pelicans">Let's draw some pelicans</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/9/gpt-5-codex-mini/#bonus-the-debug-option">Bonus: the --debug option</a></li>
</ul>

<h4 id="this-is-a-little-bit-cheeky">This is a little bit cheeky</h4>
<p>OpenAI clearly don't intend for people to access this model directly just yet. It's available exclusively through Codex CLI which is a privileged application - it gets to access a special backend API endpoint that's not publicly documented, and it uses a special authentication mechanism that bills usage directly to the user's existing ChatGPT account.</p>
<p>I figured reverse-engineering that API directly would be somewhat impolite. But... Codex CLI is an open source project released under an Apache 2.0 license. How about upgrading that to let me run my own prompts through its existing API mechanisms instead?</p>
<p>This felt like a somewhat absurd loophole, and I couldn't resist trying it out and seeing what happened.</p>
<h4 id="codex-cli-is-written-in-rust">Codex CLI is written in Rust</h4>
<p>The <a href="https://github.com/openai/codex">openai/codex</a> repository contains the source code for the Codex CLI tool, which OpenAI rewrote in Rust just a few months ago.</p>
<p>I don't know much Rust at all.</p>
<p>I made my own clone on GitHub and checked it out locally:</p>
<div class="highlight highlight-source-shell"><pre>git clone git@github.com:simonw/codex
<span class="pl-c1">cd</span> codex</pre></div>
<p>Then I fired up Codex itself (in dangerous mode, because I like living dangerously):</p>
<div class="highlight highlight-source-shell"><pre>codex --dangerously-bypass-approvals-and-sandbox</pre></div>
<p>And ran this prompt:</p>
<blockquote>
<p>Figure out how to build the rust version of this tool and then build it</p>
</blockquote>
<p>This worked. It churned away for a bit and figured out how to build itself. This is a useful starting point for a project like this - in figuring out the compile step the coding agent gets seeded with a little bit of relevant information about the project, and if it can compile that means it can later partially test the code it is writing while it works.</p>
<p>Once the compile had succeeded I fed it the design for the new feature I wanted:</p>
<blockquote>
<p>Add a new sub-command to the Rust tool called "codex prompt"</p>
<p>codex prompt "prompt goes here" - this runs the given prompt directly against the OpenAI API that Codex uses, with the same code path and authentication credentials as the rest of Codex.</p>
<p>codex prompt -m &lt;model_name&gt; "prompt goes here" - same again but lets you set the model</p>
<p>codex prompt "prompt goes here" -s/--system "system prompt goes here" - runs with a custom system/developer message</p>
<p>codex prompt --models - this lists all available models that can be used with the "codex prompt" command</p>
</blockquote>
<p>My design for this new sub-command is lifted directly from my own <a href="https://llm.datasette.io/en/stable/help.html#llm-prompt-help">llm command</a>.</p>
<h4 id="iterating-on-the-code">Iterating on the code</h4>
<p>Codex got to work. I've <a href="https://gistpreview.github.io/?ddabbff092bdd658e06d8a2e8f142098">shared the full transcript here</a> (using the tool <a href="https://simonwillison.net/2025/Oct/23/claude-code-for-web-video/">I described here</a>), but this TODO list it made itself is a useful summary of what it decided to do:</p>
<pre><code>Updated Plan
└ ✔ Inspect CLI structure and relevant core utilities for sending prompts and listing models
  ✔ Implement new `codex prompt` subcommand (CLI plumbing + command handler)
  ✔ Format, lint, and test (`just fmt`, `just fix -p codex-cli`, `cargo test -p codex-cli`)
</code></pre>
<p>I like that it figured out <a href="https://github.com/openai/codex/blob/a47181e471b6efe55e95f9858c913fc89a3a44fa/codex-rs/justfile">the justfile</a> in the repo and decided to use it to run formatting and linting commands without me needing to tell it to. (Update: it turns out that was dictated by the <a href="https://github.com/openai/codex/blob/f8b30af6dc275b3e64de5f1987e6cafe604cb72a/AGENTS.md">AGENTS.md</a> file.)</p>
<p>I tried running the first version of the code it wrote like this:</p>
<div class="highlight highlight-source-shell"><pre>./target/debug/codex prompt <span class="pl-s"><span class="pl-pds">'</span>Generate an SVG of a pelican riding a bicycle<span class="pl-pds">'</span></span> -m gpt-5-codex-mini</pre></div>
<p>... and it didn't quite work. I got this:</p>
<pre><code>(reasoning summary) **Seeking
(reasoning summary)  instructions
(reasoning summary)  and
(reasoning summary)  sandbox
(reasoning summary)  info
(reasoning summary) **
(reasoning summary) **Dec
(reasoning summary) iding
(reasoning summary)  on
(reasoning summary)  SVG
(reasoning summary)  creation
(reasoning summary)  approach
(reasoning summary) **
(reasoning summary) **Checking
(reasoning summary)  current
(reasoning summary)  directory
(reasoning summary) **
(reasoning summary) **Preparing
(reasoning summary)  to
(reasoning summary)  check
(reasoning summary)  current
(reasoning summary)  directory
(reasoning summary) **
I�m ready to help�what would you like me to do next?I�m ready to help�what would you like me to do next?
Token usage: total=2459 input=2374 cached_input=0 output=85 reasoning_output=64
</code></pre>
<p>Note that it DID think about SVG creation, but then decided it should look at the current directory. This isn't what I want - it appeared to be running in Codex's normal mode with a system prompt telling it to edit files on disk. I wanted it to respond to the prompt without acting as if it had a full workspace available to it.</p>
<p>I prompted it again, pasting in the broken output:</p>
<blockquote>
<p>this did not seem to work - here is what happened - note that the reasoning summary comes out on a lot of lines when I would rather it streams out to stderr on the same line (flushing constantly) - and then despite the reasoning summary thinking about pelican on SVG it did not actually act on that and display the result, which is very surprising. [pasted content]</p>
</blockquote>
<p>It churned for a bit more, but from the output it looked like it was still trying to include Codex-specific tools and workspace information. So I said:</p>
<blockquote>
<p>Note that this new 'codex prompt' command should NOT be able to execute any tools at all, and should not have to think about the workspace or sandbox - it should send a single prompt with no tools and then stream and display a response and then stop.</p>
</blockquote>
<p>This got me a new build, but when I ran it:</p>
<pre><code>Error: unexpected status 400 Bad Request: {"detail":"Instructions are not valid"}
</code></pre>
<p>My guess is that OpenAI's custom backend API for Codex doesn't like it if you attempt to call it <em>without</em> passing in the expected instructions. Fair enough!</p>
<p>Rather than paste that error in I got Codex to try the command itself, so it could see the error:</p>
<blockquote>
<p>You try running this and see what happens: ./target/debug/codex prompt 'Generate an SVG of a pelican riding a bicycle'</p>
</blockquote>
<p>Codex switched back to the default instructions. From its reply:</p>
<blockquote>
<p><code>cli/src/prompt_cmd.rs#L1-L320</code> now forces a tool-free request: we keep the workspace defaults, inject a lightweight system/developer message (“don’t run tools”), disable apply_patch/web search via config overrides, and build the outbound prompt as just that system span plus the user text.</p>
</blockquote>
<p>I guess that will have to do. I asked for one more feature:</p>
<blockquote>
<p>Add a --debug option to the codex prompt command which causes the full JSON request and response to be printed to stderr, plus the URL that is being accessed and the HTTP verb</p>
</blockquote>
<p>... and we're ready to try this thing out!</p>
<p>Notably I haven't written a single line of Rust myself here and paid almost no attention to what it was actually doing. My main contribution was to run the binary every now and then to see if it was doing what I needed yet.</p>
<p>I've pushed the working code to <a href="https://github.com/simonw/codex/compare/a47181e471b6efe55e95f9858c913fc89a3a44fa...ae5f98a9248a8edb5d3c53261273a482fc0b5306">a prompt-subcommand branch in my repo</a> if you want to take a look and see how it all works.</p>

<h4 id="let-s-draw-some-pelicans">Let's draw some pelicans</h4>
<p>With the final version of the code built, I drew some pelicans. Here's the <a href="https://gistpreview.github.io/?a11f9ac456d2b2bc3715ba900ef1203d">full terminal transcript</a>, but here are some highlights.</p>
<p>This is with the default GPT-5-Codex model:</p>
<div class="highlight highlight-source-shell"><pre>./target/debug/codex prompt <span class="pl-s"><span class="pl-pds">"</span>Generate an SVG of a pelican riding a bicycle<span class="pl-pds">"</span></span></pre></div>
<p>I pasted it into my <a href="https://tools.simonwillison.net/svg-render">tools.simonwillison.net/svg-render</a> tool and got the following:</p>
<p><img src="https://static.simonwillison.net/static/2025/codex-hacking-default.png" alt="It's a dumpy little pelican with a weird face, not particularly great" style="max-width: 100%;" /></p>
<p>I ran it again for GPT-5:</p>
<div class="highlight highlight-source-shell"><pre>./target/debug/codex prompt <span class="pl-s"><span class="pl-pds">"</span>Generate an SVG of a pelican riding a bicycle<span class="pl-pds">"</span></span> -m gpt-5</pre></div>
<p><img src="https://static.simonwillison.net/static/2025/codex-hacking-gpt-5.png" alt="Much better bicycle, pelican is a bit line-drawing-ish but does have the necessary parts in the right places" style="max-width: 100%;" /></p>
<p>And now the moment of truth... GPT-5 Codex Mini!</p>
<div class="highlight highlight-source-shell"><pre>./target/debug/codex prompt <span class="pl-s"><span class="pl-pds">"</span>Generate an SVG of a pelican riding a bicycle<span class="pl-pds">"</span></span> -m gpt-5-codex-mini</pre></div>
<p><img src="https://static.simonwillison.net/static/2025/codex-hacking-mini.png" alt="This is terrible. The pelican is an abstract collection of shapes, the bicycle is likewise very messed up" style="max-width: 100%;" /></p>
<p>I don't think I'll be adding that one to my SVG drawing toolkit any time soon.</p>

<h4 id="bonus-the-debug-option">Bonus: the --debug option</h4>
<p>I had Codex add a <code>--debug</code> option to help me see exactly what was going on.</p>
<div class="highlight highlight-source-shell"><pre>./target/debug/codex prompt -m gpt-5-codex-mini <span class="pl-s"><span class="pl-pds">"</span>Generate an SVG of a pelican riding a bicycle<span class="pl-pds">"</span></span> --debug</pre></div>
<p>The output starts like this:</p>
<pre><code>[codex prompt debug] POST https://chatgpt.com/backend-api/codex/responses
[codex prompt debug] Request JSON:
</code></pre>
<div class="highlight highlight-source-json"><pre>{
  <span class="pl-ent">"model"</span>: <span class="pl-s"><span class="pl-pds">"</span>gpt-5-codex-mini<span class="pl-pds">"</span></span>,
  <span class="pl-ent">"instructions"</span>: <span class="pl-s"><span class="pl-pds">"</span>You are Codex, based on GPT-5. You are running as a coding agent ...<span class="pl-pds">"</span></span>,
  <span class="pl-ent">"input"</span>: [
    {
      <span class="pl-ent">"type"</span>: <span class="pl-s"><span class="pl-pds">"</span>message<span class="pl-pds">"</span></span>,
      <span class="pl-ent">"role"</span>: <span class="pl-s"><span class="pl-pds">"</span>developer<span class="pl-pds">"</span></span>,
      <span class="pl-ent">"content"</span>: [
        {
          <span class="pl-ent">"type"</span>: <span class="pl-s"><span class="pl-pds">"</span>input_text<span class="pl-pds">"</span></span>,
          <span class="pl-ent">"text"</span>: <span class="pl-s"><span class="pl-pds">"</span>You are a helpful assistant. Respond directly to the user request without running tools or shell commands.<span class="pl-pds">"</span></span>
        }
      ]
    },
    {
      <span class="pl-ent">"type"</span>: <span class="pl-s"><span class="pl-pds">"</span>message<span class="pl-pds">"</span></span>,
      <span class="pl-ent">"role"</span>: <span class="pl-s"><span class="pl-pds">"</span>user<span class="pl-pds">"</span></span>,
      <span class="pl-ent">"content"</span>: [
        {
          <span class="pl-ent">"type"</span>: <span class="pl-s"><span class="pl-pds">"</span>input_text<span class="pl-pds">"</span></span>,
          <span class="pl-ent">"text"</span>: <span class="pl-s"><span class="pl-pds">"</span>Generate an SVG of a pelican riding a bicycle<span class="pl-pds">"</span></span>
        }
      ]
    }
  ],
  <span class="pl-ent">"tools"</span>: [],
  <span class="pl-ent">"tool_choice"</span>: <span class="pl-s"><span class="pl-pds">"</span>auto<span class="pl-pds">"</span></span>,
  <span class="pl-ent">"parallel_tool_calls"</span>: <span class="pl-c1">false</span>,
  <span class="pl-ent">"reasoning"</span>: {
    <span class="pl-ent">"summary"</span>: <span class="pl-s"><span class="pl-pds">"</span>auto<span class="pl-pds">"</span></span>
  },
  <span class="pl-ent">"store"</span>: <span class="pl-c1">false</span>,
  <span class="pl-ent">"stream"</span>: <span class="pl-c1">true</span>,
  <span class="pl-ent">"include"</span>: [
    <span class="pl-s"><span class="pl-pds">"</span>reasoning.encrypted_content<span class="pl-pds">"</span></span>
  ],
  <span class="pl-ent">"prompt_cache_key"</span>: <span class="pl-s"><span class="pl-pds">"</span>019a66bf-3e2c-7412-b05e-db9b90bbad6e<span class="pl-pds">"</span></span>
}</pre></div>
<p>This reveals that OpenAI's private API endpoint for Codex CLI is <code>https://chatgpt.com/backend-api/codex/responses</code>.</p>
<p>Also interesting is how the <code>"instructions"</code> key (truncated above, <a href="https://gist.github.com/simonw/996388ecf785ad54de479315bd4d33b7">full copy here</a>) contains the default instructions, without which the API appears not to work - but it also shows that you can send a message with <code>role="developer"</code> in advance of your user prompt.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/rust">rust</a>, <a href="https://simonwillison.net/tags/openai">openai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a>, <a href="https://simonwillison.net/tags/llm-release">llm-release</a>, <a href="https://simonwillison.net/tags/vibe-coding">vibe-coding</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/gpt-5">gpt-5</a>, <a href="https://simonwillison.net/tags/codex-cli">codex-cli</a></p>]]></description><pubDate>Sun, 9 Nov 2025 03:31:34 +0000</pubDate></item><item><title>Quoting Kenton Varda</title><link>https://simonwillison.net/2025/Nov/8/kenton-varda/#atom-everything</link><description><![CDATA[<blockquote cite="https://x.com/kentonvarda/status/1987208904724652273"><p>The big advantage of MCP over OpenAPI is that it is very clear about auth. [...]</p>
<p>Maybe an agent could read the docs and write code to auth. But we don't actually want that, because it implies the agent gets access to the API token! We want the agent's harness to handle that and never reveal the key to the agent. [...]</p>
<p>OAuth has always assumed that the client knows what API it's talking to, and so the client's developer can register the client with that API in advance to get a client_id/client_secret pair. Agents, though, don't know what MCPs they'll talk to in advance.</p>
<p>So MCP <a href="https://modelcontextprotocol.io/specification/draft/basic/authorization#dynamic-client-registration">requires OAuth dynamic client registration</a> (<a href="https://datatracker.ietf.org/doc/html/rfc7591">RFC 7591</a>), which practically nobody actually implemented prior to MCP. DCR might as well have been introduced by MCP, and may actually be the most important unlock in the whole spec.</p></blockquote>
<p class="cite">&mdash; <a href="https://x.com/kentonvarda/status/1987208904724652273">Kenton Varda</a></p>

    <p>Tags: <a href="https://simonwillison.net/tags/kenton-varda">kenton-varda</a>, <a href="https://simonwillison.net/tags/security">security</a>, <a href="https://simonwillison.net/tags/oauth">oauth</a>, <a href="https://simonwillison.net/tags/model-context-protocol">model-context-protocol</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p>]]></description><pubDate>Sat, 8 Nov 2025 22:04:45 +0000</pubDate></item><item><title>Mastodon 4.5</title><link>https://simonwillison.net/2025/Nov/8/mastodon-45/#atom-everything</link><description><![CDATA[<p><strong><a href="https://blog.joinmastodon.org/2025/11/mastodon-4.5/">Mastodon 4.5</a></strong></p>
This new release of Mastodon adds two of my most desired features!</p>
<p>The first is support for quote posts. This had already become an unofficial feature in the client apps I was using (<a href="https://phanpy.social/">phanpy.social</a> on the web and <a href="https://apps.apple.com/us/app/ivory-for-mastodon-by-tapbots/id6444602274">Ivory</a> on iOS) but now it's officially part of Mastodon's core platform.</p>
<p>Much more notably though:</p>
<blockquote>
<p><strong>Fetch All Replies: Completing the Conversation Flow</strong></p>
<p>Users on servers running 4.4 and earlier versions have likely experienced the confusion of seeing replies appearing on other servers but not their own. Mastodon 4.5 automatically checks for missing replies upon page load and again every 15 minutes, enhancing continuity of conversations across the Fediverse.</p>
</blockquote>
<p>The absolute worst thing about Mastodon - especially if you run on your own independent server - is that the nature of the platform means you can't be guaranteed to see every reply to a post your are viewing that originated on another instance (<a href="https://simonwillison.net/2023/Sep/16/notes-on-using-a-single-person-mastodon-server/">previously</a>).</p>
<p>This leads to an unpleasant reply-guy effect where you find yourself replying to a post saying the exact same thing that everyone else said... because you didn't see any of the other replies before you posted!</p>
<p>Mastodon 4.5 finally solves this problem!</p>
<p>I went looking for the GitHub issue about this and found <a href="https://github.com/mastodon/mastodon/issues/22674">this one that quoted my complaint about this</a> from December 2022, which is marked as a duplicate of this <a href="https://github.com/mastodon/mastodon/issues/9409">Fetch whole conversation threads issue</a> from 2018.</p>
<p>So happy to see this finally resolved.

    <p><small></small>Via <a href="https://lobste.rs/s/zvyspo/mastodon_4_5">lobste.rs</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/mastodon">mastodon</a></p>]]></description><pubDate>Sat, 8 Nov 2025 01:52:14 +0000</pubDate></item><item><title>Quoting Josh Cohenzadeh</title><link>https://simonwillison.net/2025/Nov/7/josh-cohenzadeh/#atom-everything</link><description><![CDATA[<blockquote cite="https://www.josh.ing/blog/aidhd"><p><strong>I have AiDHD</strong></p>
<p>It has never been easier to build an MVP and in turn, it has never been harder to keep focus. When new features always feel like they're just a prompt away, feature creep feels like a never ending battle. Being disciplined is more important than ever.</p>
<p>AI still doesn't change one very important thing: you still need to make something people want. I think that getting users (even free ones) will become significantly harder as the bar for user's time will only get higher as their options increase.</p>
<p>Being quicker to get to the point of failure is actually incredibly valuable. Even just over a year ago, many of these projects would have taken months to build.</p></blockquote>
<p class="cite">&mdash; <a href="https://www.josh.ing/blog/aidhd">Josh Cohenzadeh</a>, AiDHD</p>

    <p>Tags: <a href="https://simonwillison.net/tags/vibe-coding">vibe-coding</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a></p>]]></description><pubDate>Fri, 7 Nov 2025 16:38:03 +0000</pubDate></item><item><title>Could LLMs encourage new programming languages?</title><link>https://simonwillison.net/2025/Nov/7/llms-for-new-programming-languages/#atom-everything</link><description><![CDATA[<p>My hunch is that existing LLMs make it <em>easier</em> to build a new programming language in a way that captures new developers.</p>
<p>Most programming languages are similar enough to existing languages that you only need to know a small number of details to use them: what's the core syntax for variables, loops, conditionals and functions? How does memory management work? What's the concurrency model?</p>
<p>For many languages you can fit all of that, including illustrative examples, in a few thousand tokens of text.</p>
<p>So ship your new programming language with a <a href="https://simonwillison.net/2025/Oct/16/claude-skills/">Claude Skills style document</a> and give your early adopters the ability to write it with LLMs. The LLMs should handle that very well, especially if they get to run an agentic loop against a compiler or even a linter that you provide.</p>
<p><small>This post started <a href="https://news.ycombinator.com/context?id=45847505">as a comment</a>.</small></p>

    <p>Tags: <a href="https://simonwillison.net/tags/skills">skills</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/programming-languages">programming-languages</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/hacker-news">hacker-news</a></p>]]></description><pubDate>Fri, 7 Nov 2025 16:00:42 +0000</pubDate></item><item><title>Using Codex CLI with gpt-oss:120b on an NVIDIA DGX Spark via Tailscale</title><link>https://simonwillison.net/2025/Nov/7/codex-tailscale-spark/#atom-everything</link><description><![CDATA[<p><strong><a href="https://til.simonwillison.net/llms/codex-spark-gpt-oss">Using Codex CLI with gpt-oss:120b on an NVIDIA DGX Spark via Tailscale</a></strong></p>
Inspired by a <a href="https://www.youtube.com/watch?v=qy4ci7AoF9Y&amp;lc=UgzaGdLX8TAuQ9ugx1Z4AaABAg">YouTube comment</a> I wrote up how I run OpenAI's Codex CLI coding agent against the gpt-oss:120b model running in Ollama on my <a href="https://simonwillison.net/2025/Oct/14/nvidia-dgx-spark/">NVIDIA DGX Spark</a> via a Tailscale network.</p>
<p>It takes a little bit of work to configure but the result is I can now use Codex CLI on my laptop anywhere in the world against a self-hosted model.</p>
<p>I used it to build <a href="https://static.simonwillison.net/static/2025/gpt-oss-120b-invaders.html">this space invaders clone</a>.


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/tailscale">tailscale</a>, <a href="https://simonwillison.net/tags/til">til</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/local-llms">local-llms</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/nvidia">nvidia</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/space-invaders">space-invaders</a>, <a href="https://simonwillison.net/tags/codex-cli">codex-cli</a>, <a href="https://simonwillison.net/tags/nvidia-spark">nvidia-spark</a></p>]]></description><pubDate>Fri, 7 Nov 2025 07:23:12 +0000</pubDate></item><item><title>Game design is simple, actually</title><link>https://simonwillison.net/2025/Nov/7/game-design-is-simple-actually/#atom-everything</link><description><![CDATA[<p><strong><a href="https://www.raphkoster.com/2025/11/03/game-design-is-simple-actually/">Game design is simple, actually</a></strong></p>
Game design legend Raph Koster (Ultima Online, Star Wars Galaxies and many more) provides a deeply informative and delightfully illustrated "twelve-step program for understanding game design."</p>
<p>You know it's going to be good when the first section starts by defining "fun".

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=45841262">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/game-design">game-design</a></p>]]></description><pubDate>Fri, 7 Nov 2025 05:47:03 +0000</pubDate></item><item><title>You should write an agent</title><link>https://simonwillison.net/2025/Nov/7/you-should-write-an-agent/#atom-everything</link><description><![CDATA[<p><strong><a href="https://fly.io/blog/everyone-write-an-agent/">You should write an agent</a></strong></p>
Thomas Ptacek on the Fly blog:</p>
<blockquote>
<p>Agents are the most surprising programming experience I’ve had in my career. Not because I’m awed by the magnitude of their powers — I like them, but I don’t like-like them. It’s because of how easy it was to get one up on its legs, and how much I learned doing that.</p>
</blockquote>
<p>I think he's right: hooking up a simple agentic loop that prompts an LLM and runs a tool for it any time it request one really is the new "hello world" of AI engineering.

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=45840088">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/thomas-ptacek">thomas-ptacek</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/fly">fly</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-agents">ai-agents</a></p>]]></description><pubDate>Fri, 7 Nov 2025 04:40:12 +0000</pubDate></item><item><title>Quoting Ben Stolovitz</title><link>https://simonwillison.net/2025/Nov/7/ben-stolovitz/#atom-everything</link><description><![CDATA[<blockquote cite="https://ben.stolovitz.com/posts/how_use_ai_oct_2025/"><p>My trepidation extends to complex <strong>literature searches</strong>. I use LLMs as secondary librarians when I’m doing research. They reliably find primary sources (articles, papers, etc.) that I miss in my initial searches.</p>
<p>But these searches are <em>dangerous</em>. I distrust LLM librarians. There is so much data in the world: you can (in good faith!) find evidence to support almost any position or conclusion. ChatGPT is not a human, and, unlike teachers &amp; librarians &amp; scholars, ChatGPT does not have a consistent, legible worldview. In my experience, it readily agrees with any premise you hand it — and brings citations. It may have read every article that can be read, but it has no real opinion — so it is not a credible expert.</p></blockquote>
<p class="cite">&mdash; <a href="https://ben.stolovitz.com/posts/how_use_ai_oct_2025/">Ben Stolovitz</a>, How I use AI</p>

    <p>Tags: <a href="https://simonwillison.net/tags/ai-assisted-search">ai-assisted-search</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a></p>]]></description><pubDate>Fri, 7 Nov 2025 00:15:55 +0000</pubDate></item><item><title>Kimi K2 Thinking</title><link>https://simonwillison.net/2025/Nov/6/kimi-k2-thinking/#atom-everything</link><description><![CDATA[<p><strong><a href="https://huggingface.co/moonshotai/Kimi-K2-Thinking">Kimi K2 Thinking</a></strong></p>
Chinese AI lab Moonshot's Kimi K2 established itself as one of the largest open weight models - 1 trillion parameters - <a href="https://simonwillison.net/2025/Jul/11/kimi-k2/">back in July</a>. They've now released the Thinking version, also a trillion parameters (MoE, 32B active) and also under their custom modified (so <a href="https://simonwillison.net/2025/Jul/11/kimi-k2/#kimi-license">not quite open source</a>) MIT license.</p>
<blockquote>
<p>Starting with Kimi K2, we built it as a thinking agent that reasons step-by-step while dynamically invoking tools. It sets a new state-of-the-art on Humanity's Last Exam (HLE), BrowseComp, and other benchmarks by dramatically scaling multi-step reasoning depth and maintaining stable tool-use across 200–300 sequential calls. At the same time, K2 Thinking is a native INT4 quantization model with 256k context window, achieving lossless reductions in inference latency and GPU memory usage.</p>
</blockquote>
<p>This one is only 594GB on Hugging Face - Kimi K2 was 1.03TB - which I think is due to the new INT4 quantization. This makes the model both cheaper and faster to host.</p>
<p>So far the only people hosting it are Moonshot themselves. I tried it out both via <a href="https://platform.moonshot.ai">their own API</a> and via <a href="https://openrouter.ai/moonshotai/kimi-k2-thinking/providers">the OpenRouter proxy to it</a>, via the <a href="https://github.com/ghostofpokemon/llm-moonshot">llm-moonshot</a> plugin (by NickMystic) and my <a href="https://github.com/simonw/llm-openrouter">llm-openrouter</a> plugin respectively.</p>
<p>The buzz around this model so far is very positive. Could this be the first open weight model that's competitive with the latest from OpenAI and Anthropic, especially for long-running agentic tool call sequences?</p>
<p>Moonshot AI's <a href="https://moonshotai.github.io/Kimi-K2/thinking.html">self-reported benchmark scores</a> show K2 Thinking beating the top OpenAI and Anthropic models (GPT-5 and Sonnet 4.5 Thinking) at "Agentic Reasoning" and "Agentic Search" but not quite top for "Coding":</p>
<p><img alt="Comparison bar chart showing agentic reasoning, search, and coding benchmark performance scores across three AI systems (K, OpenAI, and AI) on tasks including Humanity's Last Exam (44.9, 41.7, 32.0), BrowseComp (60.2, 54.9, 24.1), Seal-0 (56.3, 51.4, 53.4), SWE-Multilingual (61.1, 55.3, 68.0), SWE-bench Verified (71.3, 74.9, 77.2), and LiveCodeBench V6 (83.1, 87.0, 64.0), with category descriptions including &quot;Expert-level questions across subjects&quot;, &quot;Agentic search &amp; browsing&quot;, &quot;Real-world latest information collection&quot;, &quot;Agentic coding&quot;, and &quot;Competitive programming&quot;." src="https://static.simonwillison.net/static/2025/kimi-k2-thinking-benchmarks.jpg" /></p>
<p>I ran a couple of pelican tests:</p>
<pre><code>llm install llm-moonshot
llm keys set moonshot # paste key
llm -m moonshot/kimi-k2-thinking 'Generate an SVG of a pelican riding a bicycle'
</code></pre>
<p><img alt="Sonnet 4.5 described this as: Cartoon illustration of a white duck or goose with an orange beak and gray wings riding a bicycle with a red frame and light blue wheels against a light blue background." src="https://static.simonwillison.net/static/2025/k2-thinking.png" /></p>
<pre><code>llm install llm-openrouter
llm keys set openrouter # paste key
llm -m openrouter/moonshotai/kimi-k2-thinking \
  'Generate an SVG of a pelican riding a bicycle'
</code></pre>
<p><img alt="Sonnet 4.5: Minimalist cartoon illustration of a white bird with an orange beak and feet standing on a triangular-framed penny-farthing style bicycle with gray-hubbed wheels and a propeller hat on its head, against a light background with dotted lines and a brown ground line." src="https://static.simonwillison.net/static/2025/k2-thinking-openrouter.png" /></p>
<p>Artificial Analysis <a href="https://x.com/ArtificialAnlys/status/1986541785511043536">said</a>:</p>
<blockquote>
<p>Kimi K2 Thinking achieves 93% in 𝜏²-Bench Telecom, an agentic tool use benchmark where the model acts as a customer service agent. This is the highest score we have independently measured. Tool use in long horizon agentic contexts was a strength of Kimi K2 Instruct and it appears this new Thinking variant makes substantial gains</p>
</blockquote>
<p>CNBC quoted a source who <a href="https://www.cnbc.com/2025/11/06/alibaba-backed-moonshot-releases-new-ai-model-kimi-k2-thinking.html">provided the training price</a> for the model:</p>
<blockquote>
<p>The Kimi K2 Thinking model cost $4.6 million to train, according to a source familiar with the matter. [...] CNBC was unable to independently verify the DeepSeek or Kimi figures.</p>
</blockquote>
<p>MLX developer Awni Hannun <a href="https://x.com/awnihannun/status/1986601104130646266">got it working</a> on two 512GB M3 Ultra Mac Studios:</p>
<blockquote>
<p>The new 1 Trillion parameter Kimi K2 Thinking model runs well on 2 M3 Ultras in its native format - no loss in quality!</p>
<p>The model was quantization aware trained (qat) at int4.</p>
<p>Here it generated ~3500 tokens at 15 toks/sec using pipeline-parallelism in mlx-lm</p>
</blockquote>
<p>Here's <a href="https://huggingface.co/mlx-community/Kimi-K2-Thinking">the 658GB mlx-community model</a>.


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/llm">llm</a>, <a href="https://simonwillison.net/tags/mlx">mlx</a>, <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle">pelican-riding-a-bicycle</a>, <a href="https://simonwillison.net/tags/llm-reasoning">llm-reasoning</a>, <a href="https://simonwillison.net/tags/llm-release">llm-release</a>, <a href="https://simonwillison.net/tags/openrouter">openrouter</a>, <a href="https://simonwillison.net/tags/ai-in-china">ai-in-china</a>, <a href="https://simonwillison.net/tags/artificial-analysis">artificial-analysis</a>, <a href="https://simonwillison.net/tags/moonshot">moonshot</a>, <a href="https://simonwillison.net/tags/kimi">kimi</a></p>]]></description><pubDate>Thu, 6 Nov 2025 23:53:06 +0000</pubDate></item><item><title>Quoting Nathan Lambert</title><link>https://simonwillison.net/2025/Nov/6/nathan-lambert/#atom-everything</link><description><![CDATA[<blockquote cite="https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means"><p>At the start of the year, most people loosely following AI probably knew of 0 [Chinese] AI labs. Now, and towards wrapping up 2025, I’d say all of DeepSeek, Qwen, and Kimi are becoming household names. They all have seasons of their best releases and different strengths. The important thing is this’ll be a growing list. A growing share of cutting edge mindshare is shifting to China. I expect some of the likes of Z.ai, Meituan, or Ant Ling to potentially join this list next year. For some of these labs releasing top tier benchmark models, they literally started their foundation model effort after DeepSeek. It took many Chinese companies only 6 months to catch up to the open frontier in ballpark of performance, now the question is if they can offer something in a niche of the frontier that has real demand for users.</p></blockquote>
<p class="cite">&mdash; <a href="https://www.interconnects.ai/p/kimi-k2-thinking-what-it-means">Nathan Lambert</a>, 5 Thoughts on Kimi K2 Thinking</p>

    <p>Tags: <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/ai-in-china">ai-in-china</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/nathan-lambert">nathan-lambert</a>, <a href="https://simonwillison.net/tags/kimi">kimi</a>, <a href="https://simonwillison.net/tags/moonshot">moonshot</a></p>]]></description><pubDate>Thu, 6 Nov 2025 21:44:33 +0000</pubDate></item><item><title>Video + notes on upgrading a Datasette plugin for the latest 1.0 alpha, with help from uv and OpenAI Codex CLI</title><link>https://simonwillison.net/2025/Nov/6/upgrading-datasette-plugins/#atom-everything</link><description><![CDATA[<p>I'm upgrading various plugins for compatibility with the new <a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/">Datasette 1.0a20 alpha release</a> and I decided to record <a href="https://www.youtube.com/watch?v=qy4ci7AoF9Y">a video</a> of the process. This post accompanies that video with detailed additional notes.</p>

<p><lite-youtube videoid="qy4ci7AoF9Y" js-api="js-api" title="My process for upgrading Datasette plugins with uv and OpenAI Codex CLI" playlabel="Play: My process for upgrading Datasette plugins with uv and OpenAI Codex CLI"> </lite-youtube></p>

<h4 id="the-datasette-checkbox-plugin">The datasette-checkbox plugin</h4>
<p>I picked a very simple plugin to illustrate the upgrade process (possibly too simple). <a href="https://github.com/datasette/datasette-checkbox">datasette-checkbox</a> adds just one feature to Datasette: if you are viewing a table with boolean columns (detected as integer columns with names like <code>is_active</code> or <code>has_attachments</code> or <code>should_notify</code>) <em>and</em> your current user has permission to update rows in that table it adds an inline checkbox UI that looks like this:</p>
<p><img src="https://static.simonwillison.net/static/2025/datasette-checkbox.gif" alt="Animated demo of a table with name, is_done, should_be_deleted and is_happy columns. Each column has checkboxes, and clicking a checkboxflashes a little &quot;updated&quot; message." style="max-width: 100%;" /></p>
<p>I built the first version with the help of Claude back in August 2024 - details <a href="https://github.com/datasette/datasette-checkbox/issues/1#issuecomment-2294168693">in this issue comment</a>.</p>
<p>Most of the implementation is JavaScript that makes calls to Datasette 1.0's <a href="https://simonwillison.net/2022/Dec/2/datasette-write-api/">JSON write API</a>. The Python code just checks that the user has the necessary permissions before including the extra JavaScript.</p>
<h4 id="running-the-plugin-s-tests">Running the plugin's tests</h4>
<p>The first step in upgrading any plugin is to run its tests against the latest Datasette version.</p>
<p>Thankfully <code>uv</code> makes it easy to run code in scratch virtual environments that include the different code versions you want to test against.</p>
<p>I have a test utility called <code>tadd</code> (for "test against development Datasette") which I use for that purpose. I can run it in any plugin directory like this:</p>
<div class="highlight highlight-source-shell"><pre>tadd</pre></div>
<p>And it will run the existing plugin tests against whatever version of Datasette I have checked out in my <code>~/dev/datasette</code> directory.</p>
<p>You can see the full implementation of <code>tadd</code> (and its friend <code>radd</code> described below) <a href="https://til.simonwillison.net/python/uv-tests#variants-tadd-and-radd">in this TIL</a> - the basic version looks like this:</p>
<div class="highlight highlight-source-shell"><pre><span class="pl-c"><span class="pl-c">#!</span>/bin/sh</span>
uv run --no-project --isolated \
  --with-editable <span class="pl-s"><span class="pl-pds">'</span>.[test]<span class="pl-pds">'</span></span> --with-editable <span class="pl-k">~</span>/dev/datasette \
  python -m pytest <span class="pl-s"><span class="pl-pds">"</span><span class="pl-smi">$@</span><span class="pl-pds">"</span></span></pre></div>
<p>I started by running <code>tadd</code> in the <code>datasette-checkbox</code> directory, and got my first failure... but it wasn't due to permissions, it was because the <code>pyproject.toml</code> for the plugin was <a href="https://github.com/datasette/datasette-checkbox/blob/0.1a3/pyproject.toml#L13C1-L15C2">pinned</a> to a specific mismatched version of Datasette:</p>
<div class="highlight highlight-source-toml"><pre><span class="pl-smi">dependencies</span> = [
    <span class="pl-s"><span class="pl-pds">"</span>datasette==1.0a19<span class="pl-pds">"</span></span>
]</pre></div>
<p>I fixed this problem by swapping <code>==</code> to <code>&gt;=</code> and ran the tests again... and they passed! Which was a problem because I was expecting permission-related failures.</p>
<p>It turns out when I first wrote the plugin I was <a href="https://github.com/datasette/datasette-checkbox/blob/0.1a3/tests/test_checkbox.py">lazy with the tests</a> - they weren't actually confirming that the table page loaded without errors.</p>
<p>I needed to actually run the code myself to see the expected bug.</p>
<p>First I created myself a demo database using <a href="https://sqlite-utils.datasette.io/en/stable/cli.html#creating-tables">sqlite-utils create-table</a>:</p>
<div class="highlight highlight-source-shell"><pre>sqlite-utils create-table demo.db \
  demo id integer is_checked integer --pk id</pre></div>
<p>Then I ran it with Datasette against the plugin's code like so:</p>
<div class="highlight highlight-source-shell"><pre>radd demo.db</pre></div>
<p>Sure enough, visiting <code>/demo/demo</code> produced a 500 error about the missing <code>Datasette.permission_allowed()</code> method.</p>
<p>The next step was to update the test to also trigger this error:</p>
<pre><span class="pl-en">@<span class="pl-s1">pytest</span>.<span class="pl-c1">mark</span>.<span class="pl-c1">asyncio</span></span>
<span class="pl-k">async</span> <span class="pl-k">def</span> <span class="pl-en">test_plugin_adds_javascript</span>():
    <span class="pl-s1">datasette</span> <span class="pl-c1">=</span> <span class="pl-en">Datasette</span>()
    <span class="pl-s1">db</span> <span class="pl-c1">=</span> <span class="pl-s1">datasette</span>.<span class="pl-c1">add_memory_database</span>(<span class="pl-s">"demo"</span>)
    <span class="pl-k">await</span> <span class="pl-s1">db</span>.<span class="pl-c1">execute_write</span>(
        <span class="pl-s">"CREATE TABLE IF NOT EXISTS test (id INTEGER PRIMARY KEY, is_active INTEGER)"</span>
    )
    <span class="pl-k">await</span> <span class="pl-s1">datasette</span>.<span class="pl-c1">invoke_startup</span>()
    <span class="pl-s1">response</span> <span class="pl-c1">=</span> <span class="pl-k">await</span> <span class="pl-s1">datasette</span>.<span class="pl-c1">client</span>.<span class="pl-c1">get</span>(<span class="pl-s">"/demo/test"</span>)
    <span class="pl-k">assert</span> <span class="pl-s1">response</span>.<span class="pl-c1">status_code</span> <span class="pl-c1">==</span> <span class="pl-c1">200</span></pre>
<p>And now <code>tadd</code> fails as expected.</p>
<h4 id="upgrading-the-plugin-with-codex">Upgrading the plugin with Codex</h4>
<p>It this point I could have manually fixed the plugin itself - which would likely have been faster given the small size of the fix - but instead I demonstrated a bash one-liner I've been using to apply these kinds of changes automatically:</p>
<div class="highlight highlight-source-shell"><pre>codex <span class="pl-c1">exec</span> --dangerously-bypass-approvals-and-sandbox \
<span class="pl-s"><span class="pl-pds">"</span>Run the command tadd and look at the errors and then</span>
<span class="pl-s">read ~/dev/datasette/docs/upgrade-1.0a20.md and apply</span>
<span class="pl-s">fixes and run the tests again and get them to pass<span class="pl-pds">"</span></span></pre></div>
<p><code>codex exec</code> runs OpenAI Codex in non-interactive mode - it will loop until it has finished the prompt you give it.</p>
<p>I tell it to consult the subset of the <a href="https://docs.datasette.io/en/latest/upgrade_guide.html#datasette-1-0a20-plugin-upgrade-guide">Datasette upgrade documentation</a> that talks about Datasette permissions and then get the <code>tadd</code> command to pass its tests.</p>
<p>This is an example of what I call <a href="https://simonwillison.net/2025/Sep/30/designing-agentic-loops/">designing agentic loops</a> - I gave Codex the tools it needed (<code>tadd</code>) and a clear goal and let it get to work on my behalf.</p>
<p>The remainder of the video covers finishing up the work - testing the fix manually, commiting my work using:</p>
<div class="highlight highlight-source-shell"><pre>git commit -a -m <span class="pl-s"><span class="pl-pds">"</span><span class="pl-s"><span class="pl-pds">$(</span>basename <span class="pl-s"><span class="pl-pds">"</span><span class="pl-smi">$PWD</span><span class="pl-pds">"</span></span><span class="pl-pds">)</span></span> for datasette&gt;=1.0a20<span class="pl-pds">"</span></span> \
  -m <span class="pl-s"><span class="pl-pds">"</span>Refs https://github.com/simonw/datasette/issues/2577<span class="pl-pds">"</span></span></pre></div>
<p>Then shipping a <a href="https://pypi.org/project/datasette-checkbox/0.1a4/">0.1a4 release</a> to PyPI using the pattern <a href="https://til.simonwillison.net/pypi/pypi-releases-from-github">described in this TIL</a>.
Finally, I demonstrated that the shipped plugin worked in a fresh environment using <code>uvx</code> like this:</p>
<div class="highlight highlight-source-shell"><pre>uvx --prerelease=allow --with datasette-checkbox \
  datasette --root <span class="pl-k">~</span>/dev/ecosystem/datasette-checkbox/demo.db</pre></div>
<p>Executing this command installs and runs a fresh Datasette instance with a fresh copy of the new alpha plugin (<code>--prerelease=allow</code>). It's a neat way of confirming that freshly released software works as expected.</p>
<h4 id="a-colophon-for-the-video">A colophon for the video</h4>
<p>This video was shot in a single take using <a href="https://www.descript.com/">Descript</a>, with no rehearsal and perilously little preparation in advance. I recorded through my AirPods and applied the "Studio Sound" filter to clean up the audio. I pasted in a <code>simonwillison.net</code> closing slide from <a href="https://simonwillison.net/2025/Oct/23/claude-code-for-web-video/">my previous video</a> and exported it locally at 1080p, then uploaded it to YouTube.</p>
<p>Something I learned from the Software Carpentry <a href="https://simonwillison.net/2020/Sep/26/weeknotes-software-carpentry-sqlite/">instructor training course</a> is that making mistakes in front of an audience is actively helpful - it helps them see a realistic version of how software development works and they can learn from watching you recover. I see this as a great excuse for not editing out all of my mistakes!</p>
<p>I'm trying to build new habits around video content that let me produce useful videos while minimizing the amount of time I spend on production.</p>
<p>I plan to iterate more on the format as I get more comfortable with the process. I'm hoping I can find the right balance between production time and value to viewers.</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/plugins">plugins</a>, <a href="https://simonwillison.net/tags/python">python</a>, <a href="https://simonwillison.net/tags/youtube">youtube</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/datasette">datasette</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/uv">uv</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/codex-cli">codex-cli</a></p>]]></description><pubDate>Thu, 6 Nov 2025 18:26:05 +0000</pubDate></item><item><title>Code research projects with async coding agents like Claude Code and Codex</title><link>https://simonwillison.net/2025/Nov/6/async-code-research/#atom-everything</link><description><![CDATA[<p>I've been experimenting with a pattern for LLM usage recently that's working out really well: <strong>asynchronous code research tasks</strong>. Pick a research question, spin up an asynchronous coding agent and let it go and run some experiments and report back when it's done.</p>
<ul>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#code-research">Code research</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#coding-agents">Coding agents</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#asynchronous-coding-agents">Asynchronous coding agents</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#give-them-a-dedicated-github-repository">Give them a dedicated GitHub repository</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#let-them-rip-with-unlimited-network-access">Let them rip with unlimited network access</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#my-simonw-research-collection">My simonw/research collection</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#this-is-total-slop-of-course">This is total slop, of course</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/6/async-code-research/#try-it-yourself">Try it yourself</a></li>
</ul>
<h4 id="code-research">Code research</h4>
<p>Software development benefits enormously from something I call <strong>code research</strong>. The great thing about questions about code is that they can often be definitively answered by writing and executing code.</p>
<p>I often see questions on forums which hint at a lack of understanding of this skill.</p>
<p>"Could Redis work for powering the notifications feed for my app?" is a great example. The answer is <em>always</em> "it depends", but a better answer is that a good programmer already has everything they need to answer that question for themselves. Build a proof-of-concept, simulate the patterns you expect to see in production, then run experiments to see if it's going to work.</p>
<p>I've been a keen practitioner of code research for a long time. Many of my most interesting projects started out as a few dozen lines of experimental code to prove to myself that something was possible.</p>
<h4 id="coding-agents">Coding agents</h4>
<p>It turns out <strong>coding agents</strong> like Claude Code and Codex are a fantastic fit for this kind of work as well. Give them the right goal and a useful environment and they'll churn through a basic research project without any further supervision.</p>
<p>LLMs hallucinate and make mistakes. This is far less important for code research tasks because the code itself doesn't lie: if they write code and execute it and it does the right things then they've demonstrated to both themselves and to you that something really does work.</p>
<p>They can't prove something is impossible - just because the coding agent couldn't find a way to do something doesn't mean it can't be done - but they can often demonstrate that something <em>is</em> possible in just a few minutes of crunching.</p>
<h4 id="asynchronous-coding-agents">Asynchronous coding agents</h4>
<p>I've used interactive coding agents like Claude Code and Codex CLI for a bunch of these, but today I'm increasingly turning to their <strong>asynchronous coding agent</strong> family members instead.</p>
<p>An asynchronous coding agent is a coding agent that operates on a fire-and-forget basis. You pose it a task, it churns away on a server somewhere and when it's done it files a pull request against your chosen GitHub repository.</p>
<p>OpenAI's <a href="https://chatgpt.com/codex">Codex Cloud</a>, Anthropic's <a href="https://claude.ai/code">Claude Code for web</a>, Google Gemini's <a href="https://jules.google/">Jules</a>, and GitHub's <a href="https://docs.github.com/en/copilot/concepts/agents/coding-agent/about-coding-agent?utm_source=chatgpt.com">Copilot coding agent</a> are four prominent examples of this pattern.</p>
<p>These are <em>fantastic</em> tools for code research projects. Come up with a clear goal, turn it into a few paragraphs of prompt, set them loose and check back ten minutes later to see what they've come up with.</p>
<p>I'm firing off 2-3 code research projects a day right now. My own time commitment is minimal and they frequently come back with useful or interesting results.</p>
<h4 id="give-them-a-dedicated-github-repository">Give them a dedicated GitHub repository</h4>
<p>You can run a code research task against an existing GitHub repository, but I find it's much more liberating to have a separate, dedicated repository for your coding agents to run their projects in.</p>
<p>This frees you from being limited to research against just code you've already written, and also means you can be much less cautious about what you let the agents do.</p>
<p>I have two repositories that I use for this - one public, one private. I use the public one for research tasks that have no need to be private, and the private one for anything that I'm not yet ready to share with the world.</p>
<h4 id="let-them-rip-with-unlimited-network-access">Let them rip with unlimited network access</h4>
<p>The biggest benefit of a dedicated repository is that you don't need to be cautious about what the agents operating in that repository can do.</p>
<p>Both Codex Cloud and Claude Code for web default to running agents in a locked-down environment, with strict restrictions on how they can access the network. This makes total sense if they are running against sensitive repositories - a prompt injection attack of the <a href="https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/">lethal trifecta</a> variety could easily be used to steal sensitive code or environment variables.</p>
<p>If you're running in a fresh, non-sensitive repository you don't need to worry about this at all! I've configured my research repositories for full network access, which means my coding agents can install any dependencies they need, fetch data from the web and generally do anything I'd be able to do on my own computer.</p>
<h4 id="my-simonw-research-collection">My simonw/research collection</h4>
<p>Let's dive into some examples. My public research repository is at <a href="https://github.com/simonw/research">simonw/research</a> on GitHub. It currently contains 13 folders, each of which is a separate research project. I only created it two weeks ago so I'm already averaging nearly one a day!</p>
<p>It also includes <a href="https://github.com/simonw/research/blob/main/.github/workflows/update-readme.yml">a GitHub Workflow</a> which uses <a href="https://docs.github.com/en/github-models">GitHub Models</a> to automatically update <a href="https://github.com/simonw/research/blob/main/README.md">the README</a> file with a summary of every new project, using <a href="https://cog.readthedocs.io/">Cog</a>, <a href="https://llm.datasette.io/">LLM</a>, <a href="https://github.com/tonybaloney/llm-github-models">llm-github-models</a> and <a href="https://github.com/simonw/research/blob/b059108dfefeb05a48e1c27f7a127dc9fd648129/README.md#L9-L116">this snippet of Python</a>.</p>
<p>Here are a some example research projects from the repo.</p>
<p><strong><a href="https://github.com/simonw/research/tree/main/node-pyodide">node-pyodide</a></strong> shows an example of a <a href="https://github.com/simonw/research/blob/main/node-pyodide/server-simple.js">Node.js script</a> that runs the <a href="https://pyodide.org/">Pyodide</a> WebAssembly distribution of Python inside it - yet another of my <a href="https://simonwillison.net/tags/sandboxing+python/">ongoing attempts</a> to find a great way of running Python in a WebAssembly sandbox on a server.</p>
<p><strong><a href="https://github.com/simonw/research/tree/main/python-markdown-comparison">python-markdown-comparison</a></strong> (<a href="https://gistpreview.github.io/?fb07c2a3fd2d4cfb814a46696a58a00e">transcript</a>) provides a detailed performance benchmark of seven different Python Markdown libraries. I fired this one off because I stumbled across <a href="https://pypi.org/project/cmarkgfm/">cmarkgfm</a>, a Python binding around GitHub's Markdown implementation in C, and wanted to see how it compared to the other options. This one produced some charts! <code>cmarkgfm</code> came out on top by a significant margin:</p>
<p><img src="https://static.simonwillison.net/static/2025/markdown-performance.png" alt="Bar chart titled &quot;Relative Performance vs cmarkgfm (Large Document)&quot; comparing relative speed of markdown libraries, with marko at 52.1x, markdown2 at 16.9x, mistletoe at 14.1x, markdown at 12.9x, commonmark at 12.1x, mistune at 10.0x, and cmarkgfm at 1.0x baseline marked by a red dashed line; x-axis labeled &quot;Relative Speed (lower is better)&quot; ranging from 0 to 50+" style="max-width: 100%;" /></p>
<p>Here's the entire prompt I used for that project:</p>
<blockquote>
<p>Create a performance benchmark and feature comparison report on PyPI cmarkgfm compared to other popular Python markdown libraries - check all of them out from github and read the source to get an idea for features, then design and run a benchmark including generating some charts, then create a report in a new python-markdown-comparison folder (do not create a _summary.md file or edit anywhere outside of that folder). Make sure the performance chart images are directly displayed in the README.md in the folder.</p>
</blockquote>
<p>Note that I didn't specify any Markdown libraries other than <code>cmarkgfm</code> - Claude Code ran a search and found the other six by itself.</p>
<p><strong><a href="https://github.com/simonw/research/tree/main/cmarkgfm-in-pyodide">cmarkgfm-in-pyodide</a></strong> is a lot more fun. A neat thing about having all of my research projects in the same repository is that new projects can build on previous ones. Here I decided to see how hard it would be to get <code>cmarkgfm</code> - which has a C extension - working inside Pyodide inside Node.js. Claude successfully compiled a 88.4KB <code>cmarkgfm_pyodide-2025.10.22-cp312-cp312-emscripten_3_1_46_wasm32.whl</code> file with the necessary C extension and proved it could be loaded into Pyodide in WebAssembly inside of Node.js.</p>
<p>I ran this one using Claude Code on my laptop after an initial attempt failed. The starting prompt was:</p>
<blockquote>
<p>Figure out how to get the cmarkgfm markdown lover <em>[typo in prompt, this should have been "library" but it figured it out anyway]</em> for Python working in pyodide. This will be hard because it uses C so you will need to compile it to pyodide compatible webassembly somehow. Write a report on your results plus code to a new cmarkgfm-in-pyodide directory. Test it using pytest to exercise a node.js test script that calls pyodide as seen in the existing node.js and pyodide directory</p>
<p>There is an existing branch that was an initial attempt at this research, but which failed because it did not have Internet access. You do have Internet access. Use that existing branch to accelerate your work, but do not commit any code unless you are certain that you have successfully executed tests that prove that the pyodide module you created works correctly.</p>
</blockquote>
<p>This one gave up half way through, complaining that emscripten would take too long. I told it:</p>
<blockquote>
<p>Complete this project, actually run emscripten, I do not care how long it takes, update the report if it works</p>
</blockquote>
<p>It churned away for a bit longer and complained that the existing Python library used CFFI which isn't available in Pyodide. I asked it:</p>
<blockquote>
<p>Can you figure out how to rewrite cmarkgfm to not use FFI and to use a pyodide-friendly way of integrating that C code instead?</p>
</blockquote>
<p>... and it did. You can <a href="https://gistpreview.github.io/?6d778a8f9c4c2c005a189ff308c3bc47">see the full transcript here</a>.</p>
<p><strong><a href="https://github.com/simonw/research/tree/main/blog-tags-scikit-learn">blog-tags-scikit-learn</a></strong>. Taking a short break from WebAssembly, I thought it would be fun to put <a href="https://scikit-learn.org/stable/">scikit-learn</a> through its paces on a text classification task against my blog:</p>
<blockquote>
<p>Work in a new folder called blog-tags-scikit-learn</p>
<p>Download <code>https://datasette.simonwillison.net/simonwillisonblog.db</code> - a SQLite database. Take a look at the blog_entry table and the associated tags - a lot of the earlier entries do not have tags associated with them, where the later entries do. Design, implement and execute models to suggests tags for those earlier entries based on textual analysis against later ones</p>
<p>Use Python scikit learn and try several different strategies</p>
<p>Produce JSON of the results for each one, plus scripts for running them and a detailed markdown description</p>
<p>Also include an HTML page with a nice visualization of the results that works by loading those JSON files.</p>
</blockquote>
<p>This resulted in seven <code>.py</code> files, four <code>.json</code> results files and a detailed <a href="https://github.com/simonw/research/blob/main/blog-tags-scikit-learn/README.md">report</a>. (It ignored the bit about an HTML page with a nice visualization for some reason.) Not bad for a few moments of idle curiosity typed into my phone!</p>
<p>That's just three of the thirteen projects in the repository so far. The commit history for each one usually links to the prompt and sometimes the transcript if you want to see how they unfolded.</p>
<p>More recently I added a short <code>AGENTS.md</code> file to the repo with a few extra tips for my research agents. You can <a href="https://github.com/simonw/research/blob/b059108dfefeb05a48e1c27f7a127dc9fd648129/AGENTS.md">read that here</a>.</p>
<h4 id="this-is-total-slop-of-course">This is total slop, of course</h4>
<p>My preferred definition of <a href="https://simonwillison.net/2024/May/8/slop/">AI slop</a> is AI-generated content that is published without human review. I've not been reviewing these reports in great detail myself, and I wouldn't usually publish them online without some serious editing and verification.</p>
<p>I want to share the pattern I'm using though, so I decided to keep them quarantined in this one public <code>simonw/research</code> repository.</p>
<p>A tiny feature request for GitHub: I'd love to be able to mark a repository as "exclude from search indexes" such that it gets labelled with <code>&lt;meta name="robots" content="noindex"&gt;</code> tags. I still like to keep AI-generated content out of search, to avoid contributing more to the <a href="https://en.wikipedia.org/wiki/Dead_Internet_theory">dead internet</a>.</p>
<h4 id="try-it-yourself">Try it yourself</h4>
<p>It's pretty easy to get started trying out this coding agent research pattern. Create a free GitHub repository (public or private) and let some agents loose on it and see what happens.</p>
<p>You can run agents locally but I find the asynchronous agents to be more convenient - especially as I can run them (or trigger them from my phone) without any fear of them damaging my own machine or leaking any of my private data.</p>
<p>Claude Code for web offers <a href="https://support.claude.com/en/articles/12690958-claude-code-promotion">a free $250 of credits</a> for their $20/month users for a limited time (until November 18, 2025). Gemini Jules has <a href="https://jules.google/docs/usage-limits/">a free tier</a>. There are plenty of other coding agents you can try out as well.</p>
<p>Let me know if your research agents come back with anything interesting!</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/webassembly">webassembly</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/ai-assisted-programming">ai-assisted-programming</a>, <a href="https://simonwillison.net/tags/slop">slop</a>, <a href="https://simonwillison.net/tags/ai-agents">ai-agents</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/claude-code">claude-code</a>, <a href="https://simonwillison.net/tags/jules">jules</a>, <a href="https://simonwillison.net/tags/codex-cli">codex-cli</a></p>]]></description><pubDate>Thu, 6 Nov 2025 15:53:23 +0000</pubDate></item><item><title>Open redirect endpoint in Datasette prior to 0.65.2 and 1.0a21</title><link>https://simonwillison.net/2025/Nov/5/open-redirect-datasette/#atom-everything</link><description><![CDATA[<p><strong><a href="https://github.com/simonw/datasette/security/advisories/GHSA-w832-gg5g-x44m">Open redirect endpoint in Datasette prior to 0.65.2 and 1.0a21</a></strong></p>
This GitHub security advisory covers two new releases of Datasette that I shipped today, both addressing <a href="https://github.com/simonw/datasette/issues/2429">the same open redirect issue</a> with a fix by <a href="https://github.com/jamesjefferies">James Jefferies</a>.</p>
<p><strong><a href="https://docs.datasette.io/en/stable/changelog.html#v0-65-2">Datasette 0.65.2</a></strong> fixes the bug and also adds Python 3.14 support and a <code>datasette publish cloudrun</code> fix.</p>
<p><strong><a href="https://docs.datasette.io/en/latest/changelog.html#a21-2025-11-05">Datasette 1.0a21</a></strong> also has that Cloud Run fix and two other small new features:</p>
<blockquote>
<ul>
<li>New <code>datasette --get /path --headers</code> option for inspecting the headers returned by a path. (<a href="https://github.com/simonw/datasette/issues/2578">#2578</a>)</li>
<li>New <code>datasette.client.get(..., skip_permission_checks=True)</code> parameter to bypass permission checks when making requests using the internal client. (<a href="https://github.com/simonw/datasette/issues/2583">#2583</a>)</li>
</ul>
</blockquote>
<p>I decided to include the Cloud Run deployment fix so anyone with Datasette instances deployed to Cloud Run can update them with the new patched versions.


    <p>Tags: <a href="https://simonwillison.net/tags/security">security</a>, <a href="https://simonwillison.net/tags/datasette">datasette</a>, <a href="https://simonwillison.net/tags/cloudrun">cloudrun</a>, <a href="https://simonwillison.net/tags/annotated-release-notes">annotated-release-notes</a></p>]]></description><pubDate>Wed, 5 Nov 2025 23:11:17 +0000</pubDate></item><item><title>Removing XSLT for a more secure browser</title><link>https://simonwillison.net/2025/Nov/5/removing-xslt/#atom-everything</link><description><![CDATA[<p><strong><a href="https://developer.chrome.com/docs/web-platform/deprecating-xslt">Removing XSLT for a more secure browser</a></strong></p>
Previously discussed <a href="https://simonwillison.net/2025/Aug/19/xslt/">back in August</a>, it looks like it's now official:</p>
<blockquote>
<p>Chrome intends to deprecate and remove XSLT from the browser. [...] We intend to remove support from version 155 (November 17, 2026). The <a href="https://github.com/mozilla/standards-positions/issues/1287#issuecomment-3227145793">Firefox</a> and <a href="https://github.com/whatwg/html/issues/11523#issuecomment-3149280766">WebKit</a> projects have also indicated plans to remove XSLT from their browser engines. [...]</p>
<p>The continued inclusion of XSLT 1.0 in web browsers presents a significant and unnecessary security risk. The underlying libraries that process these transformations, such as <a href="https://github.com/GNOME/libxslt">libxslt</a> (used by Chromium browsers), are complex, aging C/C++ codebases. This type of code is notoriously susceptible to memory safety vulnerabilities like buffer overflows, which can lead to arbitrary code execution.</p>
</blockquote>
<p>I mostly encounter XSLT on people's Atom/RSS feeds, converting those to a more readable format in case someone should navigate directly to that link. Jake Archibald <a href="https://jakearchibald.com/2025/making-xml-human-readable-without-xslt/">shared an alternative solution to that</a> back in September.

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=45823059">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/browsers">browsers</a>, <a href="https://simonwillison.net/tags/chrome">chrome</a>, <a href="https://simonwillison.net/tags/security">security</a>, <a href="https://simonwillison.net/tags/web-standards">web-standards</a>, <a href="https://simonwillison.net/tags/xml">xml</a>, <a href="https://simonwillison.net/tags/xslt">xslt</a>, <a href="https://simonwillison.net/tags/jake-archibald">jake-archibald</a></p>]]></description><pubDate>Wed, 5 Nov 2025 22:24:57 +0000</pubDate></item><item><title>Quoting Ada James</title><link>https://simonwillison.net/2025/Nov/5/brenda/#atom-everything</link><description><![CDATA[<blockquote cite="http://www.tiktok.com/@belligerentbarbies/video/7568380008633257271"><p>I'm worried that they put co-pilot in Excel because Excel is the beast that drives our entire economy and do you know who has tamed that beast?</p>
<p>Brenda.</p>
<p>Who is Brenda?</p>
<p>She is a mid-level employee in every finance department, in every business across this stupid nation and the Excel goddess herself descended from the heavens, kissed Brenda on her forehead and the sweat from Brenda's brow is what allows us to do capitalism. [...]</p>
<p>She's gonna birth that formula for a financial report and then she's gonna send that financial report to a higher up and he's gonna need to make a change to the report and normally he would have sent it back to Brenda but he's like oh I have AI and AI is probably like smarter than Brenda and then the AI is gonna fuck it up real bad and he won't be able to recognize it because he doesn't understand Excel because AI hallucinates.</p>
<p>You know who's not hallucinating?</p>
<p>Brenda.</p></blockquote>
<p class="cite">&mdash; <a href="http://www.tiktok.com/@belligerentbarbies/video/7568380008633257271">Ada James</a>, @belligerentbarbies on TikTok</p>

    <p>Tags: <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/excel">excel</a>, <a href="https://simonwillison.net/tags/hallucinations">hallucinations</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/tiktok">tiktok</a>, <a href="https://simonwillison.net/tags/ai-ethics">ai-ethics</a></p>]]></description><pubDate>Wed, 5 Nov 2025 03:50:31 +0000</pubDate></item><item><title>Code execution with MCP: Building more efficient agents</title><link>https://simonwillison.net/2025/Nov/4/code-execution-with-mcp/#atom-everything</link><description><![CDATA[<p><strong><a href="https://www.anthropic.com/engineering/code-execution-with-mcp">Code execution with MCP: Building more efficient agents</a></strong></p>
When I <a href="https://simonwillison.net/2025/Oct/16/claude-skills/">wrote about Claude Skills</a> I mentioned that I don't use MCP at all any more when working with coding agents - I find CLI utilities and libraries like Playwright Python to be a more effective way of achieving the same goals.</p>
<p>This new piece from Anthropic proposes a way to bring the two worlds more closely together.</p>
<p>It identifies two challenges with MCP as it exists today. The first has been widely discussed before: all of those tool descriptions take up a lot of valuable real estate in the agent context even before you start using them.</p>
<p>The second is more subtle but equally interesting: chaining multiple MCP tools together involves passing their responses through the context, absorbing more valuable tokens and introducing chances for the LLM to make additional mistakes.</p>
<p>What if you could turn MCP tools into code functions instead, and then let the LLM wire them together with executable code?</p>
<p>Anthropic's example here imagines a system that turns MCP tools into TypeScript files on disk, looking something like this:</p>
<div class="highlight highlight-source-ts"><pre><span class="pl-c">// ./servers/google-drive/getDocument.ts</span>
<span class="pl-k">interface</span> <span class="pl-smi">GetDocumentInput</span> <span class="pl-kos">{</span>
  <span class="pl-c1">documentId</span>: <span class="pl-smi">string</span><span class="pl-kos">;</span>
<span class="pl-kos">}</span>
<span class="pl-k">interface</span> <span class="pl-smi">GetDocumentResponse</span> <span class="pl-kos">{</span>
  <span class="pl-c1">content</span>: <span class="pl-smi">string</span><span class="pl-kos">;</span>
<span class="pl-kos">}</span>
<span class="pl-c">/* Read a document from Google Drive */</span>
<span class="pl-k">export</span> <span class="pl-k">async</span> <span class="pl-k">function</span> <span class="pl-en">getDocument</span><span class="pl-kos">(</span><span class="pl-s1">input</span>: <span class="pl-smi">GetDocumentInput</span><span class="pl-kos">)</span>: <span class="pl-smi">Promise</span><span class="pl-c1">&lt;</span><span class="pl-smi">GetDocumentResponse</span><span class="pl-c1">&gt;</span> <span class="pl-kos">{</span>
  <span class="pl-k">return</span> <span class="pl-en">callMCPTool</span><span class="pl-c1">&lt;</span><span class="pl-smi">GetDocumentResponse</span><span class="pl-c1">&gt;</span><span class="pl-kos">(</span><span class="pl-s">'google_drive__get_document'</span><span class="pl-kos">,</span> <span class="pl-s1">input</span><span class="pl-kos">)</span><span class="pl-kos">;</span>
<span class="pl-kos">}</span></pre></div>

<p>This takes up no tokens at all - it's a file on disk. In a similar manner to Skills the agent can navigate the filesystem to discover these definitions on demand.</p>
<p>Then it can wire them together by generating code:</p>
<div class="highlight highlight-source-ts"><pre><span class="pl-k">const</span> <span class="pl-s1">transcript</span> <span class="pl-c1">=</span> <span class="pl-kos">(</span><span class="pl-k">await</span> <span class="pl-s1">gdrive</span><span class="pl-kos">.</span><span class="pl-en">getDocument</span><span class="pl-kos">(</span><span class="pl-kos">{</span> <span class="pl-c1">documentId</span>: <span class="pl-s">'abc123'</span> <span class="pl-kos">}</span><span class="pl-kos">)</span><span class="pl-kos">)</span><span class="pl-kos">.</span><span class="pl-c1">content</span><span class="pl-kos">;</span>
<span class="pl-k">await</span> <span class="pl-s1">salesforce</span><span class="pl-kos">.</span><span class="pl-en">updateRecord</span><span class="pl-kos">(</span><span class="pl-kos">{</span>
  <span class="pl-c1">objectType</span>: <span class="pl-s">'SalesMeeting'</span><span class="pl-kos">,</span>
  <span class="pl-c1">recordId</span>: <span class="pl-s">'00Q5f000001abcXYZ'</span><span class="pl-kos">,</span>
  <span class="pl-c1">data</span>: <span class="pl-kos">{</span> <span class="pl-c1">Notes</span>: <span class="pl-s1">transcript</span> <span class="pl-kos">}</span>
<span class="pl-kos">}</span><span class="pl-kos">)</span><span class="pl-kos">;</span></pre></div>

<p>Notably, the example here avoids round-tripping the response from the <code>gdrive.getDocument()</code> call through the model on the way to the <code>salesforce.updateRecord()</code> call - which is faster, more reliable, saves on context tokens, and avoids the model being exposed to any potentially sensitive data in that document.</p>
<p>This all looks very solid to me! I think it's a sensible way to take advantage of the strengths of coding agents and address some of the major drawbacks of MCP as it is usually implemented today.</p>
<p>There's one catch: Anthropic outline the proposal in some detail but provide no code to execute on it! Implementation is left as an exercise for the reader:</p>
<blockquote>
<p>If you implement this approach, we encourage you to share your findings with the <a href="https://modelcontextprotocol.io/community/communication">MCP community</a>.</p>
</blockquote>

    <p><small></small>Via <a href="https://x.com/AnthropicAI/status/1985846791842250860">@AnthropicAI</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/prompt-engineering">prompt-engineering</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/anthropic">anthropic</a>, <a href="https://simonwillison.net/tags/model-context-protocol">model-context-protocol</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a></p>]]></description><pubDate>Tue, 4 Nov 2025 23:56:24 +0000</pubDate></item><item><title>A new SQL-powered permissions system in Datasette 1.0a20</title><link>https://simonwillison.net/2025/Nov/4/datasette-10a20/#atom-everything</link><description><![CDATA[<p><a href="https://docs.datasette.io/en/latest/changelog.html#a20-2025-11-03">Datasette 1.0a20 is out</a> with the biggest breaking API change on the road to 1.0, improving how Datasette's permissions system works by migrating permission logic to SQL running in SQLite. This release involved <a href="https://github.com/simonw/datasette/compare/1.0a19...1.0a20">163 commits</a>, with 10,660 additions and 1,825 deletions, most of which was written with the help of Claude Code.</p>


<ul>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#understanding-the-permissions-system">Understanding the permissions system</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#permissions-systems-need-to-be-able-to-efficiently-list-things">Permissions systems need to be able to efficiently list things</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#the-new-permission-resources-sql-plugin-hook">The new permission_resources_sql() plugin hook</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#hierarchies-plugins-vetoes-and-restrictions">Hierarchies, plugins, vetoes, and restrictions</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#new-debugging-tools">New debugging tools</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#the-missing-feature-list-actors-who-can-act-on-this-resource">The missing feature: list actors who can act on this resource</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#upgrading-plugins-for-datasette-1-0a20">Upgrading plugins for Datasette 1.0a20</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#using-claude-code-to-implement-this-change">Using Claude Code to implement this change</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#starting-with-a-proof-of-concept">Starting with a proof-of-concept</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#miscellaneous-tips-i-picked-up-along-the-way">Miscellaneous tips I picked up along the way</a></li>
  <li><a href="https://simonwillison.net/2025/Nov/4/datasette-10a20/#what-s-next-">What's next?</a></li>
</ul>

<h4 id="understanding-the-permissions-system">Understanding the permissions system</h4>
<p>Datasette's <a href="https://docs.datasette.io/en/latest/authentication.html">permissions system</a> exists to answer the following question:</p>
<blockquote>
<p>Is this <strong>actor</strong> allowed to perform this <strong>action</strong>, optionally against this particular <strong>resource</strong>?</p>
</blockquote>
<p>An <strong>actor</strong> is usually a user, but might also be an automation operating via the Datasette API.</p>
<p>An <strong>action</strong> is a thing they need to do - things like view-table, execute-sql, insert-row.</p>
<p>A <strong>resource</strong> is the subject of the action - the database you are executing SQL against, the table you want to insert a row into.</p>
<p>Datasette's default configuration is public but read-only: anyone can view databases and tables or execute read-only SQL queries but no-one can modify data.</p>
<p>Datasette plugins can enable all sorts of additional ways to interact with databases, many of which need to be protected by a form of authentication Datasette also 1.0 includes <a href="https://simonwillison.net/2022/Dec/2/datasette-write-api/">a write API</a> with a need to configure who can insert, update, and delete rows or create new tables.</p>
<p>Actors can be authenticated in a number of different ways provided by plugins using the <a href="https://docs.datasette.io/en/latest/plugin_hooks.html#actor-from-request-datasette-request">actor_from_request()</a> plugin hook. <a href="https://datasette.io/plugins/datasette-auth-passwords">datasette-auth-passwords</a> and <a href="https://datasette.io/plugins/datasette-auth-github">datasette-auth-github</a> and <a href="https://datasette.io/plugins/datasette-auth-existing-cookies">datasette-auth-existing-cookies</a> are examples of authentication plugins.</p>
<h4 id="permissions-systems-need-to-be-able-to-efficiently-list-things">Permissions systems need to be able to efficiently list things</h4>
<p>The previous implementation included a design flaw common to permissions systems of this nature: each permission check involved a function call which would delegate to one or more plugins and return a True/False result.</p>
<p>This works well for single checks, but has a significant problem: what if you need to show the user a list of things they can access, for example the tables they can view?</p>
<p>I want Datasette to be able to handle potentially thousands of tables - tables in SQLite are cheap! I don't want to have to run 1,000+ permission checks just to show the user a list of tables.</p>
<p>Since Datasette is built on top of SQLite we already have a powerful mechanism to help solve this problem. SQLite is <em>really</em> good at filtering large numbers of records.</p>
<h4 id="the-new-permission-resources-sql-plugin-hook">The new permission_resources_sql() plugin hook</h4>
<p>The biggest change in the new release is that I've replaced the previous  <code>permission_allowed(actor, action, resource)</code> plugin hook - which let a plugin determine if an actor could perform an action against a resource - with a new <a href="https://docs.datasette.io/en/latest/plugin_hooks.html#plugin-hook-permission-resources-sql">permission_resources_sql(actor, action)</a> plugin hook.</p>
<p>Instead of returning a True/False result, this new hook returns a SQL query that returns rules helping determine the resources the current actor can execute the specified action against.</p>
<p>Here's an example, lifted from the documentation:</p>
<pre><span class="pl-k">from</span> <span class="pl-s1">datasette</span> <span class="pl-k">import</span> <span class="pl-s1">hookimpl</span>
<span class="pl-k">from</span> <span class="pl-s1">datasette</span>.<span class="pl-s1">permissions</span> <span class="pl-k">import</span> <span class="pl-v">PermissionSQL</span>


<span class="pl-en">@<span class="pl-s1">hookimpl</span></span>
<span class="pl-k">def</span> <span class="pl-en">permission_resources_sql</span>(<span class="pl-s1">datasette</span>, <span class="pl-s1">actor</span>, <span class="pl-s1">action</span>):
    <span class="pl-k">if</span> <span class="pl-s1">action</span> <span class="pl-c1">!=</span> <span class="pl-s">"view-table"</span>:
        <span class="pl-k">return</span> <span class="pl-c1">None</span>
    <span class="pl-k">if</span> <span class="pl-c1">not</span> <span class="pl-s1">actor</span> <span class="pl-c1">or</span> <span class="pl-s1">actor</span>.<span class="pl-c1">get</span>(<span class="pl-s">"id"</span>) <span class="pl-c1">!=</span> <span class="pl-s">"alice"</span>:
        <span class="pl-k">return</span> <span class="pl-c1">None</span>

    <span class="pl-k">return</span> <span class="pl-en">PermissionSQL</span>(
        <span class="pl-s1">sql</span><span class="pl-c1">=</span><span class="pl-s">"""</span>
<span class="pl-s">            SELECT</span>
<span class="pl-s">                'accounting' AS parent,</span>
<span class="pl-s">                'sales' AS child,</span>
<span class="pl-s">                1 AS allow,</span>
<span class="pl-s">                'alice can view accounting/sales' AS reason</span>
<span class="pl-s">        """</span>,
    )</pre>
<p>This hook grants the actor with ID "alice" permission to view the "sales" table in the "accounting" database.</p>
<p>The <code>PermissionSQL</code> object should always return four columns: a parent, child, allow (1 or 0), and a reason string for debugging.</p>
<p>When you ask Datasette to list the resources an actor can access for a specific action, it will combine the SQL returned by all installed plugins into a single query that joins against <a href="https://docs.datasette.io/en/latest/internals.html#internal-database-schema">the internal catalog tables</a> and efficiently lists all the resources the actor can access.</p>
<p>This query can then be limited or paginated to avoid loading too many results at once.</p>
<h4 id="hierarchies-plugins-vetoes-and-restrictions">Hierarchies, plugins, vetoes, and restrictions</h4>
<p>Datasette has several additional requirements that make the permissions system more complicated.</p>
<p>Datasette permissions can optionally act against a two-level <strong>hierarchy</strong>. You can grant a user the ability to insert-row against a specific table, or every table in a specific database, or every table in <em>every</em> database in that Datasette instance.</p>
<p>Some actions can apply at the table level, others the database level and others only make sense globally - enabling a new feature that isn't tied to tables or databases, for example.</p>
<p>Datasette currently has <a href="https://docs.datasette.io/en/latest/authentication.html#built-in-actions">ten default actions</a> but <strong>plugins</strong> that add additional features can <a href="https://docs.datasette.io/en/latest/plugin_hooks.html#register-actions-datasette">register new actions</a> to better participate in the permission systems.</p>
<p>Datasette's permission system has a mechanism to <strong>veto</strong> permission checks - a plugin can return a deny for a specific permission check which will override any allows. This needs to be hierarchy-aware - a deny at the database level can be outvoted by an allow at the table level.</p>
<p>Finally, Datasette includes a mechanism for applying additional <strong>restrictions</strong> to a request. This was introduced for Datasette's API - it allows a user to create an API token that can act on their behalf but is only allowed to perform a subset of their capabilities - just reading from two specific tables, for example. Restrictions are <a href="https://docs.datasette.io/en/latest/authentication.html#restricting-the-actions-that-a-token-can-perform">described in more detail</a> in the documentation.</p>
<p>That's a lot of different moving parts for the new implementation to cover.</p>
<h4 id="new-debugging-tools">New debugging tools</h4>
<p>Since permissions are critical to the security of a Datasette deployment it's vital that they are as easy to understand and debug as possible.</p>
<p>The new alpha adds several new debugging tools, including this page that shows the full list of resources matching a specific action for the current user:</p>
<p><img src="https://static.simonwillison.net/static/2025/datasette-allowed-resources.jpg" alt="Allowed resources. Tabs are Playground, Check, Allowed, Rules, Actions, Allow debug. There is a form where you can select an action (here view-table) and optionally filter by parent and child. Below is a table of results listing resource paths - e.g. /fixtures/name-of-table - plus parent, child and reason columns. The reason is a JSON list for example &quot;datasette.default_permissions: root user&quot;,&quot;datasette.default_permissions: default allow for view-table&quot;." style="max-width: 100%;" /></p>
<p>And this page listing the <em>rules</em> that apply to that question - since different plugins may return different rules which get combined together:</p>
<p><img src="https://static.simonwillison.net/static/2025/datasette-rules.jpg" alt="The rules tab for the same view-table question. Here there are two allow rules - one from datasette.default_permissions for the root user and another from default_permissions labelled default allow for view-table." style="max-width: 100%;" /></p>
<p>This screenshot illustrates two of Datasette's built-in rules: there is a default allow for read-only operations such as view-table (which can be over-ridden by plugins) and another rule that says the root user can do anything (provided Datasette was started with the <code>--root</code> option.)</p>
<p>Those rules are defined in the <a href="https://github.com/simonw/datasette/blob/1.0a20/datasette/default_permissions.py">datasette/default_permissions.py</a> Python module.</p>
<h4 id="the-missing-feature-list-actors-who-can-act-on-this-resource">The missing feature: list actors who can act on this resource</h4>
<p>There's one question that the new system cannot answer: provide a full list of actors who can perform this action against this resource.</p>
<p>It's not possibly to provide this globally for Datasette because Datasette doesn't have a way to track what "actors" exist in the system. SSO plugins such as <code>datasette-auth-github</code> mean a new authenticated GitHub user might show up at any time, with the ability to perform actions despite the Datasette system never having encountered that particular username before.</p>
<p>API tokens and actor restrictions come into play here as well. A user might create a signed API token that can perform a subset of actions on their behalf - the existence of that token can't be predicted by the permissions system.</p>
<p>This is a notable omission, but it's also quite common in other systems. AWS cannot provide a list of all actors who have permission to access a specific S3 bucket, for example - presumably for similar reasons.</p>
<h4 id="upgrading-plugins-for-datasette-1-0a20">Upgrading plugins for Datasette 1.0a20</h4>
<p>Datasette's plugin ecosystem is the reason I'm paying so much attention to ensuring Datasette 1.0 has a stable API. I don't want plugin authors to need to chase breaking changes once that 1.0 release is out.</p>
<p>The <a href="https://docs.datasette.io/en/latest/upgrade_guide.html">Datasette upgrade guide</a> includes detailed notes on upgrades that are needed between the 0.x and 1.0 alpha releases. I've added an extensive section about the permissions changes to that document.</p>
<p>I've also been experimenting with dumping those instructions directly into coding agent tools - Claude Code and Codex CLI - to have them upgrade existing plugins for me. This has been working <em>extremely well</em>. I've even had Claude Code <a href="https://github.com/simonw/datasette/commit/fa978ec1006297416e2cd87a2f0d3cac99283cf8">update those notes itself</a> with things it learned during an upgrade process!</p>
<p>This is greatly helped by the fact that every single Datasette plugin has an automated test suite that demonstrates the core functionality works as expected. Coding agents can use those tests to verify that their changes have had the desired effect.</p>
<p>I've also been leaning heavily on <code>uv</code> to help with the upgrade process. I wrote myself two new helper scripts - <code>tadd</code> and <code>radd</code> - to help test the new plugins.</p>
<ul>
<li>
<code>tadd</code> = "test against datasette dev" - it runs a plugin's existing test suite against the current development version of Datasette checked out on my machine. It passes extra options through to <code>pytest</code> so I can run <code>tadd -k test_name</code> or <code>tadd -x --pdb</code> as needed.</li>
<li>
<code>radd</code> = "run against datasette dev" - it runs the latest dev <code>datasette</code> command with the plugin installed.</li>
</ul>
<p>The <code>tadd</code> and <code>radd</code> implementations <a href="https://til.simonwillison.net/python/uv-tests#variants-tadd-and-radd">can be found in this TIL</a>.</p>
<p>Some of my plugin upgrades have become a one-liner to the <code>codex exec</code> command, which runs OpenAI Codex CLI with a prompt without entering interactive mode:</p>
<div class="highlight highlight-source-shell"><pre>codex <span class="pl-c1">exec</span> --dangerously-bypass-approvals-and-sandbox \
<span class="pl-s"><span class="pl-pds">"</span>Run the command tadd and look at the errors and then</span>
<span class="pl-s">read ~/dev/datasette/docs/upgrade-1.0a20.md and apply</span>
<span class="pl-s">fixes and run the tests again and get them to pass<span class="pl-pds">"</span></span></pre></div>
<p>There are still a bunch more to go - there's <a href="https://github.com/simonw/datasette/issues/2577">a list in this tracking issue</a> - but I expect to have the plugins I maintain all upgraded pretty quickly now that I have a solid process in place.</p>
<h4 id="using-claude-code-to-implement-this-change">Using Claude Code to implement this change</h4>
<p>This change to Datasette core <em>by far</em> the most ambitious piece of work I've ever attempted using a coding agent.</p>
<p>Last year I agreed with the prevailing opinion that LLM assistance was much more useful for greenfield coding tasks than working on existing codebases. The amount you could usefully get done was greatly limited by the need to fit the entire codebase into the model's context window.</p>
<p>Coding agents have entirely changed that calculation. Claude Code and Codex CLI still have relatively limited token windows - albeit larger than last year - but their ability to search through the codebase, read extra files on demand and "reason" about the code they are working with has made them vastly more capable.</p>
<p>I no longer see codebase size as a limiting factor for how useful they can be.</p>
<p>I've also spent enough time with Claude Sonnet 4.5 to build a weird level of trust in it. I can usually predict exactly what changes it will make for a prompt. If I tell it "extract this code into a separate function" or "update every instance of this pattern" I know it's likely to get it right.</p>
<p>For something like permission code I still review everything it does, often by watching it as it works since it displays diffs in the UI.</p>
<p>I also pay extremely close attention to the tests it's writing. Datasette 1.0a19 already had 1,439 tests, many of which exercised the existing permission system. 1.0a20 increases that to 1,583 tests. I feel very good about that, especially since most of the existing tests continued to pass without modification.</p>
<h4 id="starting-with-a-proof-of-concept">Starting with a proof-of-concept</h4>
<p>I built several different proof-of-concept implementations of SQL permissions before settling on the final design. My <a href="https://github.com/simonw/research/tree/main/sqlite-permissions-poc">research/sqlite-permissions-poc</a> project was the one that finally convinced me of a viable approach,</p>
<p>That one started as a <a href="https://claude.ai/share/8fd432bc-a718-4883-9978-80ab82a75c87">free ranging conversation with Claude</a>, at the end of which I told it to generate a specification which I then <a href="https://chatgpt.com/share/68f6532f-9920-8006-928a-364e15b6e9ef">fed into GPT-5</a> to implement. You can see that specification <a href="https://github.com/simonw/research/tree/main/sqlite-permissions-poc#original-prompt">at the end of the README</a>.</p>
<p>I later fed the POC itself into Claude Code and had it implement the first version of the new Datasette system based on that previous experiment.</p>
<p>This is admittedly a very weird way of working, but it helped me finally break through on a problem that I'd been struggling with for months.</p>
<h4 id="miscellaneous-tips-i-picked-up-along-the-way">Miscellaneous tips I picked up along the way</h4>
<ul>
<li>When working on anything relating to plugins it's vital to have at least a few real plugins that you upgrade in lock-step with the core changes. The <code>tadd</code> and <code>radd</code> shortcuts were invaluable for productively working on those plugins while I made changes to core.</li>
<li>Coding agents make experiments <em>much</em> cheaper. I threw away so much code on the way to the final implementation, which was psychologically easier because the cost to create that code in the first place was so low.</li>
<li>Tests, tests, tests. This project would have been impossible without that existing test suite. The additional tests we built along the way give me confidence that the new system is as robust as I need it to be.</li>
<li>Claude writes good commit messages now! I finally gave in and let it write these - previously I've been determined to write them myself. It's a big time saver to be able to say "write a tasteful commit message for these changes".</li>
<li>Claude is also great at breaking up changes into smaller commits. It can also productively rewrite history to make it easier to follow, especially useful if you're still working in a branch.</li>
<li>A really great way to review Claude's changes is with the GitHub PR interface. You can attach comments to individual lines of code and then later prompt Claude like this: <code>Use gh CLI to fetch comments on URL-to-PR and make the requested changes</code>. This is a very quick way to apply little nitpick changes - rename this function, refactor this repeated code, add types here etc.</li>
<li>The code I write with LLMs is <em>higher quality code</em>. I usually find myself making constant trade-offs while coding: this function would be neater if I extracted this helper, it would be nice to have inline documentation here, this changing this would be good but would break a dozen tests... for each of those I have to determine if the additional time is worth the benefit. Claude can apply changes so much faster than me that these calculations have changed - almost any improvement is worth applying, no matter how trivial, because the time cost is so low.</li>
<li>Internal tools are cheap now. The new debugging interfaces were mostly written by Claude and are significantly nicer to use and look at than the hacky versions I would have knocked out myself, if I had even taken the extra time to build them.</li>
<li>That trick with a Markdown file full of upgrade instructions works astonishingly well - it's the same basic idea as <a href="https://simonwillison.net/2025/Oct/16/claude-skills/">Claude Skills</a>. I maintain over 100 Datasette plugins now and I expect I'll be automating all sorts of minor upgrades in the future using this technique.</li>
</ul>
<h4 id="what-s-next-">What's next?</h4>
<p>Now that the new alpha is out my focus is upgrading the existing plugin ecosystem to use it, and supporting other plugin authors who are doing the same.</p>
<p>The new permissions system unlocks some key improvements to Datasette Cloud concerning finely-grained permissions for larger teams, so I'll be integrating the new alpha there this week.</p>
<p>This is the single biggest backwards-incompatible change required before Datasette 1.0. I plan to apply the lessons I learned from this project to the other, less intimidating changes. I'm hoping this can result in a final 1.0 release before the end of the year!</p>
    
        <p>Tags: <a href="https://simonwillison.net/tags/plugins">plugins</a>, <a href="https://simonwillison.net/tags/projects">projects</a>, <a href="https://simonwillison.net/tags/python">python</a>, <a href="https://simonwillison.net/tags/sql">sql</a>, <a href="https://simonwillison.net/tags/sqlite">sqlite</a>, <a href="https://simonwillison.net/tags/datasette">datasette</a>, <a href="https://simonwillison.net/tags/annotated-release-notes">annotated-release-notes</a>, <a href="https://simonwillison.net/tags/uv">uv</a>, <a href="https://simonwillison.net/tags/coding-agents">coding-agents</a>, <a href="https://simonwillison.net/tags/claude-code">claude-code</a>, <a href="https://simonwillison.net/tags/codex-cli">codex-cli</a></p>]]></description><pubDate>Tue, 4 Nov 2025 21:34:42 +0000</pubDate></item><item><title>MCP Colors: Systematically deal with prompt injection risk</title><link>https://simonwillison.net/2025/Nov/4/mcp-colors/#atom-everything</link><description><![CDATA[<p><strong><a href="https://timkellogg.me/blog/2025/11/03/colors">MCP Colors: Systematically deal with prompt injection risk</a></strong></p>
Tim Kellogg proposes a neat way to think about prompt injection, especially with respect to MCP tools.</p>
<p>Classify every tool with a color: red if it exposes the agent to untrusted (potentially malicious) instructions, blue if it involves a "critical action" - something you would not want an attacker to be able to trigger.</p>
<p>This means you can configure your agent to actively avoid mixing the two colors at once:</p>
<blockquote>
<p>The Chore: Go label every data input, and <strong>every tool</strong> (especially MCP tools). For MCP tools &amp; resources, you can use the _meta object to keep track of the color. The agent can decide at runtime (or earlier) if it’s gotten into an unsafe state.</p>
<p>Personally, I like to automate. I needed to label ~200 tools, so I put them in a spreadsheet and used an LLM to label them. That way, I could focus on being <strong>precise and clear</strong> about my criteria for what constitutes “red”, “blue” or “neither”. That way I ended up with an artifact that scales beyond my initial set of tools.</p>
</blockquote>

    <p><small></small>Via <a href="https://bsky.app/profile/timkellogg.me/post/3m4ridhi3ps25">@timkellogg.me</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/security">security</a>, <a href="https://simonwillison.net/tags/ai">ai</a>, <a href="https://simonwillison.net/tags/prompt-injection">prompt-injection</a>, <a href="https://simonwillison.net/tags/generative-ai">generative-ai</a>, <a href="https://simonwillison.net/tags/llms">llms</a>, <a href="https://simonwillison.net/tags/model-context-protocol">model-context-protocol</a></p>]]></description><pubDate>Tue, 4 Nov 2025 16:52:21 +0000</pubDate></item><item><title>Quoting Steve Francia</title><link>https://simonwillison.net/2025/Nov/4/steve-francia/#atom-everything</link><description><![CDATA[<blockquote cite="https://spf13.com/p/the-hidden-conversation/"><p>Every time an engineer evaluates a language that isn’t “theirs,” their brain is literally working against them. They’re not just analyzing technical trade offs, they’re contemplating a version of themselves that doesn’t exist yet, that feels threatening to the version that does. The Python developer reads case studies about Go’s performance and their amygdala quietly marks each one as a threat to be neutralized. The Rust advocate looks at identical problems and their Default Mode Network constructs narratives about why “only” Rust can solve them.</p>
<p>We’re not lying. We genuinely believe our reasoning is sound. That’s what makes identity based thinking so expensive, and so invisible.</p></blockquote>
<p class="cite">&mdash; <a href="https://spf13.com/p/the-hidden-conversation/">Steve Francia</a>, Why Engineers Can't Be Rational About Programming Languages</p>

    <p>Tags: <a href="https://simonwillison.net/tags/technical-debt">technical-debt</a>, <a href="https://simonwillison.net/tags/psychology">psychology</a>, <a href="https://simonwillison.net/tags/programming-languages">programming-languages</a></p>]]></description><pubDate>Tue, 4 Nov 2025 02:54:07 +0000</pubDate></item><item><title>The fetch()ening</title><link>https://simonwillison.net/2025/Nov/3/htmx-the-fetchening/#atom-everything</link><description><![CDATA[<p><strong><a href="https://htmx.org/essays/the-fetchening/">The fetch()ening</a></strong></p>
After several years of stable htmx 2.0 and a promise to never release a backwards-incompatible htmx 3 Carson Gross is technically keeping that promise... by skipping to htmx 4 instead!</p>
<p>The main reason is to replace <code>XMLHttpRequest</code> with <code>fetch()</code> - a change that will have enough knock-on compatibility effects to require a major version bump - so they're using that as an excuse to clean up various other accumulated design warts at the same time.</p>
<p>htmx is a <em>very</em> responsibly run project. Here's their plan for the upgrade:</p>
<blockquote>
<p>That said, htmx 2.0 users <em>will</em> face an upgrade project when moving to 4.0 in a way that they did not have to in moving from 1.0 to 2.0.</p>
<p>I am sorry about that, and want to offer three things to address it:</p>
<ul>
<li>htmx 2.0 (like htmx 1.0 &amp; intercooler.js 1.0) will be supported <em>in perpetuity</em>, so there is absolutely <em>no</em> pressure to upgrade your application: if htmx 2.0 is satisfying your hypermedia needs, you can stick with it.</li>
<li>We will create extensions that revert htmx 4 to htmx 2 behaviors as much as is feasible (e.g. Supporting the old implicit attribute inheritance model, at least)</li>
<li>We will roll htmx 4.0 out slowly, over a multi-year period. As with the htmx 1.0 -&gt; 2.0 upgrade, there will be a long period where htmx 2.x is <code>latest</code> and htmx 4.x is <code>next</code></li>
</ul>
</blockquote>
<p>There are lots of neat details in here about the design changes they plan to make. It's a really great piece of technical writing - I learned a bunch about htmx and picked up some good notes on API design in general from this.

    <p><small></small>Via <a href="https://news.ycombinator.com/item?id=45803358">Hacker News</a></small></p>


    <p>Tags: <a href="https://simonwillison.net/tags/html">html</a>, <a href="https://simonwillison.net/tags/javascript">javascript</a>, <a href="https://simonwillison.net/tags/open-source">open-source</a>, <a href="https://simonwillison.net/tags/htmx">htmx</a>, <a href="https://simonwillison.net/tags/carson-gross">carson-gross</a></p>]]></description><pubDate>Mon, 3 Nov 2025 21:39:54 +0000</pubDate></item><item><title>Quoting Barry Warsaw</title><link>https://simonwillison.net/2025/Nov/3/barry-warsaw/#atom-everything</link><description><![CDATA[<blockquote cite="https://discuss.python.org/t/pep-810-explicit-lazy-imports/104131/465"><p>Dear PEP 810 authors. The Steering Council is happy to unanimously accept "<a href="https://peps.python.org/pep-0810/">PEP 810, Explicit lazy imports</a>". Congratulations! We appreciate the way you were able to build on and improve the previously discussed (and rejected) attempt at lazy imports as proposed in <a href="https://peps.python.org/pep-0690/">PEP 690</a>.</p></blockquote>
<p class="cite">&mdash; <a href="https://discuss.python.org/t/pep-810-explicit-lazy-imports/104131/465">Barry Warsaw</a>, on behalf of the Python Steering Council</p>

    <p>Tags: <a href="https://simonwillison.net/tags/python">python</a>, <a href="https://simonwillison.net/tags/barry-warsaw">barry-warsaw</a></p>]]></description><pubDate>Mon, 3 Nov 2025 21:27:08 +0000</pubDate></item></channel></rss>